{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLbTPYUKWWCL"
      },
      "source": [
        "#CISC684 - Final Project: Hotel Review Sentiment Analysis\n",
        "###Jacob Meredith, Yaren Usul, Connor Ludwin, Madison Johnson"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install symspellpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrHcIN030oN1",
        "outputId": "c927c2fe-b530-409e-f0c6-88c64685ba52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting symspellpy\n",
            "  Downloading symspellpy-6.7.8-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting editdistpy>=0.1.3 (from symspellpy)\n",
            "  Downloading editdistpy-0.1.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Downloading symspellpy-6.7.8-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading editdistpy-0.1.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: editdistpy, symspellpy\n",
            "Successfully installed editdistpy-0.1.5 symspellpy-6.7.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHo77aB3WGvf",
        "outputId": "9307bf63-698c-4a7a-a4cf-58ae63132dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Import all necessary libraries for RNN, datacleaning, and other tasks\n",
        "\n",
        "# Data import & RNN libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Data sorting & cleaning libraries\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "import string\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.discard('no')\n",
        "stop_words.discard('not')\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "from symspellpy import SymSpell, Verbosity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvgW73-NNRUs",
        "outputId": "fb259154-f19c-464e-fbab-e55199aac66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#drive.mount('/content/drive')\n",
        "drive.mount('/content/drive', force_remount=True) #if having endpt not connected error, this forces Google Drive to remount, which refreshes the connection\n",
        "# Read a CSV file from the shared drive\n",
        "reviews_df = pd.read_csv('/content/drive/Shared drives/CISC684 - Machine Learning/Hotel_Reviews.csv')\n",
        "# append the positive and negative text reviews\n",
        "reviews_df[\"review\"] = reviews_df[\"Negative_Review\"] + \" \" + reviews_df[\"Positive_Review\"]\n",
        "# create the label\n",
        "reviews_df[\"review_score\"] = (reviews_df[\"Reviewer_Score\"]).astype(float)\n",
        "# select only relevant columns\n",
        "reviews_df = reviews_df[[\"review\", \"review_score\"]]\n",
        "reviews_df = reviews_df.sample(frac = 1, replace = False, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn1qTaSNkwnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff3d5439-f507-4dcc-d6f5-47dd7579df26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame length: 515738\n",
            "Filtered DataFrame length: 28000\n",
            "                                              review  \\\n",
            "0       No Negative  I will never to stay this hotel   \n",
            "1   Everything this hotel should not be ranked as...   \n",
            "2                             everything No Positive   \n",
            "3   All about room about clean about staff and su...   \n",
            "4   The room is really small and has nothing to d...   \n",
            "\n",
            "                                      corrected_text  \n",
            "0        no negative i will never to stay this hotel  \n",
            "1  everything this hotel should not be ranked as ...  \n",
            "2                             everything no positive  \n",
            "3  all about room about clean about staff and sur...  \n",
            "4  ﻿the room is really small and has nothing to d...  \n"
          ]
        }
      ],
      "source": [
        "# Define a function to limit rows for each review score range\n",
        "def limit_rows(df, min_score, max_score, limit=3500):\n",
        "    filtered = df[(df[\"review_score\"] > min_score) & (df[\"review_score\"] <= max_score)]\n",
        "    if len(filtered) > limit:\n",
        "        return filtered.sample(n=limit, random_state=42)\n",
        "    return filtered\n",
        "\n",
        "ranges = [(0, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10)]\n",
        "limited_reviews = pd.concat(\n",
        "    [limit_rows(reviews_df, min_score, max_score) for min_score, max_score in ranges],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "dictionary_path = \"/content/drive/Shared drives/CISC684 - Machine Learning/frequency_dictionary_en_82_765.txt\"  #Update with the correct path\n",
        "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
        "\n",
        "# Define a function to limit rows for each review score range\n",
        "def limit_rows(df, min_score, max_score, limit=3500):\n",
        "    filtered = df[(df[\"review_score\"] > min_score) &\n",
        "(df[\"review_score\"] <= max_score)]\n",
        "    if len(filtered) > limit:\n",
        "        return filtered.sample(n=limit, random_state=42)\n",
        "    return filtered\n",
        "\n",
        "# Apply the function for each score range and concatenate results\n",
        "ranges = [(0, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8), (8, 9), (9, 10)]\n",
        "limited_reviews = pd.concat(\n",
        "    [limit_rows(reviews_df, min_score, max_score) for min_score,\n",
        "max_score in ranges],\n",
        "    ignore_index=True\n",
        ")\n",
        "\n",
        "# Define the correction function using SymSpell\n",
        "def correct_with_symspell(text):\n",
        "    suggestions = sym_spell.lookup_compound(text, max_edit_distance=2)\n",
        "    return suggestions[0].term if suggestions else text\n",
        "\n",
        "# Optimize by deduplicating and correcting unique entries\n",
        "unique_reviews = limited_reviews[\"review\"].unique()\n",
        "corrections = {review: correct_with_symspell(review) for review in\n",
        "unique_reviews}\n",
        "\n",
        "# Map corrected reviews back to the DataFrame\n",
        "limited_reviews[\"corrected_text\"] = limited_reviews[\"review\"].map(corrections)\n",
        "limited_reviews[\"review_score\"] = limited_reviews[\"review_score\"].astype(float)\n",
        "\n",
        "# Display results\n",
        "print(f\"Original DataFrame length: {len(reviews_df)}\")\n",
        "print(f\"Filtered DataFrame length: {len(limited_reviews)}\")\n",
        "print(limited_reviews[[\"review\", \"corrected_text\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(limited_reviews.head(100)) #line 96 proves typos have been fixed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFV2xkW107mv",
        "outputId": "3d7e465b-b150-44ea-9a77-1e0d8b0a49ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               review  review_score  \\\n",
            "0        No Negative  I will never to stay this hotel           2.9   \n",
            "1    Everything this hotel should not be ranked as...           2.9   \n",
            "2                              everything No Positive           2.5   \n",
            "3    All about room about clean about staff and su...           2.9   \n",
            "4    The room is really small and has nothing to d...           2.9   \n",
            "..                                                ...           ...   \n",
            "95   Staff rude and did not sort things out fast R...           2.9   \n",
            "96   I did n t like anyrhing over there  It is pat...           2.5   \n",
            "97   Everything about it got given keys to someone...           2.5   \n",
            "98   The hotel the zone was not clean the service ...           2.9   \n",
            "99                    The list is so long No Positive           2.9   \n",
            "\n",
            "                                       corrected_text  \n",
            "0         no negative i will never to stay this hotel  \n",
            "1   everything this hotel should not be ranked as ...  \n",
            "2                              everything no positive  \n",
            "3   all about room about clean about staff and sur...  \n",
            "4   ﻿the room is really small and has nothing to d...  \n",
            "..                                                ...  \n",
            "95  staff rude and did not sort things out fast ro...  \n",
            "96  i did it like anything over there it is pathet...  \n",
            "97  everything about it got given keys to someones...  \n",
            "98  ﻿the hotel ﻿the zone was not clean ﻿the servic...  \n",
            "99                   ﻿the list is so long no positive  \n",
            "\n",
            "[100 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(limited_reviews.head)\n",
        "reviews_df = limited_reviews.copy()\n",
        "reviews_df.drop(columns=[\"review\"], inplace=True)\n",
        "print(reviews_df)\n",
        "reviews_df.rename(columns={\"corrected_text\": \"review\"}, inplace=True)\n",
        "print(reviews_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzHj7JDdpmuB",
        "outputId": "7a9becd3-d39d-4643-f5b6-4a557aaa60ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of                                                   review  review_score  \\\n",
            "0           No Negative  I will never to stay this hotel           2.9   \n",
            "1       Everything this hotel should not be ranked as...           2.9   \n",
            "2                                 everything No Positive           2.5   \n",
            "3       All about room about clean about staff and su...           2.9   \n",
            "4       The room is really small and has nothing to d...           2.9   \n",
            "...                                                  ...           ...   \n",
            "27995   Asked for a single room and was admittedly a ...           9.6   \n",
            "27996   Pillows on bed were a little hard   Bed was v...          10.0   \n",
            "27997   There was a problem with hot water in the bat...           9.2   \n",
            "27998   Bit of a shame that you can t drink on the te...           9.6   \n",
            "27999   Nothing  Brilliant can not fault the hotel at...          10.0   \n",
            "\n",
            "                                          corrected_text  \n",
            "0            no negative i will never to stay this hotel  \n",
            "1      everything this hotel should not be ranked as ...  \n",
            "2                                 everything no positive  \n",
            "3      all about room about clean about staff and sur...  \n",
            "4      ﻿the room is really small and has nothing to d...  \n",
            "...                                                  ...  \n",
            "27995  asked for a single room and was admittedly a b...  \n",
            "27996  pillows on bed were a little hard bed was very...  \n",
            "27997  there was a problem with hot water in ﻿the bat...  \n",
            "27998  bit of a shame that you can to drink on ﻿the t...  \n",
            "27999  nothing brilliant can not fault ﻿the hotel at all  \n",
            "\n",
            "[28000 rows x 3 columns]>\n",
            "       review_score                                     corrected_text\n",
            "0               2.9        no negative i will never to stay this hotel\n",
            "1               2.9  everything this hotel should not be ranked as ...\n",
            "2               2.5                             everything no positive\n",
            "3               2.9  all about room about clean about staff and sur...\n",
            "4               2.9  ﻿the room is really small and has nothing to d...\n",
            "...             ...                                                ...\n",
            "27995           9.6  asked for a single room and was admittedly a b...\n",
            "27996          10.0  pillows on bed were a little hard bed was very...\n",
            "27997           9.2  there was a problem with hot water in ﻿the bat...\n",
            "27998           9.6  bit of a shame that you can to drink on ﻿the t...\n",
            "27999          10.0  nothing brilliant can not fault ﻿the hotel at all\n",
            "\n",
            "[28000 rows x 2 columns]\n",
            "       review_score                                             review\n",
            "0               2.9        no negative i will never to stay this hotel\n",
            "1               2.9  everything this hotel should not be ranked as ...\n",
            "2               2.5                             everything no positive\n",
            "3               2.9  all about room about clean about staff and sur...\n",
            "4               2.9  ﻿the room is really small and has nothing to d...\n",
            "...             ...                                                ...\n",
            "27995           9.6  asked for a single room and was admittedly a b...\n",
            "27996          10.0  pillows on bed were a little hard bed was very...\n",
            "27997           9.2  there was a problem with hot water in ﻿the bat...\n",
            "27998           9.6  bit of a shame that you can to drink on ﻿the t...\n",
            "27999          10.0  nothing brilliant can not fault ﻿the hotel at all\n",
            "\n",
            "[28000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWScZGMjXZTi",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "# Cleaning Data - needs to be done before working with data\n",
        "# takes out filler words (unnecessary words like conjunction words (they called it stop words))\n",
        "# makes it all lowercase, gets rid of punctuation\n",
        "# just makes data easier to interpret by the model!\n",
        "\n",
        "reviews_df[\"review\"] = reviews_df[\"review\"].apply(lambda x: x.replace(\"no negative\", \"\").replace(\"no positive\", \"\"))\n",
        "# combining the reviews will make it easier to work through in the model\n",
        "def get_wordnet_pos(pos_tag):\n",
        "  #generates tags, a bridge converting Penn Treebank-style POS tags into WordNet-compatible constants\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "def clean_text(text):\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove stop words\n",
        "    text = [x for x in text if x not in stop_words]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # Any words with no or not before it, get combined together - instead of having \"no\" \"problem\" its \"no problem\"\n",
        "    i = 0\n",
        "    while i < len(text) - 1:\n",
        "      if text[i] == 'no' or text[i] == 'not':\n",
        "        text[i] = text[i] + ' ' + text[i+1]\n",
        "        del text[i+1]\n",
        "      else:\n",
        "        i += 1\n",
        "    return(text)\n",
        "\n",
        "reviews_df[\"review\"] = reviews_df[\"review\"].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkKgq7ZU7Wt5",
        "outputId": "bdeee3cd-55d5-4a87-b572-51c55c23568e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   review_score                                             review\n",
            "0           2.9                               [never, stay, hotel]\n",
            "1           2.9  [everything, hotel, not rank, star, ﻿the, woul...\n",
            "2           2.5                                       [everything]\n",
            "3           2.9  [room, clean, staff, sure, price, bad, room, s...\n",
            "4           2.9  [﻿the, room, really, small, nothing, ﻿the, pic...\n",
            "5           2.5  [service, improve, service, meet, ﻿the, guest,...\n",
            "6           2.9  [﻿the, service, almost, make, want, cry, unfri...\n",
            "7           2.9  [large, patch, mould, ﻿the, bathroom, ceiling,...\n",
            "8           2.5  [﻿the, room, bad, conservation, dirty, ﻿the, r...\n",
            "9           2.9  [room, small, not even, room, walk, around, ro...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36YIwPJGXkWL"
      },
      "outputs": [],
      "source": [
        "# NUMERICALIZATION\n",
        "# Create dictionary that maps words from all the cleaned data to integers - all vocab values assigned are != 0\n",
        "# every word should get a number, NOT starting at 0 but at 1.\n",
        "# in order of appearance?? CHECK THIS\n",
        "\n",
        "#reviews_df = pd.read_csv('cleaned_reviews.csv')\n",
        "\n",
        "cleaned_reviews = reviews_df[\"review\"].tolist()\n",
        "all_text = ' '.join(word for row in cleaned_reviews for word in row)\n",
        "words = [item for sublist in cleaned_reviews for item in sublist]\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "cleaned_reviews_int = []\n",
        "for review in cleaned_reviews:\n",
        "    cleaned_reviews_int.append([vocab_to_int.get(word, 0) for word in review])\n",
        "reviews_df[\"review_clean_int\"] = cleaned_reviews_int"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(reviews_df.head(10))\n",
        "reviews_df_nums = reviews_df.copy()\n",
        "reviews_df = reviews_df_nums.copy()\n",
        "reviews_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WJydV0mQ8Jhc",
        "outputId": "d1af0d15-602f-4b09-ea46-c91e2ea9778a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   review_score                                             review  \\\n",
              "0           2.9                               [never, stay, hotel]   \n",
              "1           2.9  [everything, hotel, not rank, star, ﻿the, woul...   \n",
              "2           2.5                                       [everything]   \n",
              "3           2.9  [room, clean, staff, sure, price, bad, room, s...   \n",
              "4           2.9  [﻿the, room, really, small, nothing, ﻿the, pic...   \n",
              "5           2.5  [service, improve, service, meet, ﻿the, guest,...   \n",
              "6           2.9  [﻿the, service, almost, make, want, cry, unfri...   \n",
              "7           2.9  [large, patch, mould, ﻿the, bathroom, ceiling,...   \n",
              "8           2.5  [﻿the, room, bad, conservation, dirty, ﻿the, r...   \n",
              "9           2.9  [room, small, not even, room, walk, around, ro...   \n",
              "\n",
              "                                    review_clean_int  \n",
              "0                                        [81, 10, 3]  \n",
              "1  [55, 3, 9174, 58, 1, 14, 2020, 1, 197, 1390, 3...  \n",
              "2                                               [55]  \n",
              "3  [2, 12, 4, 514, 40, 31, 2, 555, 52, 799, 52, 2...  \n",
              "4  [1, 2, 38, 9, 21, 1, 277, 1, 454, 114, 62, 906...  \n",
              "5  [18, 810, 18, 622, 1, 118, 2073, 38, 1149, 18,...  \n",
              "6  [1, 18, 303, 42, 35, 2689, 411, 820, 74, 548, ...  \n",
              "7  [198, 2372, 981, 1, 17, 517, 1253, 33, 17, 274...  \n",
              "8         [1, 2, 31, 9175, 61, 1, 2, 185, 185, 4874]  \n",
              "9  [2, 9, 344, 2, 51, 100, 2, 31, 1375, 1304, 714...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18609271-1a79-407a-bea8-b0e3fcd57e70\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_score</th>\n",
              "      <th>review</th>\n",
              "      <th>review_clean_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[never, stay, hotel]</td>\n",
              "      <td>[81, 10, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[everything, hotel, not rank, star, ﻿the, woul...</td>\n",
              "      <td>[55, 3, 9174, 58, 1, 14, 2020, 1, 197, 1390, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.5</td>\n",
              "      <td>[everything]</td>\n",
              "      <td>[55]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[room, clean, staff, sure, price, bad, room, s...</td>\n",
              "      <td>[2, 12, 4, 514, 40, 31, 2, 555, 52, 799, 52, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[﻿the, room, really, small, nothing, ﻿the, pic...</td>\n",
              "      <td>[1, 2, 38, 9, 21, 1, 277, 1, 454, 114, 62, 906...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.5</td>\n",
              "      <td>[service, improve, service, meet, ﻿the, guest,...</td>\n",
              "      <td>[18, 810, 18, 622, 1, 118, 2073, 38, 1149, 18,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[﻿the, service, almost, make, want, cry, unfri...</td>\n",
              "      <td>[1, 18, 303, 42, 35, 2689, 411, 820, 74, 548, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[large, patch, mould, ﻿the, bathroom, ceiling,...</td>\n",
              "      <td>[198, 2372, 981, 1, 17, 517, 1253, 33, 17, 274...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.5</td>\n",
              "      <td>[﻿the, room, bad, conservation, dirty, ﻿the, r...</td>\n",
              "      <td>[1, 2, 31, 9175, 61, 1, 2, 185, 185, 4874]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[room, small, not even, room, walk, around, ro...</td>\n",
              "      <td>[2, 9, 344, 2, 51, 100, 2, 31, 1375, 1304, 714...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18609271-1a79-407a-bea8-b0e3fcd57e70')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18609271-1a79-407a-bea8-b0e3fcd57e70 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18609271-1a79-407a-bea8-b0e3fcd57e70');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80f0130e-c104-4fa3-b80b-91c4d0c5bad6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80f0130e-c104-4fa3-b80b-91c4d0c5bad6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80f0130e-c104-4fa3-b80b-91c4d0c5bad6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reviews_df",
              "summary": "{\n  \"name\": \"reviews_df\",\n  \"rows\": 28000,\n  \"fields\": [\n    {\n      \"column\": \"review_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2940395220145273,\n        \"min\": 2.5,\n        \"max\": 10.0,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          5.6,\n          5.8,\n          3.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_clean_int\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m5wqph8eyDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9b3455bb-bc6e-4dca-891f-97783d50601d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   review_score                                             review  \\\n",
              "0           2.9                               [never, stay, hotel]   \n",
              "1           2.9  [everything, hotel, not rank, star, ﻿the, woul...   \n",
              "2           2.5                                       [everything]   \n",
              "3           2.9  [room, clean, staff, sure, price, bad, room, s...   \n",
              "4           2.9  [﻿the, room, really, small, nothing, ﻿the, pic...   \n",
              "\n",
              "                                    review_clean_int  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0903cc22-e79a-4202-9f82-6bfc50274d02\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_score</th>\n",
              "      <th>review</th>\n",
              "      <th>review_clean_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[never, stay, hotel]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[everything, hotel, not rank, star, ﻿the, woul...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.5</td>\n",
              "      <td>[everything]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[room, clean, staff, sure, price, bad, room, s...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.9</td>\n",
              "      <td>[﻿the, room, really, small, nothing, ﻿the, pic...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0903cc22-e79a-4202-9f82-6bfc50274d02')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0903cc22-e79a-4202-9f82-6bfc50274d02 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0903cc22-e79a-4202-9f82-6bfc50274d02');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7a0dd89d-5931-4f8b-8492-c3af612665fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a0dd89d-5931-4f8b-8492-c3af612665fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7a0dd89d-5931-4f8b-8492-c3af612665fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "reviews_df",
              "summary": "{\n  \"name\": \"reviews_df\",\n  \"rows\": 28000,\n  \"fields\": [\n    {\n      \"column\": \"review_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2940395220145273,\n        \"min\": 2.5,\n        \"max\": 10.0,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          5.6,\n          5.8,\n          3.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"review_clean_int\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Add padding to equalize all the lengths of the reviews in the dataframe - assign values to 0\n",
        "max_len = max(len(row) for row in cleaned_reviews)\n",
        "padded_review_clean_int = []\n",
        "for row in reviews_df[\"review_clean_int\"]:\n",
        "  if len(row) < max_len:\n",
        "    current_len = len(row)\n",
        "    padded_review_clean_int.append([0]*(max_len-current_len) + row)\n",
        "  else:\n",
        "    padded_review_clean_int.append(row)\n",
        "reviews_df[\"review_clean_int\"] = padded_review_clean_int\n",
        "reviews_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "abgMwazykwnE",
        "outputId": "f7f913fa-514a-4d41-ce19-e673df29b562"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for word, index in vocab_to_int.items():\\n    print(f\"{word}: {index}\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#See each word and its number\n",
        "\"\"\"for word, index in vocab_to_int.items():\n",
        "    print(f\"{word}: {index}\")\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2HflUBDTiDv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "87c32e40-9f45-4ed8-e68e-e6bae10de5c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Split the data sets into the training data and the testing data - use training in RNN class\\ntrain_reviews_df, test_reviews_df = train_test_split(reviews_df, test_size=0.2, random_state=42)\\n\\n# Further sort reviews into X and Y variables for training and testing\\nX_train = np.array(train_reviews_df[\"review_clean_int\"])\\nX_test = np.array(test_reviews_df[\"review_clean_int\"])\\nY_train = np.array(train_reviews_df[\"review_score\"])\\nY_test = np.array(test_reviews_df[\"review_score\"])\\n\\n# Turn data into array of floats instead of comma separated values. Needed to do\\n# this because pytorch tensor could not read it when it was comma separated vals\\nX_train = np.array(X_train.tolist(), dtype=np.float16)\\nX_test = np.array(X_test.tolist(), dtype=np.float16)\\nY_train = np.array(Y_train.tolist(), dtype=np.int8)\\nY_test = np.array(Y_test.tolist(), dtype=np.int8)\\n\\n# FOR TESTING ONLY: Split X and Y into even smaller sets of data for sake of\\n# testing without making algorithm take forever to run\\n#X_train = X_train[:10000]\\n#X_test = X_test[:2000]\\n#Y_train = Y_train[:10000]\\n#Y_test = Y_test[:2000]\\nX_train_tensor_init = torch.Tensor(X_train).long()\\nY_train_tensor_init = torch.Tensor(Y_train).reshape(-1, 1)\\nX_test_tensor_init = torch.Tensor(X_test).long()\\nY_test_tensor_init = torch.Tensor(Y_test).reshape(-1, 1)\\n\\ndel X_train\\ndel X_test\\ndel Y_train\\ndel Y_test\\ndel train_reviews_df\\ndel test_reviews_df\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Split the data sets into the training data and the testing data - use training in RNN class\n",
        "train_reviews_df, test_reviews_df = train_test_split(reviews_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further sort reviews into X and Y variables for training and testing\n",
        "X_train = np.array(train_reviews_df[\"review_clean_int\"])\n",
        "X_test = np.array(test_reviews_df[\"review_clean_int\"])\n",
        "Y_train = np.array(train_reviews_df[\"review_score\"])\n",
        "Y_test = np.array(test_reviews_df[\"review_score\"])\n",
        "\n",
        "# Turn data into array of floats instead of comma separated values. Needed to do\n",
        "# this because pytorch tensor could not read it when it was comma separated vals\n",
        "X_train = np.array(X_train.tolist(), dtype=np.float16)\n",
        "X_test = np.array(X_test.tolist(), dtype=np.float16)\n",
        "Y_train = np.array(Y_train.tolist(), dtype=np.int8)\n",
        "Y_test = np.array(Y_test.tolist(), dtype=np.int8)\n",
        "\n",
        "# FOR TESTING ONLY: Split X and Y into even smaller sets of data for sake of\n",
        "# testing without making algorithm take forever to run\n",
        "#X_train = X_train[:10000]\n",
        "#X_test = X_test[:2000]\n",
        "#Y_train = Y_train[:10000]\n",
        "#Y_test = Y_test[:2000]\n",
        "X_train_tensor_init = torch.Tensor(X_train).long()\n",
        "Y_train_tensor_init = torch.Tensor(Y_train).reshape(-1, 1)\n",
        "X_test_tensor_init = torch.Tensor(X_test).long()\n",
        "Y_test_tensor_init = torch.Tensor(Y_test).reshape(-1, 1)\n",
        "\n",
        "del X_train\n",
        "del X_test\n",
        "del Y_train\n",
        "del Y_test\n",
        "del train_reviews_df\n",
        "del test_reviews_df\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Split the data sets into the training data and the testing data - use training in RNN class\n",
        "train_reviews_df, test_reviews_df = train_test_split(reviews_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further sort reviews into X and Y variables for training and testing\n",
        "X_train = np.array(train_reviews_df[\"review_clean_int\"])\n",
        "X_test = np.array(test_reviews_df[\"review_clean_int\"])\n",
        "Y_train = np.array(train_reviews_df[\"review_score\"])\n",
        "Y_test = np.array(test_reviews_df[\"review_score\"])\n",
        "\n",
        "# Turn data into array of floats instead of comma separated values. Needed to do\n",
        "# this because pytorch tensor could not read it when it was comma separated vals\n",
        "X_train = np.array(X_train.tolist(), dtype=np.float16)\n",
        "X_test = np.array(X_test.tolist(), dtype=np.float16)\n",
        "Y_train = np.array(Y_train.tolist(), dtype=np.int8)\n",
        "Y_test = np.array(Y_test.tolist(), dtype=np.int8)\n",
        "\n",
        "X_train_tensor = torch.Tensor(X_train).long()\n",
        "Y_train_tensor = torch.Tensor(Y_train).reshape(-1, 1)\n",
        "X_test_tensor = torch.Tensor(X_test).long()\n",
        "Y_test_tensor = torch.Tensor(Y_test).reshape(-1, 1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
        "batch_size = 100\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "del X_train\n",
        "del X_test\n",
        "del Y_train\n",
        "del Y_test\n",
        "del train_reviews_df\n",
        "del test_reviews_df"
      ],
      "metadata": {
        "id": "dTNRZ6Vf90V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A72rAjdACSGE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "ec66f547-d0f3-4dfa-f56c-e46146329424"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from torch.utils.data import DataLoader, TensorDataset\\n\\nX_train_tensor_short = X_train_tensor_init[:10000]\\nX_test_tensor_short = X_test_tensor_init[:2000]\\nY_train_tensor_short = Y_train_tensor_init[:10000]\\nY_test_tensor_short = Y_test_tensor_init[:2000]\\n\\ntrain_dataset = TensorDataset(X_train_tensor_short, Y_train_tensor_short)\\ntest_dataset = TensorDataset(X_test_tensor_short, Y_test_tensor_short)\\nprint(len(train_dataset))\\nprint(len(test_dataset))\\n\\nbatch_size = 100\\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"\"\"from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "X_train_tensor_short = X_train_tensor_init[:10000]\n",
        "X_test_tensor_short = X_test_tensor_init[:2000]\n",
        "Y_train_tensor_short = Y_train_tensor_init[:10000]\n",
        "Y_test_tensor_short = Y_test_tensor_init[:2000]\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor_short, Y_train_tensor_short)\n",
        "test_dataset = TensorDataset(X_test_tensor_short, Y_test_tensor_short)\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))\n",
        "\n",
        "batch_size = 100\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6Kd10j1hnza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600659ef-0c23-4f5a-d1a6-da8d3a167d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "224"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Second attempt SimpleRNN Model for regression decimal (float) output\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=0.3)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x.long())\n",
        "        rnn_out, hidden = self.rnn(embedded)\n",
        "        last_hidden = rnn_out[:, -1, :]\n",
        "        dropped_out = self.dropout(last_hidden)\n",
        "        output = self.sigmoid(self.fc(dropped_out))\n",
        "        return output\"\"\""
      ],
      "metadata": {
        "id": "LOOwU_kL_nzZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fda78bfc-b4db-4c43-e9ae-29a530991d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import torch\\nimport torch.nn as nn\\nimport torch.optim as optim\\nfrom torch.utils.data import DataLoader\\nimport matplotlib.pyplot as plt\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\\n\\n# Second attempt SimpleRNN Model for regression decimal (float) output\\nclass SimpleRNN(nn.Module):\\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\\n        super(SimpleRNN, self).__init__()\\n        self.hidden_dim = hidden_dim\\n        self.num_layers = num_layers\\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\\n        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=0.3)\\n        self.dropout = nn.Dropout(0.3)\\n        self.fc = nn.Linear(hidden_dim, output_dim)\\n        self.sigmoid = nn.Sigmoid()\\n\\n    def forward(self, x):\\n        embedded = self.embedding(x.long())\\n        rnn_out, hidden = self.rnn(embedded)\\n        last_hidden = rnn_out[:, -1, :]\\n        dropped_out = self.dropout(last_hidden)\\n        output = self.sigmoid(self.fc(dropped_out))\\n        return output'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPTIMIZED Bidirectional LSTM"
      ],
      "metadata": {
        "id": "MJJkTz-PJfTb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define LSTM Model\n",
        "class OptimizedBiLSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(OptimizedBiLSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=0.3)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x.long())\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
        "        last_hidden = lstm_out[:, -1, :]\n",
        "        dropped_out = self.dropout(last_hidden)\n",
        "        output = self.fc(dropped_out)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "num_layers = 3\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "embedding_dim = 100\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "vocab_size = len(vocab) + 1  # Use your vocabulary size\n",
        "model = OptimizedBiLSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# Initialize lists to store training and testing losses\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# Training Loop\n",
        "for t in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    # Training phase\n",
        "    for batch_X, batch_Y in train_loader:\n",
        "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(batch_X)\n",
        "        loss = criterion(predictions, batch_Y.float())\n",
        "        print(f\"Epoch {t+1}, Batch {batch_num}/{len(train_loader)}, Training Loss: {loss:.4f}\")\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_train_loss += loss.item()\n",
        "        batch_num += 1\n",
        "\n",
        "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)  # Store training loss\n",
        "\n",
        "    # Evaluation phase on the test set\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_Y in test_loader:\n",
        "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "            # Ensure indices are valid for the embedding layer\n",
        "            batch_X = torch.clamp(batch_X, 0, vocab_size - 1)\n",
        "\n",
        "            # Ensure shapes match for loss calculation\n",
        "            batch_Y = batch_Y.view(-1, 1)  # Reshape to [batch_size, 1]\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(batch_X)\n",
        "            loss = criterion(predictions, batch_Y.float())\n",
        "            epoch_test_loss += loss.item()\n",
        "\n",
        "    avg_test_loss = epoch_test_loss / len(test_loader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "\n",
        "    # Print epoch progress\n",
        "    print(f\"Epoch {t+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "# Plot Training and Test Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', marker='s')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o_ihWHZS0Rsi",
        "outputId": "27e157d1-dc69-4e94-cb1b-1044d45eb272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 78, Batch 175/224, Training Loss: 0.4804\n",
            "Epoch 78, Batch 176/224, Training Loss: 0.4312\n",
            "Epoch 78, Batch 177/224, Training Loss: 0.7222\n",
            "Epoch 78, Batch 178/224, Training Loss: 0.4722\n",
            "Epoch 78, Batch 179/224, Training Loss: 0.3893\n",
            "Epoch 78, Batch 180/224, Training Loss: 0.8420\n",
            "Epoch 78, Batch 181/224, Training Loss: 0.4445\n",
            "Epoch 78, Batch 182/224, Training Loss: 0.5722\n",
            "Epoch 78, Batch 183/224, Training Loss: 0.3222\n",
            "Epoch 78, Batch 184/224, Training Loss: 0.3570\n",
            "Epoch 78, Batch 185/224, Training Loss: 0.7878\n",
            "Epoch 78, Batch 186/224, Training Loss: 0.6492\n",
            "Epoch 78, Batch 187/224, Training Loss: 0.4337\n",
            "Epoch 78, Batch 188/224, Training Loss: 0.4426\n",
            "Epoch 78, Batch 189/224, Training Loss: 0.4183\n",
            "Epoch 78, Batch 190/224, Training Loss: 0.4671\n",
            "Epoch 78, Batch 191/224, Training Loss: 0.2153\n",
            "Epoch 78, Batch 192/224, Training Loss: 0.3859\n",
            "Epoch 78, Batch 193/224, Training Loss: 0.3434\n",
            "Epoch 78, Batch 194/224, Training Loss: 0.3946\n",
            "Epoch 78, Batch 195/224, Training Loss: 0.3056\n",
            "Epoch 78, Batch 196/224, Training Loss: 0.5980\n",
            "Epoch 78, Batch 197/224, Training Loss: 0.3570\n",
            "Epoch 78, Batch 198/224, Training Loss: 0.6549\n",
            "Epoch 78, Batch 199/224, Training Loss: 0.3087\n",
            "Epoch 78, Batch 200/224, Training Loss: 0.3233\n",
            "Epoch 78, Batch 201/224, Training Loss: 0.4532\n",
            "Epoch 78, Batch 202/224, Training Loss: 0.2633\n",
            "Epoch 78, Batch 203/224, Training Loss: 0.2942\n",
            "Epoch 78, Batch 204/224, Training Loss: 0.4601\n",
            "Epoch 78, Batch 205/224, Training Loss: 0.4662\n",
            "Epoch 78, Batch 206/224, Training Loss: 0.4063\n",
            "Epoch 78, Batch 207/224, Training Loss: 0.2489\n",
            "Epoch 78, Batch 208/224, Training Loss: 0.2935\n",
            "Epoch 78, Batch 209/224, Training Loss: 0.4064\n",
            "Epoch 78, Batch 210/224, Training Loss: 0.8539\n",
            "Epoch 78, Batch 211/224, Training Loss: 0.4587\n",
            "Epoch 78, Batch 212/224, Training Loss: 0.2428\n",
            "Epoch 78, Batch 213/224, Training Loss: 0.6125\n",
            "Epoch 78, Batch 214/224, Training Loss: 0.3691\n",
            "Epoch 78, Batch 215/224, Training Loss: 0.5205\n",
            "Epoch 78, Batch 216/224, Training Loss: 0.7995\n",
            "Epoch 78, Batch 217/224, Training Loss: 0.4108\n",
            "Epoch 78, Batch 218/224, Training Loss: 0.4230\n",
            "Epoch 78, Batch 219/224, Training Loss: 0.6525\n",
            "Epoch 78, Batch 220/224, Training Loss: 0.5543\n",
            "Epoch 78, Batch 221/224, Training Loss: 0.6409\n",
            "Epoch 78, Batch 222/224, Training Loss: 0.3889\n",
            "Epoch 78, Batch 223/224, Training Loss: 0.4233\n",
            "Epoch 78/100, Training Loss: 0.4239, Test Loss: 3.0823\n",
            "Epoch 79, Batch 0/224, Training Loss: 0.2959\n",
            "Epoch 79, Batch 1/224, Training Loss: 0.3766\n",
            "Epoch 79, Batch 2/224, Training Loss: 0.2795\n",
            "Epoch 79, Batch 3/224, Training Loss: 0.3421\n",
            "Epoch 79, Batch 4/224, Training Loss: 0.7540\n",
            "Epoch 79, Batch 5/224, Training Loss: 0.2624\n",
            "Epoch 79, Batch 6/224, Training Loss: 0.5117\n",
            "Epoch 79, Batch 7/224, Training Loss: 0.2946\n",
            "Epoch 79, Batch 8/224, Training Loss: 0.4377\n",
            "Epoch 79, Batch 9/224, Training Loss: 0.2772\n",
            "Epoch 79, Batch 10/224, Training Loss: 0.2428\n",
            "Epoch 79, Batch 11/224, Training Loss: 0.3947\n",
            "Epoch 79, Batch 12/224, Training Loss: 0.4233\n",
            "Epoch 79, Batch 13/224, Training Loss: 0.4029\n",
            "Epoch 79, Batch 14/224, Training Loss: 0.3817\n",
            "Epoch 79, Batch 15/224, Training Loss: 0.4116\n",
            "Epoch 79, Batch 16/224, Training Loss: 0.3475\n",
            "Epoch 79, Batch 17/224, Training Loss: 0.3133\n",
            "Epoch 79, Batch 18/224, Training Loss: 0.4020\n",
            "Epoch 79, Batch 19/224, Training Loss: 0.3592\n",
            "Epoch 79, Batch 20/224, Training Loss: 0.6203\n",
            "Epoch 79, Batch 21/224, Training Loss: 0.2692\n",
            "Epoch 79, Batch 22/224, Training Loss: 0.3296\n",
            "Epoch 79, Batch 23/224, Training Loss: 0.3732\n",
            "Epoch 79, Batch 24/224, Training Loss: 0.5791\n",
            "Epoch 79, Batch 25/224, Training Loss: 0.3138\n",
            "Epoch 79, Batch 26/224, Training Loss: 0.5497\n",
            "Epoch 79, Batch 27/224, Training Loss: 0.5102\n",
            "Epoch 79, Batch 28/224, Training Loss: 0.5263\n",
            "Epoch 79, Batch 29/224, Training Loss: 0.3452\n",
            "Epoch 79, Batch 30/224, Training Loss: 0.7460\n",
            "Epoch 79, Batch 31/224, Training Loss: 0.7527\n",
            "Epoch 79, Batch 32/224, Training Loss: 0.3256\n",
            "Epoch 79, Batch 33/224, Training Loss: 0.5800\n",
            "Epoch 79, Batch 34/224, Training Loss: 0.3943\n",
            "Epoch 79, Batch 35/224, Training Loss: 0.4454\n",
            "Epoch 79, Batch 36/224, Training Loss: 0.4177\n",
            "Epoch 79, Batch 37/224, Training Loss: 0.6448\n",
            "Epoch 79, Batch 38/224, Training Loss: 0.2312\n",
            "Epoch 79, Batch 39/224, Training Loss: 0.3868\n",
            "Epoch 79, Batch 40/224, Training Loss: 0.3060\n",
            "Epoch 79, Batch 41/224, Training Loss: 0.2716\n",
            "Epoch 79, Batch 42/224, Training Loss: 0.4382\n",
            "Epoch 79, Batch 43/224, Training Loss: 0.3279\n",
            "Epoch 79, Batch 44/224, Training Loss: 0.2555\n",
            "Epoch 79, Batch 45/224, Training Loss: 0.3635\n",
            "Epoch 79, Batch 46/224, Training Loss: 0.3755\n",
            "Epoch 79, Batch 47/224, Training Loss: 0.3665\n",
            "Epoch 79, Batch 48/224, Training Loss: 0.3983\n",
            "Epoch 79, Batch 49/224, Training Loss: 0.7959\n",
            "Epoch 79, Batch 50/224, Training Loss: 0.5012\n",
            "Epoch 79, Batch 51/224, Training Loss: 0.3019\n",
            "Epoch 79, Batch 52/224, Training Loss: 0.2940\n",
            "Epoch 79, Batch 53/224, Training Loss: 0.2990\n",
            "Epoch 79, Batch 54/224, Training Loss: 0.5891\n",
            "Epoch 79, Batch 55/224, Training Loss: 0.3487\n",
            "Epoch 79, Batch 56/224, Training Loss: 0.3743\n",
            "Epoch 79, Batch 57/224, Training Loss: 0.3463\n",
            "Epoch 79, Batch 58/224, Training Loss: 0.3575\n",
            "Epoch 79, Batch 59/224, Training Loss: 0.2410\n",
            "Epoch 79, Batch 60/224, Training Loss: 0.3908\n",
            "Epoch 79, Batch 61/224, Training Loss: 0.4257\n",
            "Epoch 79, Batch 62/224, Training Loss: 0.3566\n",
            "Epoch 79, Batch 63/224, Training Loss: 0.3695\n",
            "Epoch 79, Batch 64/224, Training Loss: 0.3841\n",
            "Epoch 79, Batch 65/224, Training Loss: 0.5269\n",
            "Epoch 79, Batch 66/224, Training Loss: 0.3329\n",
            "Epoch 79, Batch 67/224, Training Loss: 0.3031\n",
            "Epoch 79, Batch 68/224, Training Loss: 0.5453\n",
            "Epoch 79, Batch 69/224, Training Loss: 0.3286\n",
            "Epoch 79, Batch 70/224, Training Loss: 0.3275\n",
            "Epoch 79, Batch 71/224, Training Loss: 0.7063\n",
            "Epoch 79, Batch 72/224, Training Loss: 0.2424\n",
            "Epoch 79, Batch 73/224, Training Loss: 0.2706\n",
            "Epoch 79, Batch 74/224, Training Loss: 0.4026\n",
            "Epoch 79, Batch 75/224, Training Loss: 1.1138\n",
            "Epoch 79, Batch 76/224, Training Loss: 0.5258\n",
            "Epoch 79, Batch 77/224, Training Loss: 0.3072\n",
            "Epoch 79, Batch 78/224, Training Loss: 0.4550\n",
            "Epoch 79, Batch 79/224, Training Loss: 0.3024\n",
            "Epoch 79, Batch 80/224, Training Loss: 0.6113\n",
            "Epoch 79, Batch 81/224, Training Loss: 0.3510\n",
            "Epoch 79, Batch 82/224, Training Loss: 0.2957\n",
            "Epoch 79, Batch 83/224, Training Loss: 0.3846\n",
            "Epoch 79, Batch 84/224, Training Loss: 0.2639\n",
            "Epoch 79, Batch 85/224, Training Loss: 0.3445\n",
            "Epoch 79, Batch 86/224, Training Loss: 0.3820\n",
            "Epoch 79, Batch 87/224, Training Loss: 0.9050\n",
            "Epoch 79, Batch 88/224, Training Loss: 0.4349\n",
            "Epoch 79, Batch 89/224, Training Loss: 0.3226\n",
            "Epoch 79, Batch 90/224, Training Loss: 0.2879\n",
            "Epoch 79, Batch 91/224, Training Loss: 0.3676\n",
            "Epoch 79, Batch 92/224, Training Loss: 0.5371\n",
            "Epoch 79, Batch 93/224, Training Loss: 0.3650\n",
            "Epoch 79, Batch 94/224, Training Loss: 0.4908\n",
            "Epoch 79, Batch 95/224, Training Loss: 0.3575\n",
            "Epoch 79, Batch 96/224, Training Loss: 0.3342\n",
            "Epoch 79, Batch 97/224, Training Loss: 0.2631\n",
            "Epoch 79, Batch 98/224, Training Loss: 0.3003\n",
            "Epoch 79, Batch 99/224, Training Loss: 0.4292\n",
            "Epoch 79, Batch 100/224, Training Loss: 0.4427\n",
            "Epoch 79, Batch 101/224, Training Loss: 0.3418\n",
            "Epoch 79, Batch 102/224, Training Loss: 0.2323\n",
            "Epoch 79, Batch 103/224, Training Loss: 0.3448\n",
            "Epoch 79, Batch 104/224, Training Loss: 0.3805\n",
            "Epoch 79, Batch 105/224, Training Loss: 0.5023\n",
            "Epoch 79, Batch 106/224, Training Loss: 0.6434\n",
            "Epoch 79, Batch 107/224, Training Loss: 0.4600\n",
            "Epoch 79, Batch 108/224, Training Loss: 0.4829\n",
            "Epoch 79, Batch 109/224, Training Loss: 0.4330\n",
            "Epoch 79, Batch 110/224, Training Loss: 0.4217\n",
            "Epoch 79, Batch 111/224, Training Loss: 0.3325\n",
            "Epoch 79, Batch 112/224, Training Loss: 0.4028\n",
            "Epoch 79, Batch 113/224, Training Loss: 0.3598\n",
            "Epoch 79, Batch 114/224, Training Loss: 0.3140\n",
            "Epoch 79, Batch 115/224, Training Loss: 0.4529\n",
            "Epoch 79, Batch 116/224, Training Loss: 0.3465\n",
            "Epoch 79, Batch 117/224, Training Loss: 0.3876\n",
            "Epoch 79, Batch 118/224, Training Loss: 0.5790\n",
            "Epoch 79, Batch 119/224, Training Loss: 0.4721\n",
            "Epoch 79, Batch 120/224, Training Loss: 0.3741\n",
            "Epoch 79, Batch 121/224, Training Loss: 0.5899\n",
            "Epoch 79, Batch 122/224, Training Loss: 0.2946\n",
            "Epoch 79, Batch 123/224, Training Loss: 0.3053\n",
            "Epoch 79, Batch 124/224, Training Loss: 0.7503\n",
            "Epoch 79, Batch 125/224, Training Loss: 0.5867\n",
            "Epoch 79, Batch 126/224, Training Loss: 0.5268\n",
            "Epoch 79, Batch 127/224, Training Loss: 0.3315\n",
            "Epoch 79, Batch 128/224, Training Loss: 0.2476\n",
            "Epoch 79, Batch 129/224, Training Loss: 0.3858\n",
            "Epoch 79, Batch 130/224, Training Loss: 0.6268\n",
            "Epoch 79, Batch 131/224, Training Loss: 0.7602\n",
            "Epoch 79, Batch 132/224, Training Loss: 0.2888\n",
            "Epoch 79, Batch 133/224, Training Loss: 0.3260\n",
            "Epoch 79, Batch 134/224, Training Loss: 0.4494\n",
            "Epoch 79, Batch 135/224, Training Loss: 0.3423\n",
            "Epoch 79, Batch 136/224, Training Loss: 0.3326\n",
            "Epoch 79, Batch 137/224, Training Loss: 0.5931\n",
            "Epoch 79, Batch 138/224, Training Loss: 0.2784\n",
            "Epoch 79, Batch 139/224, Training Loss: 0.5272\n",
            "Epoch 79, Batch 140/224, Training Loss: 1.0372\n",
            "Epoch 79, Batch 141/224, Training Loss: 0.8161\n",
            "Epoch 79, Batch 142/224, Training Loss: 0.5620\n",
            "Epoch 79, Batch 143/224, Training Loss: 0.4417\n",
            "Epoch 79, Batch 144/224, Training Loss: 0.2788\n",
            "Epoch 79, Batch 145/224, Training Loss: 0.3681\n",
            "Epoch 79, Batch 146/224, Training Loss: 0.3850\n",
            "Epoch 79, Batch 147/224, Training Loss: 0.4418\n",
            "Epoch 79, Batch 148/224, Training Loss: 0.4232\n",
            "Epoch 79, Batch 149/224, Training Loss: 0.3602\n",
            "Epoch 79, Batch 150/224, Training Loss: 0.3496\n",
            "Epoch 79, Batch 151/224, Training Loss: 0.3274\n",
            "Epoch 79, Batch 152/224, Training Loss: 0.7032\n",
            "Epoch 79, Batch 153/224, Training Loss: 0.6640\n",
            "Epoch 79, Batch 154/224, Training Loss: 0.3723\n",
            "Epoch 79, Batch 155/224, Training Loss: 0.2798\n",
            "Epoch 79, Batch 156/224, Training Loss: 0.4696\n",
            "Epoch 79, Batch 157/224, Training Loss: 0.3273\n",
            "Epoch 79, Batch 158/224, Training Loss: 0.3160\n",
            "Epoch 79, Batch 159/224, Training Loss: 0.4602\n",
            "Epoch 79, Batch 160/224, Training Loss: 0.3042\n",
            "Epoch 79, Batch 161/224, Training Loss: 0.3371\n",
            "Epoch 79, Batch 162/224, Training Loss: 0.4371\n",
            "Epoch 79, Batch 163/224, Training Loss: 0.4722\n",
            "Epoch 79, Batch 164/224, Training Loss: 0.2813\n",
            "Epoch 79, Batch 165/224, Training Loss: 0.9563\n",
            "Epoch 79, Batch 166/224, Training Loss: 0.3537\n",
            "Epoch 79, Batch 167/224, Training Loss: 0.5301\n",
            "Epoch 79, Batch 168/224, Training Loss: 0.4527\n",
            "Epoch 79, Batch 169/224, Training Loss: 0.4400\n",
            "Epoch 79, Batch 170/224, Training Loss: 0.7496\n",
            "Epoch 79, Batch 171/224, Training Loss: 0.5159\n",
            "Epoch 79, Batch 172/224, Training Loss: 0.4660\n",
            "Epoch 79, Batch 173/224, Training Loss: 0.3400\n",
            "Epoch 79, Batch 174/224, Training Loss: 0.3729\n",
            "Epoch 79, Batch 175/224, Training Loss: 0.3031\n",
            "Epoch 79, Batch 176/224, Training Loss: 0.4042\n",
            "Epoch 79, Batch 177/224, Training Loss: 0.4480\n",
            "Epoch 79, Batch 178/224, Training Loss: 0.3251\n",
            "Epoch 79, Batch 179/224, Training Loss: 0.4356\n",
            "Epoch 79, Batch 180/224, Training Loss: 0.4314\n",
            "Epoch 79, Batch 181/224, Training Loss: 0.4041\n",
            "Epoch 79, Batch 182/224, Training Loss: 0.4500\n",
            "Epoch 79, Batch 183/224, Training Loss: 0.4094\n",
            "Epoch 79, Batch 184/224, Training Loss: 0.4130\n",
            "Epoch 79, Batch 185/224, Training Loss: 0.3642\n",
            "Epoch 79, Batch 186/224, Training Loss: 0.3413\n",
            "Epoch 79, Batch 187/224, Training Loss: 0.4596\n",
            "Epoch 79, Batch 188/224, Training Loss: 0.4646\n",
            "Epoch 79, Batch 189/224, Training Loss: 0.3085\n",
            "Epoch 79, Batch 190/224, Training Loss: 0.3458\n",
            "Epoch 79, Batch 191/224, Training Loss: 0.7210\n",
            "Epoch 79, Batch 192/224, Training Loss: 0.4622\n",
            "Epoch 79, Batch 193/224, Training Loss: 0.2970\n",
            "Epoch 79, Batch 194/224, Training Loss: 0.6005\n",
            "Epoch 79, Batch 195/224, Training Loss: 0.4458\n",
            "Epoch 79, Batch 196/224, Training Loss: 0.4314\n",
            "Epoch 79, Batch 197/224, Training Loss: 0.3526\n",
            "Epoch 79, Batch 198/224, Training Loss: 0.3341\n",
            "Epoch 79, Batch 199/224, Training Loss: 0.4723\n",
            "Epoch 79, Batch 200/224, Training Loss: 0.3391\n",
            "Epoch 79, Batch 201/224, Training Loss: 0.3475\n",
            "Epoch 79, Batch 202/224, Training Loss: 0.2902\n",
            "Epoch 79, Batch 203/224, Training Loss: 0.4613\n",
            "Epoch 79, Batch 204/224, Training Loss: 0.4450\n",
            "Epoch 79, Batch 205/224, Training Loss: 0.5475\n",
            "Epoch 79, Batch 206/224, Training Loss: 0.4216\n",
            "Epoch 79, Batch 207/224, Training Loss: 0.4418\n",
            "Epoch 79, Batch 208/224, Training Loss: 0.7634\n",
            "Epoch 79, Batch 209/224, Training Loss: 0.2403\n",
            "Epoch 79, Batch 210/224, Training Loss: 0.4624\n",
            "Epoch 79, Batch 211/224, Training Loss: 0.3910\n",
            "Epoch 79, Batch 212/224, Training Loss: 0.5006\n",
            "Epoch 79, Batch 213/224, Training Loss: 0.4680\n",
            "Epoch 79, Batch 214/224, Training Loss: 0.3789\n",
            "Epoch 79, Batch 215/224, Training Loss: 0.3079\n",
            "Epoch 79, Batch 216/224, Training Loss: 0.5491\n",
            "Epoch 79, Batch 217/224, Training Loss: 0.3524\n",
            "Epoch 79, Batch 218/224, Training Loss: 0.7163\n",
            "Epoch 79, Batch 219/224, Training Loss: 0.5378\n",
            "Epoch 79, Batch 220/224, Training Loss: 0.7361\n",
            "Epoch 79, Batch 221/224, Training Loss: 0.4115\n",
            "Epoch 79, Batch 222/224, Training Loss: 0.4518\n",
            "Epoch 79, Batch 223/224, Training Loss: 0.3663\n",
            "Epoch 79/100, Training Loss: 0.4288, Test Loss: 3.0647\n",
            "Epoch 80, Batch 0/224, Training Loss: 0.3623\n",
            "Epoch 80, Batch 1/224, Training Loss: 0.1975\n",
            "Epoch 80, Batch 2/224, Training Loss: 0.2720\n",
            "Epoch 80, Batch 3/224, Training Loss: 0.2583\n",
            "Epoch 80, Batch 4/224, Training Loss: 0.2387\n",
            "Epoch 80, Batch 5/224, Training Loss: 0.3730\n",
            "Epoch 80, Batch 6/224, Training Loss: 0.3855\n",
            "Epoch 80, Batch 7/224, Training Loss: 0.2389\n",
            "Epoch 80, Batch 8/224, Training Loss: 0.3162\n",
            "Epoch 80, Batch 9/224, Training Loss: 0.2957\n",
            "Epoch 80, Batch 10/224, Training Loss: 0.3783\n",
            "Epoch 80, Batch 11/224, Training Loss: 0.4011\n",
            "Epoch 80, Batch 12/224, Training Loss: 0.6554\n",
            "Epoch 80, Batch 13/224, Training Loss: 0.4596\n",
            "Epoch 80, Batch 14/224, Training Loss: 0.3485\n",
            "Epoch 80, Batch 15/224, Training Loss: 0.5581\n",
            "Epoch 80, Batch 16/224, Training Loss: 0.8578\n",
            "Epoch 80, Batch 17/224, Training Loss: 0.3568\n",
            "Epoch 80, Batch 18/224, Training Loss: 0.4565\n",
            "Epoch 80, Batch 19/224, Training Loss: 0.2507\n",
            "Epoch 80, Batch 20/224, Training Loss: 0.3080\n",
            "Epoch 80, Batch 21/224, Training Loss: 0.4666\n",
            "Epoch 80, Batch 22/224, Training Loss: 0.3508\n",
            "Epoch 80, Batch 23/224, Training Loss: 0.3869\n",
            "Epoch 80, Batch 24/224, Training Loss: 0.3704\n",
            "Epoch 80, Batch 25/224, Training Loss: 0.4633\n",
            "Epoch 80, Batch 26/224, Training Loss: 0.5742\n",
            "Epoch 80, Batch 27/224, Training Loss: 0.5025\n",
            "Epoch 80, Batch 28/224, Training Loss: 0.3213\n",
            "Epoch 80, Batch 29/224, Training Loss: 0.3627\n",
            "Epoch 80, Batch 30/224, Training Loss: 0.3424\n",
            "Epoch 80, Batch 31/224, Training Loss: 0.8148\n",
            "Epoch 80, Batch 32/224, Training Loss: 0.4588\n",
            "Epoch 80, Batch 33/224, Training Loss: 0.3049\n",
            "Epoch 80, Batch 34/224, Training Loss: 0.4863\n",
            "Epoch 80, Batch 35/224, Training Loss: 0.3142\n",
            "Epoch 80, Batch 36/224, Training Loss: 0.4151\n",
            "Epoch 80, Batch 37/224, Training Loss: 0.4941\n",
            "Epoch 80, Batch 38/224, Training Loss: 0.3612\n",
            "Epoch 80, Batch 39/224, Training Loss: 0.3443\n",
            "Epoch 80, Batch 40/224, Training Loss: 0.3966\n",
            "Epoch 80, Batch 41/224, Training Loss: 0.4227\n",
            "Epoch 80, Batch 42/224, Training Loss: 0.5354\n",
            "Epoch 80, Batch 43/224, Training Loss: 0.4560\n",
            "Epoch 80, Batch 44/224, Training Loss: 0.2990\n",
            "Epoch 80, Batch 45/224, Training Loss: 0.3254\n",
            "Epoch 80, Batch 46/224, Training Loss: 0.7356\n",
            "Epoch 80, Batch 47/224, Training Loss: 0.4130\n",
            "Epoch 80, Batch 48/224, Training Loss: 0.3405\n",
            "Epoch 80, Batch 49/224, Training Loss: 0.3908\n",
            "Epoch 80, Batch 50/224, Training Loss: 0.3125\n",
            "Epoch 80, Batch 51/224, Training Loss: 0.3873\n",
            "Epoch 80, Batch 52/224, Training Loss: 0.3528\n",
            "Epoch 80, Batch 53/224, Training Loss: 0.7151\n",
            "Epoch 80, Batch 54/224, Training Loss: 0.4282\n",
            "Epoch 80, Batch 55/224, Training Loss: 0.2688\n",
            "Epoch 80, Batch 56/224, Training Loss: 0.3122\n",
            "Epoch 80, Batch 57/224, Training Loss: 0.2646\n",
            "Epoch 80, Batch 58/224, Training Loss: 0.3121\n",
            "Epoch 80, Batch 59/224, Training Loss: 0.5309\n",
            "Epoch 80, Batch 60/224, Training Loss: 0.4309\n",
            "Epoch 80, Batch 61/224, Training Loss: 0.5334\n",
            "Epoch 80, Batch 62/224, Training Loss: 0.6698\n",
            "Epoch 80, Batch 63/224, Training Loss: 0.7308\n",
            "Epoch 80, Batch 64/224, Training Loss: 0.2394\n",
            "Epoch 80, Batch 65/224, Training Loss: 0.3363\n",
            "Epoch 80, Batch 66/224, Training Loss: 0.3020\n",
            "Epoch 80, Batch 67/224, Training Loss: 0.4101\n",
            "Epoch 80, Batch 68/224, Training Loss: 0.5329\n",
            "Epoch 80, Batch 69/224, Training Loss: 0.3108\n",
            "Epoch 80, Batch 70/224, Training Loss: 0.2433\n",
            "Epoch 80, Batch 71/224, Training Loss: 0.4486\n",
            "Epoch 80, Batch 72/224, Training Loss: 0.3681\n",
            "Epoch 80, Batch 73/224, Training Loss: 0.3830\n",
            "Epoch 80, Batch 74/224, Training Loss: 0.2778\n",
            "Epoch 80, Batch 75/224, Training Loss: 0.6526\n",
            "Epoch 80, Batch 76/224, Training Loss: 0.2809\n",
            "Epoch 80, Batch 77/224, Training Loss: 0.5490\n",
            "Epoch 80, Batch 78/224, Training Loss: 0.2918\n",
            "Epoch 80, Batch 79/224, Training Loss: 0.3118\n",
            "Epoch 80, Batch 80/224, Training Loss: 0.3428\n",
            "Epoch 80, Batch 81/224, Training Loss: 0.4385\n",
            "Epoch 80, Batch 82/224, Training Loss: 0.5311\n",
            "Epoch 80, Batch 83/224, Training Loss: 0.3062\n",
            "Epoch 80, Batch 84/224, Training Loss: 0.3963\n",
            "Epoch 80, Batch 85/224, Training Loss: 0.2658\n",
            "Epoch 80, Batch 86/224, Training Loss: 0.3471\n",
            "Epoch 80, Batch 87/224, Training Loss: 0.4632\n",
            "Epoch 80, Batch 88/224, Training Loss: 0.2668\n",
            "Epoch 80, Batch 89/224, Training Loss: 0.3211\n",
            "Epoch 80, Batch 90/224, Training Loss: 0.3944\n",
            "Epoch 80, Batch 91/224, Training Loss: 0.5081\n",
            "Epoch 80, Batch 92/224, Training Loss: 0.6008\n",
            "Epoch 80, Batch 93/224, Training Loss: 0.3060\n",
            "Epoch 80, Batch 94/224, Training Loss: 0.4152\n",
            "Epoch 80, Batch 95/224, Training Loss: 0.3977\n",
            "Epoch 80, Batch 96/224, Training Loss: 0.4206\n",
            "Epoch 80, Batch 97/224, Training Loss: 0.3198\n",
            "Epoch 80, Batch 98/224, Training Loss: 0.4450\n",
            "Epoch 80, Batch 99/224, Training Loss: 0.2765\n",
            "Epoch 80, Batch 100/224, Training Loss: 0.3698\n",
            "Epoch 80, Batch 101/224, Training Loss: 0.3628\n",
            "Epoch 80, Batch 102/224, Training Loss: 0.3095\n",
            "Epoch 80, Batch 103/224, Training Loss: 0.7062\n",
            "Epoch 80, Batch 104/224, Training Loss: 0.8157\n",
            "Epoch 80, Batch 105/224, Training Loss: 0.4236\n",
            "Epoch 80, Batch 106/224, Training Loss: 0.2891\n",
            "Epoch 80, Batch 107/224, Training Loss: 0.3082\n",
            "Epoch 80, Batch 108/224, Training Loss: 0.5005\n",
            "Epoch 80, Batch 109/224, Training Loss: 0.5023\n",
            "Epoch 80, Batch 110/224, Training Loss: 0.2800\n",
            "Epoch 80, Batch 111/224, Training Loss: 0.3731\n",
            "Epoch 80, Batch 112/224, Training Loss: 0.5131\n",
            "Epoch 80, Batch 113/224, Training Loss: 0.3029\n",
            "Epoch 80, Batch 114/224, Training Loss: 0.3710\n",
            "Epoch 80, Batch 115/224, Training Loss: 0.4158\n",
            "Epoch 80, Batch 116/224, Training Loss: 0.4505\n",
            "Epoch 80, Batch 117/224, Training Loss: 0.3236\n",
            "Epoch 80, Batch 118/224, Training Loss: 0.3910\n",
            "Epoch 80, Batch 119/224, Training Loss: 0.3810\n",
            "Epoch 80, Batch 120/224, Training Loss: 0.5429\n",
            "Epoch 80, Batch 121/224, Training Loss: 0.3174\n",
            "Epoch 80, Batch 122/224, Training Loss: 0.6547\n",
            "Epoch 80, Batch 123/224, Training Loss: 0.2991\n",
            "Epoch 80, Batch 124/224, Training Loss: 0.3269\n",
            "Epoch 80, Batch 125/224, Training Loss: 0.3189\n",
            "Epoch 80, Batch 126/224, Training Loss: 0.4826\n",
            "Epoch 80, Batch 127/224, Training Loss: 0.3013\n",
            "Epoch 80, Batch 128/224, Training Loss: 0.4231\n",
            "Epoch 80, Batch 129/224, Training Loss: 0.3125\n",
            "Epoch 80, Batch 130/224, Training Loss: 0.7210\n",
            "Epoch 80, Batch 131/224, Training Loss: 0.3546\n",
            "Epoch 80, Batch 132/224, Training Loss: 0.3032\n",
            "Epoch 80, Batch 133/224, Training Loss: 0.4014\n",
            "Epoch 80, Batch 134/224, Training Loss: 0.3108\n",
            "Epoch 80, Batch 135/224, Training Loss: 0.3657\n",
            "Epoch 80, Batch 136/224, Training Loss: 0.3223\n",
            "Epoch 80, Batch 137/224, Training Loss: 0.2794\n",
            "Epoch 80, Batch 138/224, Training Loss: 0.3961\n",
            "Epoch 80, Batch 139/224, Training Loss: 0.6306\n",
            "Epoch 80, Batch 140/224, Training Loss: 0.8431\n",
            "Epoch 80, Batch 141/224, Training Loss: 0.5196\n",
            "Epoch 80, Batch 142/224, Training Loss: 0.6800\n",
            "Epoch 80, Batch 143/224, Training Loss: 0.3387\n",
            "Epoch 80, Batch 144/224, Training Loss: 0.3516\n",
            "Epoch 80, Batch 145/224, Training Loss: 0.3425\n",
            "Epoch 80, Batch 146/224, Training Loss: 0.4075\n",
            "Epoch 80, Batch 147/224, Training Loss: 0.3321\n",
            "Epoch 80, Batch 148/224, Training Loss: 0.5010\n",
            "Epoch 80, Batch 149/224, Training Loss: 0.3690\n",
            "Epoch 80, Batch 150/224, Training Loss: 0.6724\n",
            "Epoch 80, Batch 151/224, Training Loss: 0.4457\n",
            "Epoch 80, Batch 152/224, Training Loss: 0.5572\n",
            "Epoch 80, Batch 153/224, Training Loss: 0.4145\n",
            "Epoch 80, Batch 154/224, Training Loss: 0.4035\n",
            "Epoch 80, Batch 155/224, Training Loss: 0.4284\n",
            "Epoch 80, Batch 156/224, Training Loss: 0.3895\n",
            "Epoch 80, Batch 157/224, Training Loss: 0.4771\n",
            "Epoch 80, Batch 158/224, Training Loss: 0.3464\n",
            "Epoch 80, Batch 159/224, Training Loss: 0.4251\n",
            "Epoch 80, Batch 160/224, Training Loss: 0.6302\n",
            "Epoch 80, Batch 161/224, Training Loss: 0.3618\n",
            "Epoch 80, Batch 162/224, Training Loss: 0.7863\n",
            "Epoch 80, Batch 163/224, Training Loss: 0.5626\n",
            "Epoch 80, Batch 164/224, Training Loss: 0.4366\n",
            "Epoch 80, Batch 165/224, Training Loss: 0.4268\n",
            "Epoch 80, Batch 166/224, Training Loss: 0.4187\n",
            "Epoch 80, Batch 167/224, Training Loss: 0.3790\n",
            "Epoch 80, Batch 168/224, Training Loss: 0.2817\n",
            "Epoch 80, Batch 169/224, Training Loss: 0.2982\n",
            "Epoch 80, Batch 170/224, Training Loss: 0.3038\n",
            "Epoch 80, Batch 171/224, Training Loss: 0.4751\n",
            "Epoch 80, Batch 172/224, Training Loss: 0.4423\n",
            "Epoch 80, Batch 173/224, Training Loss: 0.6375\n",
            "Epoch 80, Batch 174/224, Training Loss: 0.4729\n",
            "Epoch 80, Batch 175/224, Training Loss: 0.2615\n",
            "Epoch 80, Batch 176/224, Training Loss: 0.3785\n",
            "Epoch 80, Batch 177/224, Training Loss: 0.4018\n",
            "Epoch 80, Batch 178/224, Training Loss: 0.3451\n",
            "Epoch 80, Batch 179/224, Training Loss: 0.2657\n",
            "Epoch 80, Batch 180/224, Training Loss: 0.2685\n",
            "Epoch 80, Batch 181/224, Training Loss: 0.4179\n",
            "Epoch 80, Batch 182/224, Training Loss: 0.3055\n",
            "Epoch 80, Batch 183/224, Training Loss: 0.4343\n",
            "Epoch 80, Batch 184/224, Training Loss: 0.5491\n",
            "Epoch 80, Batch 185/224, Training Loss: 0.6521\n",
            "Epoch 80, Batch 186/224, Training Loss: 0.2167\n",
            "Epoch 80, Batch 187/224, Training Loss: 0.4361\n",
            "Epoch 80, Batch 188/224, Training Loss: 0.3724\n",
            "Epoch 80, Batch 189/224, Training Loss: 0.2988\n",
            "Epoch 80, Batch 190/224, Training Loss: 0.5168\n",
            "Epoch 80, Batch 191/224, Training Loss: 0.3796\n",
            "Epoch 80, Batch 192/224, Training Loss: 0.3943\n",
            "Epoch 80, Batch 193/224, Training Loss: 0.6319\n",
            "Epoch 80, Batch 194/224, Training Loss: 0.4428\n",
            "Epoch 80, Batch 195/224, Training Loss: 0.3285\n",
            "Epoch 80, Batch 196/224, Training Loss: 0.2057\n",
            "Epoch 80, Batch 197/224, Training Loss: 0.4782\n",
            "Epoch 80, Batch 198/224, Training Loss: 0.3031\n",
            "Epoch 80, Batch 199/224, Training Loss: 0.2874\n",
            "Epoch 80, Batch 200/224, Training Loss: 0.3376\n",
            "Epoch 80, Batch 201/224, Training Loss: 0.3657\n",
            "Epoch 80, Batch 202/224, Training Loss: 0.4892\n",
            "Epoch 80, Batch 203/224, Training Loss: 0.3510\n",
            "Epoch 80, Batch 204/224, Training Loss: 0.4829\n",
            "Epoch 80, Batch 205/224, Training Loss: 0.4690\n",
            "Epoch 80, Batch 206/224, Training Loss: 0.4858\n",
            "Epoch 80, Batch 207/224, Training Loss: 0.3720\n",
            "Epoch 80, Batch 208/224, Training Loss: 0.4220\n",
            "Epoch 80, Batch 209/224, Training Loss: 0.6171\n",
            "Epoch 80, Batch 210/224, Training Loss: 0.3361\n",
            "Epoch 80, Batch 211/224, Training Loss: 0.4335\n",
            "Epoch 80, Batch 212/224, Training Loss: 0.3775\n",
            "Epoch 80, Batch 213/224, Training Loss: 0.4591\n",
            "Epoch 80, Batch 214/224, Training Loss: 0.3674\n",
            "Epoch 80, Batch 215/224, Training Loss: 0.3565\n",
            "Epoch 80, Batch 216/224, Training Loss: 0.5886\n",
            "Epoch 80, Batch 217/224, Training Loss: 0.3959\n",
            "Epoch 80, Batch 218/224, Training Loss: 0.9206\n",
            "Epoch 80, Batch 219/224, Training Loss: 0.3884\n",
            "Epoch 80, Batch 220/224, Training Loss: 0.4552\n",
            "Epoch 80, Batch 221/224, Training Loss: 0.4119\n",
            "Epoch 80, Batch 222/224, Training Loss: 0.6100\n",
            "Epoch 80, Batch 223/224, Training Loss: 0.5400\n",
            "Epoch 80/100, Training Loss: 0.4178, Test Loss: 3.0985\n",
            "Epoch 81, Batch 0/224, Training Loss: 0.4121\n",
            "Epoch 81, Batch 1/224, Training Loss: 0.4704\n",
            "Epoch 81, Batch 2/224, Training Loss: 0.3758\n",
            "Epoch 81, Batch 3/224, Training Loss: 0.6026\n",
            "Epoch 81, Batch 4/224, Training Loss: 0.5094\n",
            "Epoch 81, Batch 5/224, Training Loss: 0.3957\n",
            "Epoch 81, Batch 6/224, Training Loss: 0.3842\n",
            "Epoch 81, Batch 7/224, Training Loss: 0.4098\n",
            "Epoch 81, Batch 8/224, Training Loss: 0.4960\n",
            "Epoch 81, Batch 9/224, Training Loss: 0.3918\n",
            "Epoch 81, Batch 10/224, Training Loss: 0.3718\n",
            "Epoch 81, Batch 11/224, Training Loss: 0.2916\n",
            "Epoch 81, Batch 12/224, Training Loss: 0.3144\n",
            "Epoch 81, Batch 13/224, Training Loss: 0.4282\n",
            "Epoch 81, Batch 14/224, Training Loss: 0.2656\n",
            "Epoch 81, Batch 15/224, Training Loss: 0.6171\n",
            "Epoch 81, Batch 16/224, Training Loss: 0.3265\n",
            "Epoch 81, Batch 17/224, Training Loss: 0.4047\n",
            "Epoch 81, Batch 18/224, Training Loss: 0.2504\n",
            "Epoch 81, Batch 19/224, Training Loss: 0.3320\n",
            "Epoch 81, Batch 20/224, Training Loss: 0.2925\n",
            "Epoch 81, Batch 21/224, Training Loss: 0.2881\n",
            "Epoch 81, Batch 22/224, Training Loss: 0.4183\n",
            "Epoch 81, Batch 23/224, Training Loss: 0.3955\n",
            "Epoch 81, Batch 24/224, Training Loss: 0.4256\n",
            "Epoch 81, Batch 25/224, Training Loss: 0.3755\n",
            "Epoch 81, Batch 26/224, Training Loss: 0.5375\n",
            "Epoch 81, Batch 27/224, Training Loss: 0.3238\n",
            "Epoch 81, Batch 28/224, Training Loss: 0.4269\n",
            "Epoch 81, Batch 29/224, Training Loss: 0.3355\n",
            "Epoch 81, Batch 30/224, Training Loss: 0.4889\n",
            "Epoch 81, Batch 31/224, Training Loss: 0.3788\n",
            "Epoch 81, Batch 32/224, Training Loss: 0.4131\n",
            "Epoch 81, Batch 33/224, Training Loss: 0.2967\n",
            "Epoch 81, Batch 34/224, Training Loss: 0.3561\n",
            "Epoch 81, Batch 35/224, Training Loss: 0.2719\n",
            "Epoch 81, Batch 36/224, Training Loss: 0.3482\n",
            "Epoch 81, Batch 37/224, Training Loss: 0.5412\n",
            "Epoch 81, Batch 38/224, Training Loss: 0.2632\n",
            "Epoch 81, Batch 39/224, Training Loss: 0.4000\n",
            "Epoch 81, Batch 40/224, Training Loss: 0.3668\n",
            "Epoch 81, Batch 41/224, Training Loss: 0.3943\n",
            "Epoch 81, Batch 42/224, Training Loss: 0.2914\n",
            "Epoch 81, Batch 43/224, Training Loss: 0.4822\n",
            "Epoch 81, Batch 44/224, Training Loss: 0.3565\n",
            "Epoch 81, Batch 45/224, Training Loss: 0.3626\n",
            "Epoch 81, Batch 46/224, Training Loss: 0.4306\n",
            "Epoch 81, Batch 47/224, Training Loss: 0.3251\n",
            "Epoch 81, Batch 48/224, Training Loss: 0.4984\n",
            "Epoch 81, Batch 49/224, Training Loss: 0.3860\n",
            "Epoch 81, Batch 50/224, Training Loss: 0.2906\n",
            "Epoch 81, Batch 51/224, Training Loss: 0.3279\n",
            "Epoch 81, Batch 52/224, Training Loss: 0.3416\n",
            "Epoch 81, Batch 53/224, Training Loss: 0.2936\n",
            "Epoch 81, Batch 54/224, Training Loss: 0.3748\n",
            "Epoch 81, Batch 55/224, Training Loss: 0.5122\n",
            "Epoch 81, Batch 56/224, Training Loss: 0.3478\n",
            "Epoch 81, Batch 57/224, Training Loss: 0.4803\n",
            "Epoch 81, Batch 58/224, Training Loss: 0.3603\n",
            "Epoch 81, Batch 59/224, Training Loss: 0.7457\n",
            "Epoch 81, Batch 60/224, Training Loss: 0.4950\n",
            "Epoch 81, Batch 61/224, Training Loss: 0.1972\n",
            "Epoch 81, Batch 62/224, Training Loss: 0.7182\n",
            "Epoch 81, Batch 63/224, Training Loss: 0.2890\n",
            "Epoch 81, Batch 64/224, Training Loss: 0.4665\n",
            "Epoch 81, Batch 65/224, Training Loss: 0.4942\n",
            "Epoch 81, Batch 66/224, Training Loss: 0.4825\n",
            "Epoch 81, Batch 67/224, Training Loss: 0.3713\n",
            "Epoch 81, Batch 68/224, Training Loss: 0.2440\n",
            "Epoch 81, Batch 69/224, Training Loss: 0.4855\n",
            "Epoch 81, Batch 70/224, Training Loss: 0.2938\n",
            "Epoch 81, Batch 71/224, Training Loss: 0.4782\n",
            "Epoch 81, Batch 72/224, Training Loss: 0.5014\n",
            "Epoch 81, Batch 73/224, Training Loss: 0.4041\n",
            "Epoch 81, Batch 74/224, Training Loss: 0.5535\n",
            "Epoch 81, Batch 75/224, Training Loss: 0.4168\n",
            "Epoch 81, Batch 76/224, Training Loss: 0.3596\n",
            "Epoch 81, Batch 77/224, Training Loss: 0.5762\n",
            "Epoch 81, Batch 78/224, Training Loss: 0.6645\n",
            "Epoch 81, Batch 79/224, Training Loss: 0.4198\n",
            "Epoch 81, Batch 80/224, Training Loss: 0.4964\n",
            "Epoch 81, Batch 81/224, Training Loss: 0.6634\n",
            "Epoch 81, Batch 82/224, Training Loss: 0.4004\n",
            "Epoch 81, Batch 83/224, Training Loss: 0.7597\n",
            "Epoch 81, Batch 84/224, Training Loss: 0.3048\n",
            "Epoch 81, Batch 85/224, Training Loss: 0.4446\n",
            "Epoch 81, Batch 86/224, Training Loss: 0.3179\n",
            "Epoch 81, Batch 87/224, Training Loss: 0.2984\n",
            "Epoch 81, Batch 88/224, Training Loss: 0.3200\n",
            "Epoch 81, Batch 89/224, Training Loss: 0.2740\n",
            "Epoch 81, Batch 90/224, Training Loss: 0.3060\n",
            "Epoch 81, Batch 91/224, Training Loss: 0.3720\n",
            "Epoch 81, Batch 92/224, Training Loss: 0.3391\n",
            "Epoch 81, Batch 93/224, Training Loss: 0.3243\n",
            "Epoch 81, Batch 94/224, Training Loss: 0.2815\n",
            "Epoch 81, Batch 95/224, Training Loss: 0.4586\n",
            "Epoch 81, Batch 96/224, Training Loss: 0.3751\n",
            "Epoch 81, Batch 97/224, Training Loss: 0.3201\n",
            "Epoch 81, Batch 98/224, Training Loss: 0.4395\n",
            "Epoch 81, Batch 99/224, Training Loss: 0.4368\n",
            "Epoch 81, Batch 100/224, Training Loss: 0.4088\n",
            "Epoch 81, Batch 101/224, Training Loss: 0.3971\n",
            "Epoch 81, Batch 102/224, Training Loss: 0.4138\n",
            "Epoch 81, Batch 103/224, Training Loss: 0.3312\n",
            "Epoch 81, Batch 104/224, Training Loss: 0.3142\n",
            "Epoch 81, Batch 105/224, Training Loss: 0.3454\n",
            "Epoch 81, Batch 106/224, Training Loss: 0.4282\n",
            "Epoch 81, Batch 107/224, Training Loss: 0.5370\n",
            "Epoch 81, Batch 108/224, Training Loss: 0.4331\n",
            "Epoch 81, Batch 109/224, Training Loss: 0.3719\n",
            "Epoch 81, Batch 110/224, Training Loss: 0.2930\n",
            "Epoch 81, Batch 111/224, Training Loss: 0.3054\n",
            "Epoch 81, Batch 112/224, Training Loss: 0.9409\n",
            "Epoch 81, Batch 113/224, Training Loss: 0.5430\n",
            "Epoch 81, Batch 114/224, Training Loss: 0.4282\n",
            "Epoch 81, Batch 115/224, Training Loss: 0.2279\n",
            "Epoch 81, Batch 116/224, Training Loss: 0.4364\n",
            "Epoch 81, Batch 117/224, Training Loss: 0.5138\n",
            "Epoch 81, Batch 118/224, Training Loss: 0.2719\n",
            "Epoch 81, Batch 119/224, Training Loss: 0.2906\n",
            "Epoch 81, Batch 120/224, Training Loss: 0.5564\n",
            "Epoch 81, Batch 121/224, Training Loss: 0.3840\n",
            "Epoch 81, Batch 122/224, Training Loss: 0.3271\n",
            "Epoch 81, Batch 123/224, Training Loss: 0.5766\n",
            "Epoch 81, Batch 124/224, Training Loss: 0.2814\n",
            "Epoch 81, Batch 125/224, Training Loss: 0.7182\n",
            "Epoch 81, Batch 126/224, Training Loss: 0.3620\n",
            "Epoch 81, Batch 127/224, Training Loss: 0.3714\n",
            "Epoch 81, Batch 128/224, Training Loss: 0.4247\n",
            "Epoch 81, Batch 129/224, Training Loss: 0.3122\n",
            "Epoch 81, Batch 130/224, Training Loss: 0.2971\n",
            "Epoch 81, Batch 131/224, Training Loss: 0.4261\n",
            "Epoch 81, Batch 132/224, Training Loss: 0.4173\n",
            "Epoch 81, Batch 133/224, Training Loss: 0.6905\n",
            "Epoch 81, Batch 134/224, Training Loss: 0.3197\n",
            "Epoch 81, Batch 135/224, Training Loss: 0.9101\n",
            "Epoch 81, Batch 136/224, Training Loss: 0.3964\n",
            "Epoch 81, Batch 137/224, Training Loss: 0.4907\n",
            "Epoch 81, Batch 138/224, Training Loss: 0.3662\n",
            "Epoch 81, Batch 139/224, Training Loss: 0.3112\n",
            "Epoch 81, Batch 140/224, Training Loss: 0.4386\n",
            "Epoch 81, Batch 141/224, Training Loss: 0.4580\n",
            "Epoch 81, Batch 142/224, Training Loss: 0.5097\n",
            "Epoch 81, Batch 143/224, Training Loss: 0.4157\n",
            "Epoch 81, Batch 144/224, Training Loss: 0.5817\n",
            "Epoch 81, Batch 145/224, Training Loss: 0.5567\n",
            "Epoch 81, Batch 146/224, Training Loss: 0.2781\n",
            "Epoch 81, Batch 147/224, Training Loss: 0.4992\n",
            "Epoch 81, Batch 148/224, Training Loss: 0.3899\n",
            "Epoch 81, Batch 149/224, Training Loss: 0.4443\n",
            "Epoch 81, Batch 150/224, Training Loss: 0.7047\n",
            "Epoch 81, Batch 151/224, Training Loss: 0.3063\n",
            "Epoch 81, Batch 152/224, Training Loss: 0.3750\n",
            "Epoch 81, Batch 153/224, Training Loss: 0.5650\n",
            "Epoch 81, Batch 154/224, Training Loss: 0.3467\n",
            "Epoch 81, Batch 155/224, Training Loss: 0.4404\n",
            "Epoch 81, Batch 156/224, Training Loss: 0.4195\n",
            "Epoch 81, Batch 157/224, Training Loss: 0.2689\n",
            "Epoch 81, Batch 158/224, Training Loss: 0.4765\n",
            "Epoch 81, Batch 159/224, Training Loss: 0.6984\n",
            "Epoch 81, Batch 160/224, Training Loss: 0.4277\n",
            "Epoch 81, Batch 161/224, Training Loss: 0.4966\n",
            "Epoch 81, Batch 162/224, Training Loss: 0.3743\n",
            "Epoch 81, Batch 163/224, Training Loss: 0.3284\n",
            "Epoch 81, Batch 164/224, Training Loss: 0.3686\n",
            "Epoch 81, Batch 165/224, Training Loss: 0.3283\n",
            "Epoch 81, Batch 166/224, Training Loss: 0.3347\n",
            "Epoch 81, Batch 167/224, Training Loss: 0.3390\n",
            "Epoch 81, Batch 168/224, Training Loss: 0.3663\n",
            "Epoch 81, Batch 169/224, Training Loss: 0.3968\n",
            "Epoch 81, Batch 170/224, Training Loss: 0.4129\n",
            "Epoch 81, Batch 171/224, Training Loss: 0.3823\n",
            "Epoch 81, Batch 172/224, Training Loss: 0.3123\n",
            "Epoch 81, Batch 173/224, Training Loss: 0.2741\n",
            "Epoch 81, Batch 174/224, Training Loss: 0.4009\n",
            "Epoch 81, Batch 175/224, Training Loss: 0.3816\n",
            "Epoch 81, Batch 176/224, Training Loss: 0.2542\n",
            "Epoch 81, Batch 177/224, Training Loss: 0.8082\n",
            "Epoch 81, Batch 178/224, Training Loss: 0.3719\n",
            "Epoch 81, Batch 179/224, Training Loss: 0.4936\n",
            "Epoch 81, Batch 180/224, Training Loss: 0.4100\n",
            "Epoch 81, Batch 181/224, Training Loss: 0.5994\n",
            "Epoch 81, Batch 182/224, Training Loss: 0.3288\n",
            "Epoch 81, Batch 183/224, Training Loss: 0.3201\n",
            "Epoch 81, Batch 184/224, Training Loss: 0.4691\n",
            "Epoch 81, Batch 185/224, Training Loss: 0.3686\n",
            "Epoch 81, Batch 186/224, Training Loss: 0.5204\n",
            "Epoch 81, Batch 187/224, Training Loss: 0.5194\n",
            "Epoch 81, Batch 188/224, Training Loss: 0.4331\n",
            "Epoch 81, Batch 189/224, Training Loss: 0.4374\n",
            "Epoch 81, Batch 190/224, Training Loss: 0.3712\n",
            "Epoch 81, Batch 191/224, Training Loss: 0.3618\n",
            "Epoch 81, Batch 192/224, Training Loss: 0.3271\n",
            "Epoch 81, Batch 193/224, Training Loss: 0.3722\n",
            "Epoch 81, Batch 194/224, Training Loss: 1.0619\n",
            "Epoch 81, Batch 195/224, Training Loss: 0.5227\n",
            "Epoch 81, Batch 196/224, Training Loss: 0.3094\n",
            "Epoch 81, Batch 197/224, Training Loss: 0.4292\n",
            "Epoch 81, Batch 198/224, Training Loss: 0.4605\n",
            "Epoch 81, Batch 199/224, Training Loss: 0.3608\n",
            "Epoch 81, Batch 200/224, Training Loss: 0.3785\n",
            "Epoch 81, Batch 201/224, Training Loss: 0.2759\n",
            "Epoch 81, Batch 202/224, Training Loss: 0.3851\n",
            "Epoch 81, Batch 203/224, Training Loss: 0.2858\n",
            "Epoch 81, Batch 204/224, Training Loss: 0.3451\n",
            "Epoch 81, Batch 205/224, Training Loss: 0.3065\n",
            "Epoch 81, Batch 206/224, Training Loss: 1.0985\n",
            "Epoch 81, Batch 207/224, Training Loss: 0.5253\n",
            "Epoch 81, Batch 208/224, Training Loss: 0.3168\n",
            "Epoch 81, Batch 209/224, Training Loss: 0.3347\n",
            "Epoch 81, Batch 210/224, Training Loss: 0.3457\n",
            "Epoch 81, Batch 211/224, Training Loss: 0.3779\n",
            "Epoch 81, Batch 212/224, Training Loss: 0.2710\n",
            "Epoch 81, Batch 213/224, Training Loss: 0.6185\n",
            "Epoch 81, Batch 214/224, Training Loss: 0.5869\n",
            "Epoch 81, Batch 215/224, Training Loss: 0.5350\n",
            "Epoch 81, Batch 216/224, Training Loss: 0.5041\n",
            "Epoch 81, Batch 217/224, Training Loss: 0.3920\n",
            "Epoch 81, Batch 218/224, Training Loss: 0.2991\n",
            "Epoch 81, Batch 219/224, Training Loss: 0.6766\n",
            "Epoch 81, Batch 220/224, Training Loss: 0.4162\n",
            "Epoch 81, Batch 221/224, Training Loss: 0.4489\n",
            "Epoch 81, Batch 222/224, Training Loss: 0.4502\n",
            "Epoch 81, Batch 223/224, Training Loss: 0.4116\n",
            "Epoch 81/100, Training Loss: 0.4206, Test Loss: 3.0194\n",
            "Epoch 82, Batch 0/224, Training Loss: 0.3280\n",
            "Epoch 82, Batch 1/224, Training Loss: 0.3759\n",
            "Epoch 82, Batch 2/224, Training Loss: 0.2226\n",
            "Epoch 82, Batch 3/224, Training Loss: 0.3023\n",
            "Epoch 82, Batch 4/224, Training Loss: 0.2455\n",
            "Epoch 82, Batch 5/224, Training Loss: 0.2305\n",
            "Epoch 82, Batch 6/224, Training Loss: 0.4062\n",
            "Epoch 82, Batch 7/224, Training Loss: 0.2345\n",
            "Epoch 82, Batch 8/224, Training Loss: 0.3424\n",
            "Epoch 82, Batch 9/224, Training Loss: 0.2623\n",
            "Epoch 82, Batch 10/224, Training Loss: 0.2792\n",
            "Epoch 82, Batch 11/224, Training Loss: 0.3141\n",
            "Epoch 82, Batch 12/224, Training Loss: 0.2882\n",
            "Epoch 82, Batch 13/224, Training Loss: 0.3589\n",
            "Epoch 82, Batch 14/224, Training Loss: 0.6150\n",
            "Epoch 82, Batch 15/224, Training Loss: 0.4465\n",
            "Epoch 82, Batch 16/224, Training Loss: 0.3573\n",
            "Epoch 82, Batch 17/224, Training Loss: 0.2865\n",
            "Epoch 82, Batch 18/224, Training Loss: 0.6914\n",
            "Epoch 82, Batch 19/224, Training Loss: 0.4505\n",
            "Epoch 82, Batch 20/224, Training Loss: 0.3282\n",
            "Epoch 82, Batch 21/224, Training Loss: 0.3817\n",
            "Epoch 82, Batch 22/224, Training Loss: 0.3554\n",
            "Epoch 82, Batch 23/224, Training Loss: 0.3590\n",
            "Epoch 82, Batch 24/224, Training Loss: 0.3455\n",
            "Epoch 82, Batch 25/224, Training Loss: 0.2856\n",
            "Epoch 82, Batch 26/224, Training Loss: 0.3830\n",
            "Epoch 82, Batch 27/224, Training Loss: 0.2784\n",
            "Epoch 82, Batch 28/224, Training Loss: 0.3833\n",
            "Epoch 82, Batch 29/224, Training Loss: 0.4144\n",
            "Epoch 82, Batch 30/224, Training Loss: 0.2666\n",
            "Epoch 82, Batch 31/224, Training Loss: 0.6369\n",
            "Epoch 82, Batch 32/224, Training Loss: 0.3744\n",
            "Epoch 82, Batch 33/224, Training Loss: 0.3770\n",
            "Epoch 82, Batch 34/224, Training Loss: 0.3630\n",
            "Epoch 82, Batch 35/224, Training Loss: 0.6664\n",
            "Epoch 82, Batch 36/224, Training Loss: 0.3941\n",
            "Epoch 82, Batch 37/224, Training Loss: 0.2736\n",
            "Epoch 82, Batch 38/224, Training Loss: 0.3498\n",
            "Epoch 82, Batch 39/224, Training Loss: 0.3736\n",
            "Epoch 82, Batch 40/224, Training Loss: 0.3091\n",
            "Epoch 82, Batch 41/224, Training Loss: 0.3671\n",
            "Epoch 82, Batch 42/224, Training Loss: 0.2754\n",
            "Epoch 82, Batch 43/224, Training Loss: 0.3561\n",
            "Epoch 82, Batch 44/224, Training Loss: 0.1976\n",
            "Epoch 82, Batch 45/224, Training Loss: 0.3632\n",
            "Epoch 82, Batch 46/224, Training Loss: 0.3741\n",
            "Epoch 82, Batch 47/224, Training Loss: 0.2860\n",
            "Epoch 82, Batch 48/224, Training Loss: 0.3611\n",
            "Epoch 82, Batch 49/224, Training Loss: 0.2480\n",
            "Epoch 82, Batch 50/224, Training Loss: 0.2981\n",
            "Epoch 82, Batch 51/224, Training Loss: 0.4074\n",
            "Epoch 82, Batch 52/224, Training Loss: 0.3231\n",
            "Epoch 82, Batch 53/224, Training Loss: 0.3940\n",
            "Epoch 82, Batch 54/224, Training Loss: 0.3810\n",
            "Epoch 82, Batch 55/224, Training Loss: 0.4253\n",
            "Epoch 82, Batch 56/224, Training Loss: 1.0941\n",
            "Epoch 82, Batch 57/224, Training Loss: 0.2398\n",
            "Epoch 82, Batch 58/224, Training Loss: 0.3359\n",
            "Epoch 82, Batch 59/224, Training Loss: 0.3467\n",
            "Epoch 82, Batch 60/224, Training Loss: 0.2601\n",
            "Epoch 82, Batch 61/224, Training Loss: 0.3956\n",
            "Epoch 82, Batch 62/224, Training Loss: 0.3965\n",
            "Epoch 82, Batch 63/224, Training Loss: 0.6678\n",
            "Epoch 82, Batch 64/224, Training Loss: 0.2956\n",
            "Epoch 82, Batch 65/224, Training Loss: 0.2818\n",
            "Epoch 82, Batch 66/224, Training Loss: 0.4088\n",
            "Epoch 82, Batch 67/224, Training Loss: 0.2558\n",
            "Epoch 82, Batch 68/224, Training Loss: 0.5480\n",
            "Epoch 82, Batch 69/224, Training Loss: 0.4778\n",
            "Epoch 82, Batch 70/224, Training Loss: 0.5089\n",
            "Epoch 82, Batch 71/224, Training Loss: 0.2940\n",
            "Epoch 82, Batch 72/224, Training Loss: 0.2983\n",
            "Epoch 82, Batch 73/224, Training Loss: 0.6053\n",
            "Epoch 82, Batch 74/224, Training Loss: 0.4151\n",
            "Epoch 82, Batch 75/224, Training Loss: 0.3793\n",
            "Epoch 82, Batch 76/224, Training Loss: 0.4673\n",
            "Epoch 82, Batch 77/224, Training Loss: 0.4814\n",
            "Epoch 82, Batch 78/224, Training Loss: 0.4509\n",
            "Epoch 82, Batch 79/224, Training Loss: 1.0257\n",
            "Epoch 82, Batch 80/224, Training Loss: 0.3456\n",
            "Epoch 82, Batch 81/224, Training Loss: 0.3539\n",
            "Epoch 82, Batch 82/224, Training Loss: 0.3494\n",
            "Epoch 82, Batch 83/224, Training Loss: 0.4315\n",
            "Epoch 82, Batch 84/224, Training Loss: 0.3124\n",
            "Epoch 82, Batch 85/224, Training Loss: 0.4399\n",
            "Epoch 82, Batch 86/224, Training Loss: 0.4156\n",
            "Epoch 82, Batch 87/224, Training Loss: 0.3222\n",
            "Epoch 82, Batch 88/224, Training Loss: 0.5223\n",
            "Epoch 82, Batch 89/224, Training Loss: 0.2632\n",
            "Epoch 82, Batch 90/224, Training Loss: 0.4531\n",
            "Epoch 82, Batch 91/224, Training Loss: 0.2750\n",
            "Epoch 82, Batch 92/224, Training Loss: 0.3214\n",
            "Epoch 82, Batch 93/224, Training Loss: 0.4879\n",
            "Epoch 82, Batch 94/224, Training Loss: 0.3475\n",
            "Epoch 82, Batch 95/224, Training Loss: 0.3360\n",
            "Epoch 82, Batch 96/224, Training Loss: 0.4550\n",
            "Epoch 82, Batch 97/224, Training Loss: 0.2842\n",
            "Epoch 82, Batch 98/224, Training Loss: 0.5507\n",
            "Epoch 82, Batch 99/224, Training Loss: 0.6151\n",
            "Epoch 82, Batch 100/224, Training Loss: 0.2857\n",
            "Epoch 82, Batch 101/224, Training Loss: 0.4295\n",
            "Epoch 82, Batch 102/224, Training Loss: 0.2848\n",
            "Epoch 82, Batch 103/224, Training Loss: 0.3204\n",
            "Epoch 82, Batch 104/224, Training Loss: 0.3554\n",
            "Epoch 82, Batch 105/224, Training Loss: 0.3756\n",
            "Epoch 82, Batch 106/224, Training Loss: 0.5100\n",
            "Epoch 82, Batch 107/224, Training Loss: 0.2878\n",
            "Epoch 82, Batch 108/224, Training Loss: 0.2563\n",
            "Epoch 82, Batch 109/224, Training Loss: 0.5808\n",
            "Epoch 82, Batch 110/224, Training Loss: 0.3196\n",
            "Epoch 82, Batch 111/224, Training Loss: 0.3353\n",
            "Epoch 82, Batch 112/224, Training Loss: 0.2943\n",
            "Epoch 82, Batch 113/224, Training Loss: 0.4708\n",
            "Epoch 82, Batch 114/224, Training Loss: 0.3753\n",
            "Epoch 82, Batch 115/224, Training Loss: 0.3600\n",
            "Epoch 82, Batch 116/224, Training Loss: 0.2936\n",
            "Epoch 82, Batch 117/224, Training Loss: 0.4917\n",
            "Epoch 82, Batch 118/224, Training Loss: 0.4727\n",
            "Epoch 82, Batch 119/224, Training Loss: 0.3800\n",
            "Epoch 82, Batch 120/224, Training Loss: 0.3325\n",
            "Epoch 82, Batch 121/224, Training Loss: 0.2368\n",
            "Epoch 82, Batch 122/224, Training Loss: 0.7586\n",
            "Epoch 82, Batch 123/224, Training Loss: 0.3701\n",
            "Epoch 82, Batch 124/224, Training Loss: 0.3688\n",
            "Epoch 82, Batch 125/224, Training Loss: 0.3107\n",
            "Epoch 82, Batch 126/224, Training Loss: 0.7942\n",
            "Epoch 82, Batch 127/224, Training Loss: 0.4524\n",
            "Epoch 82, Batch 128/224, Training Loss: 0.3366\n",
            "Epoch 82, Batch 129/224, Training Loss: 0.4791\n",
            "Epoch 82, Batch 130/224, Training Loss: 0.3863\n",
            "Epoch 82, Batch 131/224, Training Loss: 0.4385\n",
            "Epoch 82, Batch 132/224, Training Loss: 0.4187\n",
            "Epoch 82, Batch 133/224, Training Loss: 0.4526\n",
            "Epoch 82, Batch 134/224, Training Loss: 0.3741\n",
            "Epoch 82, Batch 135/224, Training Loss: 0.4112\n",
            "Epoch 82, Batch 136/224, Training Loss: 0.3332\n",
            "Epoch 82, Batch 137/224, Training Loss: 0.3521\n",
            "Epoch 82, Batch 138/224, Training Loss: 0.4539\n",
            "Epoch 82, Batch 139/224, Training Loss: 0.3344\n",
            "Epoch 82, Batch 140/224, Training Loss: 0.2770\n",
            "Epoch 82, Batch 141/224, Training Loss: 0.3073\n",
            "Epoch 82, Batch 142/224, Training Loss: 0.4269\n",
            "Epoch 82, Batch 143/224, Training Loss: 0.5615\n",
            "Epoch 82, Batch 144/224, Training Loss: 0.3268\n",
            "Epoch 82, Batch 145/224, Training Loss: 0.6246\n",
            "Epoch 82, Batch 146/224, Training Loss: 0.3176\n",
            "Epoch 82, Batch 147/224, Training Loss: 0.4433\n",
            "Epoch 82, Batch 148/224, Training Loss: 0.4660\n",
            "Epoch 82, Batch 149/224, Training Loss: 0.6558\n",
            "Epoch 82, Batch 150/224, Training Loss: 0.2703\n",
            "Epoch 82, Batch 151/224, Training Loss: 0.4559\n",
            "Epoch 82, Batch 152/224, Training Loss: 0.5821\n",
            "Epoch 82, Batch 153/224, Training Loss: 0.5412\n",
            "Epoch 82, Batch 154/224, Training Loss: 0.5746\n",
            "Epoch 82, Batch 155/224, Training Loss: 0.3719\n",
            "Epoch 82, Batch 156/224, Training Loss: 0.4296\n",
            "Epoch 82, Batch 157/224, Training Loss: 0.2967\n",
            "Epoch 82, Batch 158/224, Training Loss: 0.5111\n",
            "Epoch 82, Batch 159/224, Training Loss: 0.4112\n",
            "Epoch 82, Batch 160/224, Training Loss: 0.3970\n",
            "Epoch 82, Batch 161/224, Training Loss: 0.5733\n",
            "Epoch 82, Batch 162/224, Training Loss: 0.3561\n",
            "Epoch 82, Batch 163/224, Training Loss: 0.2869\n",
            "Epoch 82, Batch 164/224, Training Loss: 0.3717\n",
            "Epoch 82, Batch 165/224, Training Loss: 0.3980\n",
            "Epoch 82, Batch 166/224, Training Loss: 0.3073\n",
            "Epoch 82, Batch 167/224, Training Loss: 0.3860\n",
            "Epoch 82, Batch 168/224, Training Loss: 0.4268\n",
            "Epoch 82, Batch 169/224, Training Loss: 0.3210\n",
            "Epoch 82, Batch 170/224, Training Loss: 1.2147\n",
            "Epoch 82, Batch 171/224, Training Loss: 0.2319\n",
            "Epoch 82, Batch 172/224, Training Loss: 0.3698\n",
            "Epoch 82, Batch 173/224, Training Loss: 0.3427\n",
            "Epoch 82, Batch 174/224, Training Loss: 0.7715\n",
            "Epoch 82, Batch 175/224, Training Loss: 0.3172\n",
            "Epoch 82, Batch 176/224, Training Loss: 0.5140\n",
            "Epoch 82, Batch 177/224, Training Loss: 0.5528\n",
            "Epoch 82, Batch 178/224, Training Loss: 0.7134\n",
            "Epoch 82, Batch 179/224, Training Loss: 0.3347\n",
            "Epoch 82, Batch 180/224, Training Loss: 0.4133\n",
            "Epoch 82, Batch 181/224, Training Loss: 0.3707\n",
            "Epoch 82, Batch 182/224, Training Loss: 0.3698\n",
            "Epoch 82, Batch 183/224, Training Loss: 0.4639\n",
            "Epoch 82, Batch 184/224, Training Loss: 0.3913\n",
            "Epoch 82, Batch 185/224, Training Loss: 0.3422\n",
            "Epoch 82, Batch 186/224, Training Loss: 0.4397\n",
            "Epoch 82, Batch 187/224, Training Loss: 0.3589\n",
            "Epoch 82, Batch 188/224, Training Loss: 0.2808\n",
            "Epoch 82, Batch 189/224, Training Loss: 0.4899\n",
            "Epoch 82, Batch 190/224, Training Loss: 0.3270\n",
            "Epoch 82, Batch 191/224, Training Loss: 0.5026\n",
            "Epoch 82, Batch 192/224, Training Loss: 0.3915\n",
            "Epoch 82, Batch 193/224, Training Loss: 0.2668\n",
            "Epoch 82, Batch 194/224, Training Loss: 0.9111\n",
            "Epoch 82, Batch 195/224, Training Loss: 0.4781\n",
            "Epoch 82, Batch 196/224, Training Loss: 0.5432\n",
            "Epoch 82, Batch 197/224, Training Loss: 0.4365\n",
            "Epoch 82, Batch 198/224, Training Loss: 0.7583\n",
            "Epoch 82, Batch 199/224, Training Loss: 0.3236\n",
            "Epoch 82, Batch 200/224, Training Loss: 0.2706\n",
            "Epoch 82, Batch 201/224, Training Loss: 0.4543\n",
            "Epoch 82, Batch 202/224, Training Loss: 0.5486\n",
            "Epoch 82, Batch 203/224, Training Loss: 0.4156\n",
            "Epoch 82, Batch 204/224, Training Loss: 0.3498\n",
            "Epoch 82, Batch 205/224, Training Loss: 0.3651\n",
            "Epoch 82, Batch 206/224, Training Loss: 0.3717\n",
            "Epoch 82, Batch 207/224, Training Loss: 0.7232\n",
            "Epoch 82, Batch 208/224, Training Loss: 0.4138\n",
            "Epoch 82, Batch 209/224, Training Loss: 0.4459\n",
            "Epoch 82, Batch 210/224, Training Loss: 0.4678\n",
            "Epoch 82, Batch 211/224, Training Loss: 0.5048\n",
            "Epoch 82, Batch 212/224, Training Loss: 0.6521\n",
            "Epoch 82, Batch 213/224, Training Loss: 0.6241\n",
            "Epoch 82, Batch 214/224, Training Loss: 0.3907\n",
            "Epoch 82, Batch 215/224, Training Loss: 0.4989\n",
            "Epoch 82, Batch 216/224, Training Loss: 0.3259\n",
            "Epoch 82, Batch 217/224, Training Loss: 0.5603\n",
            "Epoch 82, Batch 218/224, Training Loss: 0.3033\n",
            "Epoch 82, Batch 219/224, Training Loss: 0.4605\n",
            "Epoch 82, Batch 220/224, Training Loss: 0.6310\n",
            "Epoch 82, Batch 221/224, Training Loss: 0.4375\n",
            "Epoch 82, Batch 222/224, Training Loss: 0.3030\n",
            "Epoch 82, Batch 223/224, Training Loss: 0.3330\n",
            "Epoch 82/100, Training Loss: 0.4126, Test Loss: 3.1239\n",
            "Epoch 83, Batch 0/224, Training Loss: 0.4456\n",
            "Epoch 83, Batch 1/224, Training Loss: 0.3716\n",
            "Epoch 83, Batch 2/224, Training Loss: 0.3584\n",
            "Epoch 83, Batch 3/224, Training Loss: 0.3190\n",
            "Epoch 83, Batch 4/224, Training Loss: 0.2647\n",
            "Epoch 83, Batch 5/224, Training Loss: 0.3105\n",
            "Epoch 83, Batch 6/224, Training Loss: 0.4581\n",
            "Epoch 83, Batch 7/224, Training Loss: 0.3788\n",
            "Epoch 83, Batch 8/224, Training Loss: 0.7299\n",
            "Epoch 83, Batch 9/224, Training Loss: 0.6304\n",
            "Epoch 83, Batch 10/224, Training Loss: 0.2700\n",
            "Epoch 83, Batch 11/224, Training Loss: 0.3776\n",
            "Epoch 83, Batch 12/224, Training Loss: 0.4394\n",
            "Epoch 83, Batch 13/224, Training Loss: 0.2691\n",
            "Epoch 83, Batch 14/224, Training Loss: 0.6066\n",
            "Epoch 83, Batch 15/224, Training Loss: 0.5422\n",
            "Epoch 83, Batch 16/224, Training Loss: 0.6615\n",
            "Epoch 83, Batch 17/224, Training Loss: 0.5144\n",
            "Epoch 83, Batch 18/224, Training Loss: 0.2869\n",
            "Epoch 83, Batch 19/224, Training Loss: 0.4278\n",
            "Epoch 83, Batch 20/224, Training Loss: 0.6201\n",
            "Epoch 83, Batch 21/224, Training Loss: 0.2415\n",
            "Epoch 83, Batch 22/224, Training Loss: 0.3399\n",
            "Epoch 83, Batch 23/224, Training Loss: 0.4220\n",
            "Epoch 83, Batch 24/224, Training Loss: 0.4883\n",
            "Epoch 83, Batch 25/224, Training Loss: 0.2605\n",
            "Epoch 83, Batch 26/224, Training Loss: 0.4811\n",
            "Epoch 83, Batch 27/224, Training Loss: 0.3057\n",
            "Epoch 83, Batch 28/224, Training Loss: 0.7006\n",
            "Epoch 83, Batch 29/224, Training Loss: 0.4175\n",
            "Epoch 83, Batch 30/224, Training Loss: 0.3662\n",
            "Epoch 83, Batch 31/224, Training Loss: 0.4120\n",
            "Epoch 83, Batch 32/224, Training Loss: 0.4330\n",
            "Epoch 83, Batch 33/224, Training Loss: 0.2697\n",
            "Epoch 83, Batch 34/224, Training Loss: 0.2940\n",
            "Epoch 83, Batch 35/224, Training Loss: 0.4205\n",
            "Epoch 83, Batch 36/224, Training Loss: 0.3525\n",
            "Epoch 83, Batch 37/224, Training Loss: 0.4291\n",
            "Epoch 83, Batch 38/224, Training Loss: 0.4341\n",
            "Epoch 83, Batch 39/224, Training Loss: 0.5821\n",
            "Epoch 83, Batch 40/224, Training Loss: 0.4325\n",
            "Epoch 83, Batch 41/224, Training Loss: 0.3319\n",
            "Epoch 83, Batch 42/224, Training Loss: 0.5436\n",
            "Epoch 83, Batch 43/224, Training Loss: 0.4887\n",
            "Epoch 83, Batch 44/224, Training Loss: 0.8222\n",
            "Epoch 83, Batch 45/224, Training Loss: 0.4408\n",
            "Epoch 83, Batch 46/224, Training Loss: 0.8254\n",
            "Epoch 83, Batch 47/224, Training Loss: 0.3179\n",
            "Epoch 83, Batch 48/224, Training Loss: 0.2818\n",
            "Epoch 83, Batch 49/224, Training Loss: 0.2522\n",
            "Epoch 83, Batch 50/224, Training Loss: 0.5953\n",
            "Epoch 83, Batch 51/224, Training Loss: 0.4489\n",
            "Epoch 83, Batch 52/224, Training Loss: 0.3363\n",
            "Epoch 83, Batch 53/224, Training Loss: 0.5592\n",
            "Epoch 83, Batch 54/224, Training Loss: 0.3957\n",
            "Epoch 83, Batch 55/224, Training Loss: 0.2681\n",
            "Epoch 83, Batch 56/224, Training Loss: 0.3674\n",
            "Epoch 83, Batch 57/224, Training Loss: 0.5697\n",
            "Epoch 83, Batch 58/224, Training Loss: 0.2717\n",
            "Epoch 83, Batch 59/224, Training Loss: 0.3356\n",
            "Epoch 83, Batch 60/224, Training Loss: 0.4356\n",
            "Epoch 83, Batch 61/224, Training Loss: 0.4093\n",
            "Epoch 83, Batch 62/224, Training Loss: 0.3028\n",
            "Epoch 83, Batch 63/224, Training Loss: 0.2950\n",
            "Epoch 83, Batch 64/224, Training Loss: 0.5014\n",
            "Epoch 83, Batch 65/224, Training Loss: 0.3104\n",
            "Epoch 83, Batch 66/224, Training Loss: 0.4392\n",
            "Epoch 83, Batch 67/224, Training Loss: 0.2806\n",
            "Epoch 83, Batch 68/224, Training Loss: 0.2893\n",
            "Epoch 83, Batch 69/224, Training Loss: 0.3025\n",
            "Epoch 83, Batch 70/224, Training Loss: 0.3047\n",
            "Epoch 83, Batch 71/224, Training Loss: 0.3265\n",
            "Epoch 83, Batch 72/224, Training Loss: 0.2339\n",
            "Epoch 83, Batch 73/224, Training Loss: 0.4184\n",
            "Epoch 83, Batch 74/224, Training Loss: 0.3598\n",
            "Epoch 83, Batch 75/224, Training Loss: 0.3391\n",
            "Epoch 83, Batch 76/224, Training Loss: 0.3140\n",
            "Epoch 83, Batch 77/224, Training Loss: 0.2406\n",
            "Epoch 83, Batch 78/224, Training Loss: 0.5221\n",
            "Epoch 83, Batch 79/224, Training Loss: 0.2854\n",
            "Epoch 83, Batch 80/224, Training Loss: 0.4349\n",
            "Epoch 83, Batch 81/224, Training Loss: 0.2416\n",
            "Epoch 83, Batch 82/224, Training Loss: 0.3216\n",
            "Epoch 83, Batch 83/224, Training Loss: 0.4445\n",
            "Epoch 83, Batch 84/224, Training Loss: 0.5491\n",
            "Epoch 83, Batch 85/224, Training Loss: 0.4462\n",
            "Epoch 83, Batch 86/224, Training Loss: 0.5247\n",
            "Epoch 83, Batch 87/224, Training Loss: 0.4202\n",
            "Epoch 83, Batch 88/224, Training Loss: 0.3436\n",
            "Epoch 83, Batch 89/224, Training Loss: 0.3700\n",
            "Epoch 83, Batch 90/224, Training Loss: 0.5608\n",
            "Epoch 83, Batch 91/224, Training Loss: 0.4748\n",
            "Epoch 83, Batch 92/224, Training Loss: 0.3725\n",
            "Epoch 83, Batch 93/224, Training Loss: 0.3666\n",
            "Epoch 83, Batch 94/224, Training Loss: 0.3573\n",
            "Epoch 83, Batch 95/224, Training Loss: 0.4323\n",
            "Epoch 83, Batch 96/224, Training Loss: 0.4727\n",
            "Epoch 83, Batch 97/224, Training Loss: 0.4776\n",
            "Epoch 83, Batch 98/224, Training Loss: 0.3994\n",
            "Epoch 83, Batch 99/224, Training Loss: 0.6363\n",
            "Epoch 83, Batch 100/224, Training Loss: 0.5025\n",
            "Epoch 83, Batch 101/224, Training Loss: 0.3306\n",
            "Epoch 83, Batch 102/224, Training Loss: 0.3267\n",
            "Epoch 83, Batch 103/224, Training Loss: 0.4221\n",
            "Epoch 83, Batch 104/224, Training Loss: 0.2838\n",
            "Epoch 83, Batch 105/224, Training Loss: 0.4185\n",
            "Epoch 83, Batch 106/224, Training Loss: 0.2435\n",
            "Epoch 83, Batch 107/224, Training Loss: 0.3991\n",
            "Epoch 83, Batch 108/224, Training Loss: 0.4118\n",
            "Epoch 83, Batch 109/224, Training Loss: 0.3290\n",
            "Epoch 83, Batch 110/224, Training Loss: 0.3361\n",
            "Epoch 83, Batch 111/224, Training Loss: 0.1904\n",
            "Epoch 83, Batch 112/224, Training Loss: 0.3372\n",
            "Epoch 83, Batch 113/224, Training Loss: 0.3322\n",
            "Epoch 83, Batch 114/224, Training Loss: 0.4505\n",
            "Epoch 83, Batch 115/224, Training Loss: 0.3314\n",
            "Epoch 83, Batch 116/224, Training Loss: 0.3178\n",
            "Epoch 83, Batch 117/224, Training Loss: 0.5238\n",
            "Epoch 83, Batch 118/224, Training Loss: 0.3347\n",
            "Epoch 83, Batch 119/224, Training Loss: 0.2831\n",
            "Epoch 83, Batch 120/224, Training Loss: 0.3583\n",
            "Epoch 83, Batch 121/224, Training Loss: 0.5170\n",
            "Epoch 83, Batch 122/224, Training Loss: 0.3262\n",
            "Epoch 83, Batch 123/224, Training Loss: 0.3682\n",
            "Epoch 83, Batch 124/224, Training Loss: 0.3342\n",
            "Epoch 83, Batch 125/224, Training Loss: 0.2944\n",
            "Epoch 83, Batch 126/224, Training Loss: 0.6868\n",
            "Epoch 83, Batch 127/224, Training Loss: 0.2906\n",
            "Epoch 83, Batch 128/224, Training Loss: 0.4546\n",
            "Epoch 83, Batch 129/224, Training Loss: 0.4459\n",
            "Epoch 83, Batch 130/224, Training Loss: 0.3808\n",
            "Epoch 83, Batch 131/224, Training Loss: 0.3905\n",
            "Epoch 83, Batch 132/224, Training Loss: 0.3728\n",
            "Epoch 83, Batch 133/224, Training Loss: 0.6118\n",
            "Epoch 83, Batch 134/224, Training Loss: 0.2457\n",
            "Epoch 83, Batch 135/224, Training Loss: 0.5214\n",
            "Epoch 83, Batch 136/224, Training Loss: 0.8947\n",
            "Epoch 83, Batch 137/224, Training Loss: 0.3832\n",
            "Epoch 83, Batch 138/224, Training Loss: 0.3850\n",
            "Epoch 83, Batch 139/224, Training Loss: 0.3569\n",
            "Epoch 83, Batch 140/224, Training Loss: 0.3208\n",
            "Epoch 83, Batch 141/224, Training Loss: 0.3999\n",
            "Epoch 83, Batch 142/224, Training Loss: 0.3990\n",
            "Epoch 83, Batch 143/224, Training Loss: 0.5196\n",
            "Epoch 83, Batch 144/224, Training Loss: 0.3379\n",
            "Epoch 83, Batch 145/224, Training Loss: 0.4161\n",
            "Epoch 83, Batch 146/224, Training Loss: 0.2506\n",
            "Epoch 83, Batch 147/224, Training Loss: 0.8110\n",
            "Epoch 83, Batch 148/224, Training Loss: 0.5233\n",
            "Epoch 83, Batch 149/224, Training Loss: 0.7872\n",
            "Epoch 83, Batch 150/224, Training Loss: 0.3194\n",
            "Epoch 83, Batch 151/224, Training Loss: 0.3115\n",
            "Epoch 83, Batch 152/224, Training Loss: 0.3577\n",
            "Epoch 83, Batch 153/224, Training Loss: 0.2856\n",
            "Epoch 83, Batch 154/224, Training Loss: 0.4761\n",
            "Epoch 83, Batch 155/224, Training Loss: 0.3796\n",
            "Epoch 83, Batch 156/224, Training Loss: 0.6395\n",
            "Epoch 83, Batch 157/224, Training Loss: 0.3594\n",
            "Epoch 83, Batch 158/224, Training Loss: 0.3131\n",
            "Epoch 83, Batch 159/224, Training Loss: 0.3005\n",
            "Epoch 83, Batch 160/224, Training Loss: 0.3974\n",
            "Epoch 83, Batch 161/224, Training Loss: 0.5264\n",
            "Epoch 83, Batch 162/224, Training Loss: 0.3939\n",
            "Epoch 83, Batch 163/224, Training Loss: 0.3348\n",
            "Epoch 83, Batch 164/224, Training Loss: 0.4196\n",
            "Epoch 83, Batch 165/224, Training Loss: 0.4384\n",
            "Epoch 83, Batch 166/224, Training Loss: 0.3748\n",
            "Epoch 83, Batch 167/224, Training Loss: 0.4712\n",
            "Epoch 83, Batch 168/224, Training Loss: 0.4450\n",
            "Epoch 83, Batch 169/224, Training Loss: 0.5983\n",
            "Epoch 83, Batch 170/224, Training Loss: 0.3717\n",
            "Epoch 83, Batch 171/224, Training Loss: 0.5842\n",
            "Epoch 83, Batch 172/224, Training Loss: 0.4428\n",
            "Epoch 83, Batch 173/224, Training Loss: 0.8624\n",
            "Epoch 83, Batch 174/224, Training Loss: 0.3151\n",
            "Epoch 83, Batch 175/224, Training Loss: 0.4460\n",
            "Epoch 83, Batch 176/224, Training Loss: 0.4995\n",
            "Epoch 83, Batch 177/224, Training Loss: 0.3952\n",
            "Epoch 83, Batch 178/224, Training Loss: 0.5290\n",
            "Epoch 83, Batch 179/224, Training Loss: 0.4274\n",
            "Epoch 83, Batch 180/224, Training Loss: 0.3314\n",
            "Epoch 83, Batch 181/224, Training Loss: 0.4378\n",
            "Epoch 83, Batch 182/224, Training Loss: 0.3057\n",
            "Epoch 83, Batch 183/224, Training Loss: 0.7726\n",
            "Epoch 83, Batch 184/224, Training Loss: 0.3440\n",
            "Epoch 83, Batch 185/224, Training Loss: 0.4106\n",
            "Epoch 83, Batch 186/224, Training Loss: 0.3127\n",
            "Epoch 83, Batch 187/224, Training Loss: 0.4555\n",
            "Epoch 83, Batch 188/224, Training Loss: 0.4956\n",
            "Epoch 83, Batch 189/224, Training Loss: 0.3968\n",
            "Epoch 83, Batch 190/224, Training Loss: 0.3705\n",
            "Epoch 83, Batch 191/224, Training Loss: 0.3903\n",
            "Epoch 83, Batch 192/224, Training Loss: 0.4679\n",
            "Epoch 83, Batch 193/224, Training Loss: 0.3948\n",
            "Epoch 83, Batch 194/224, Training Loss: 0.4811\n",
            "Epoch 83, Batch 195/224, Training Loss: 0.3700\n",
            "Epoch 83, Batch 196/224, Training Loss: 0.3012\n",
            "Epoch 83, Batch 197/224, Training Loss: 0.4900\n",
            "Epoch 83, Batch 198/224, Training Loss: 0.4922\n",
            "Epoch 83, Batch 199/224, Training Loss: 0.3593\n",
            "Epoch 83, Batch 200/224, Training Loss: 0.4038\n",
            "Epoch 83, Batch 201/224, Training Loss: 0.3861\n",
            "Epoch 83, Batch 202/224, Training Loss: 0.3626\n",
            "Epoch 83, Batch 203/224, Training Loss: 0.3568\n",
            "Epoch 83, Batch 204/224, Training Loss: 0.3256\n",
            "Epoch 83, Batch 205/224, Training Loss: 0.3868\n",
            "Epoch 83, Batch 206/224, Training Loss: 0.6706\n",
            "Epoch 83, Batch 207/224, Training Loss: 0.4869\n",
            "Epoch 83, Batch 208/224, Training Loss: 0.2437\n",
            "Epoch 83, Batch 209/224, Training Loss: 0.3947\n",
            "Epoch 83, Batch 210/224, Training Loss: 0.3269\n",
            "Epoch 83, Batch 211/224, Training Loss: 0.3014\n",
            "Epoch 83, Batch 212/224, Training Loss: 0.3745\n",
            "Epoch 83, Batch 213/224, Training Loss: 0.2925\n",
            "Epoch 83, Batch 214/224, Training Loss: 0.2968\n",
            "Epoch 83, Batch 215/224, Training Loss: 0.3175\n",
            "Epoch 83, Batch 216/224, Training Loss: 0.4367\n",
            "Epoch 83, Batch 217/224, Training Loss: 0.8102\n",
            "Epoch 83, Batch 218/224, Training Loss: 0.4401\n",
            "Epoch 83, Batch 219/224, Training Loss: 0.9299\n",
            "Epoch 83, Batch 220/224, Training Loss: 0.3491\n",
            "Epoch 83, Batch 221/224, Training Loss: 0.3505\n",
            "Epoch 83, Batch 222/224, Training Loss: 0.6251\n",
            "Epoch 83, Batch 223/224, Training Loss: 0.3166\n",
            "Epoch 83/100, Training Loss: 0.4172, Test Loss: 3.0752\n",
            "Epoch 84, Batch 0/224, Training Loss: 0.3966\n",
            "Epoch 84, Batch 1/224, Training Loss: 0.2824\n",
            "Epoch 84, Batch 2/224, Training Loss: 0.1667\n",
            "Epoch 84, Batch 3/224, Training Loss: 0.3600\n",
            "Epoch 84, Batch 4/224, Training Loss: 0.2415\n",
            "Epoch 84, Batch 5/224, Training Loss: 0.3248\n",
            "Epoch 84, Batch 6/224, Training Loss: 0.3107\n",
            "Epoch 84, Batch 7/224, Training Loss: 0.3067\n",
            "Epoch 84, Batch 8/224, Training Loss: 0.5468\n",
            "Epoch 84, Batch 9/224, Training Loss: 0.2812\n",
            "Epoch 84, Batch 10/224, Training Loss: 0.3851\n",
            "Epoch 84, Batch 11/224, Training Loss: 0.3334\n",
            "Epoch 84, Batch 12/224, Training Loss: 0.3043\n",
            "Epoch 84, Batch 13/224, Training Loss: 0.3744\n",
            "Epoch 84, Batch 14/224, Training Loss: 0.4824\n",
            "Epoch 84, Batch 15/224, Training Loss: 0.5291\n",
            "Epoch 84, Batch 16/224, Training Loss: 0.2972\n",
            "Epoch 84, Batch 17/224, Training Loss: 0.3521\n",
            "Epoch 84, Batch 18/224, Training Loss: 0.2919\n",
            "Epoch 84, Batch 19/224, Training Loss: 0.2001\n",
            "Epoch 84, Batch 20/224, Training Loss: 0.2947\n",
            "Epoch 84, Batch 21/224, Training Loss: 0.2696\n",
            "Epoch 84, Batch 22/224, Training Loss: 0.3898\n",
            "Epoch 84, Batch 23/224, Training Loss: 0.3227\n",
            "Epoch 84, Batch 24/224, Training Loss: 0.2463\n",
            "Epoch 84, Batch 25/224, Training Loss: 0.5008\n",
            "Epoch 84, Batch 26/224, Training Loss: 0.3833\n",
            "Epoch 84, Batch 27/224, Training Loss: 0.4662\n",
            "Epoch 84, Batch 28/224, Training Loss: 0.3037\n",
            "Epoch 84, Batch 29/224, Training Loss: 0.4068\n",
            "Epoch 84, Batch 30/224, Training Loss: 0.3309\n",
            "Epoch 84, Batch 31/224, Training Loss: 0.3620\n",
            "Epoch 84, Batch 32/224, Training Loss: 0.3404\n",
            "Epoch 84, Batch 33/224, Training Loss: 0.2971\n",
            "Epoch 84, Batch 34/224, Training Loss: 0.3869\n",
            "Epoch 84, Batch 35/224, Training Loss: 0.3492\n",
            "Epoch 84, Batch 36/224, Training Loss: 0.4204\n",
            "Epoch 84, Batch 37/224, Training Loss: 0.4705\n",
            "Epoch 84, Batch 38/224, Training Loss: 0.2439\n",
            "Epoch 84, Batch 39/224, Training Loss: 0.2957\n",
            "Epoch 84, Batch 40/224, Training Loss: 0.4101\n",
            "Epoch 84, Batch 41/224, Training Loss: 0.4739\n",
            "Epoch 84, Batch 42/224, Training Loss: 0.3780\n",
            "Epoch 84, Batch 43/224, Training Loss: 0.2018\n",
            "Epoch 84, Batch 44/224, Training Loss: 0.2606\n",
            "Epoch 84, Batch 45/224, Training Loss: 0.3626\n",
            "Epoch 84, Batch 46/224, Training Loss: 0.3639\n",
            "Epoch 84, Batch 47/224, Training Loss: 0.4448\n",
            "Epoch 84, Batch 48/224, Training Loss: 0.4427\n",
            "Epoch 84, Batch 49/224, Training Loss: 0.5473\n",
            "Epoch 84, Batch 50/224, Training Loss: 0.3140\n",
            "Epoch 84, Batch 51/224, Training Loss: 0.2994\n",
            "Epoch 84, Batch 52/224, Training Loss: 0.3203\n",
            "Epoch 84, Batch 53/224, Training Loss: 0.2935\n",
            "Epoch 84, Batch 54/224, Training Loss: 0.4082\n",
            "Epoch 84, Batch 55/224, Training Loss: 0.2935\n",
            "Epoch 84, Batch 56/224, Training Loss: 0.2846\n",
            "Epoch 84, Batch 57/224, Training Loss: 0.2520\n",
            "Epoch 84, Batch 58/224, Training Loss: 0.3717\n",
            "Epoch 84, Batch 59/224, Training Loss: 0.3309\n",
            "Epoch 84, Batch 60/224, Training Loss: 0.2804\n",
            "Epoch 84, Batch 61/224, Training Loss: 0.4341\n",
            "Epoch 84, Batch 62/224, Training Loss: 0.2807\n",
            "Epoch 84, Batch 63/224, Training Loss: 0.3285\n",
            "Epoch 84, Batch 64/224, Training Loss: 0.4295\n",
            "Epoch 84, Batch 65/224, Training Loss: 0.5685\n",
            "Epoch 84, Batch 66/224, Training Loss: 0.4257\n",
            "Epoch 84, Batch 67/224, Training Loss: 0.5373\n",
            "Epoch 84, Batch 68/224, Training Loss: 0.3073\n",
            "Epoch 84, Batch 69/224, Training Loss: 0.4659\n",
            "Epoch 84, Batch 70/224, Training Loss: 0.3759\n",
            "Epoch 84, Batch 71/224, Training Loss: 0.5330\n",
            "Epoch 84, Batch 72/224, Training Loss: 0.2367\n",
            "Epoch 84, Batch 73/224, Training Loss: 0.3121\n",
            "Epoch 84, Batch 74/224, Training Loss: 0.5042\n",
            "Epoch 84, Batch 75/224, Training Loss: 0.3266\n",
            "Epoch 84, Batch 76/224, Training Loss: 0.2935\n",
            "Epoch 84, Batch 77/224, Training Loss: 0.3179\n",
            "Epoch 84, Batch 78/224, Training Loss: 0.4056\n",
            "Epoch 84, Batch 79/224, Training Loss: 0.3350\n",
            "Epoch 84, Batch 80/224, Training Loss: 0.4914\n",
            "Epoch 84, Batch 81/224, Training Loss: 0.2685\n",
            "Epoch 84, Batch 82/224, Training Loss: 0.2803\n",
            "Epoch 84, Batch 83/224, Training Loss: 0.2149\n",
            "Epoch 84, Batch 84/224, Training Loss: 0.3301\n",
            "Epoch 84, Batch 85/224, Training Loss: 0.5738\n",
            "Epoch 84, Batch 86/224, Training Loss: 0.3073\n",
            "Epoch 84, Batch 87/224, Training Loss: 0.6671\n",
            "Epoch 84, Batch 88/224, Training Loss: 0.4452\n",
            "Epoch 84, Batch 89/224, Training Loss: 0.5930\n",
            "Epoch 84, Batch 90/224, Training Loss: 0.8570\n",
            "Epoch 84, Batch 91/224, Training Loss: 0.4413\n",
            "Epoch 84, Batch 92/224, Training Loss: 0.3963\n",
            "Epoch 84, Batch 93/224, Training Loss: 0.3428\n",
            "Epoch 84, Batch 94/224, Training Loss: 0.3859\n",
            "Epoch 84, Batch 95/224, Training Loss: 0.4788\n",
            "Epoch 84, Batch 96/224, Training Loss: 0.3125\n",
            "Epoch 84, Batch 97/224, Training Loss: 0.3442\n",
            "Epoch 84, Batch 98/224, Training Loss: 0.4548\n",
            "Epoch 84, Batch 99/224, Training Loss: 0.5914\n",
            "Epoch 84, Batch 100/224, Training Loss: 0.3911\n",
            "Epoch 84, Batch 101/224, Training Loss: 0.2675\n",
            "Epoch 84, Batch 102/224, Training Loss: 0.7042\n",
            "Epoch 84, Batch 103/224, Training Loss: 0.8516\n",
            "Epoch 84, Batch 104/224, Training Loss: 0.3755\n",
            "Epoch 84, Batch 105/224, Training Loss: 0.8949\n",
            "Epoch 84, Batch 106/224, Training Loss: 0.4194\n",
            "Epoch 84, Batch 107/224, Training Loss: 0.5881\n",
            "Epoch 84, Batch 108/224, Training Loss: 0.3039\n",
            "Epoch 84, Batch 109/224, Training Loss: 0.3911\n",
            "Epoch 84, Batch 110/224, Training Loss: 0.8579\n",
            "Epoch 84, Batch 111/224, Training Loss: 0.3406\n",
            "Epoch 84, Batch 112/224, Training Loss: 0.3700\n",
            "Epoch 84, Batch 113/224, Training Loss: 0.2162\n",
            "Epoch 84, Batch 114/224, Training Loss: 0.3309\n",
            "Epoch 84, Batch 115/224, Training Loss: 0.6674\n",
            "Epoch 84, Batch 116/224, Training Loss: 0.4142\n",
            "Epoch 84, Batch 117/224, Training Loss: 0.6453\n",
            "Epoch 84, Batch 118/224, Training Loss: 0.4492\n",
            "Epoch 84, Batch 119/224, Training Loss: 0.3006\n",
            "Epoch 84, Batch 120/224, Training Loss: 0.3386\n",
            "Epoch 84, Batch 121/224, Training Loss: 0.5090\n",
            "Epoch 84, Batch 122/224, Training Loss: 0.3198\n",
            "Epoch 84, Batch 123/224, Training Loss: 0.3569\n",
            "Epoch 84, Batch 124/224, Training Loss: 0.3055\n",
            "Epoch 84, Batch 125/224, Training Loss: 0.3180\n",
            "Epoch 84, Batch 126/224, Training Loss: 0.7158\n",
            "Epoch 84, Batch 127/224, Training Loss: 0.4243\n",
            "Epoch 84, Batch 128/224, Training Loss: 0.2683\n",
            "Epoch 84, Batch 129/224, Training Loss: 0.4670\n",
            "Epoch 84, Batch 130/224, Training Loss: 0.4519\n",
            "Epoch 84, Batch 131/224, Training Loss: 0.4671\n",
            "Epoch 84, Batch 132/224, Training Loss: 0.2546\n",
            "Epoch 84, Batch 133/224, Training Loss: 0.3218\n",
            "Epoch 84, Batch 134/224, Training Loss: 0.2927\n",
            "Epoch 84, Batch 135/224, Training Loss: 0.5582\n",
            "Epoch 84, Batch 136/224, Training Loss: 0.3684\n",
            "Epoch 84, Batch 137/224, Training Loss: 0.4435\n",
            "Epoch 84, Batch 138/224, Training Loss: 0.8878\n",
            "Epoch 84, Batch 139/224, Training Loss: 0.3772\n",
            "Epoch 84, Batch 140/224, Training Loss: 0.3159\n",
            "Epoch 84, Batch 141/224, Training Loss: 0.6263\n",
            "Epoch 84, Batch 142/224, Training Loss: 0.4465\n",
            "Epoch 84, Batch 143/224, Training Loss: 0.4587\n",
            "Epoch 84, Batch 144/224, Training Loss: 0.5691\n",
            "Epoch 84, Batch 145/224, Training Loss: 0.2878\n",
            "Epoch 84, Batch 146/224, Training Loss: 0.5796\n",
            "Epoch 84, Batch 147/224, Training Loss: 0.2659\n",
            "Epoch 84, Batch 148/224, Training Loss: 0.3790\n",
            "Epoch 84, Batch 149/224, Training Loss: 0.4579\n",
            "Epoch 84, Batch 150/224, Training Loss: 0.3328\n",
            "Epoch 84, Batch 151/224, Training Loss: 0.2791\n",
            "Epoch 84, Batch 152/224, Training Loss: 0.3487\n",
            "Epoch 84, Batch 153/224, Training Loss: 0.2934\n",
            "Epoch 84, Batch 154/224, Training Loss: 0.5404\n",
            "Epoch 84, Batch 155/224, Training Loss: 0.3218\n",
            "Epoch 84, Batch 156/224, Training Loss: 0.3343\n",
            "Epoch 84, Batch 157/224, Training Loss: 0.4010\n",
            "Epoch 84, Batch 158/224, Training Loss: 0.5993\n",
            "Epoch 84, Batch 159/224, Training Loss: 0.3769\n",
            "Epoch 84, Batch 160/224, Training Loss: 0.4497\n",
            "Epoch 84, Batch 161/224, Training Loss: 0.3835\n",
            "Epoch 84, Batch 162/224, Training Loss: 0.6973\n",
            "Epoch 84, Batch 163/224, Training Loss: 0.4513\n",
            "Epoch 84, Batch 164/224, Training Loss: 0.5372\n",
            "Epoch 84, Batch 165/224, Training Loss: 0.4025\n",
            "Epoch 84, Batch 166/224, Training Loss: 0.3270\n",
            "Epoch 84, Batch 167/224, Training Loss: 0.3161\n",
            "Epoch 84, Batch 168/224, Training Loss: 0.4055\n",
            "Epoch 84, Batch 169/224, Training Loss: 0.4432\n",
            "Epoch 84, Batch 170/224, Training Loss: 0.3359\n",
            "Epoch 84, Batch 171/224, Training Loss: 0.2965\n",
            "Epoch 84, Batch 172/224, Training Loss: 0.3593\n",
            "Epoch 84, Batch 173/224, Training Loss: 0.3956\n",
            "Epoch 84, Batch 174/224, Training Loss: 0.3230\n",
            "Epoch 84, Batch 175/224, Training Loss: 0.4228\n",
            "Epoch 84, Batch 176/224, Training Loss: 0.4371\n",
            "Epoch 84, Batch 177/224, Training Loss: 0.5297\n",
            "Epoch 84, Batch 178/224, Training Loss: 0.3550\n",
            "Epoch 84, Batch 179/224, Training Loss: 0.4887\n",
            "Epoch 84, Batch 180/224, Training Loss: 0.6034\n",
            "Epoch 84, Batch 181/224, Training Loss: 0.3366\n",
            "Epoch 84, Batch 182/224, Training Loss: 0.3959\n",
            "Epoch 84, Batch 183/224, Training Loss: 0.6295\n",
            "Epoch 84, Batch 184/224, Training Loss: 0.4178\n",
            "Epoch 84, Batch 185/224, Training Loss: 0.2758\n",
            "Epoch 84, Batch 186/224, Training Loss: 0.2833\n",
            "Epoch 84, Batch 187/224, Training Loss: 0.2469\n",
            "Epoch 84, Batch 188/224, Training Loss: 0.9132\n",
            "Epoch 84, Batch 189/224, Training Loss: 0.3687\n",
            "Epoch 84, Batch 190/224, Training Loss: 0.3323\n",
            "Epoch 84, Batch 191/224, Training Loss: 0.2475\n",
            "Epoch 84, Batch 192/224, Training Loss: 0.2773\n",
            "Epoch 84, Batch 193/224, Training Loss: 0.3316\n",
            "Epoch 84, Batch 194/224, Training Loss: 0.3107\n",
            "Epoch 84, Batch 195/224, Training Loss: 0.4725\n",
            "Epoch 84, Batch 196/224, Training Loss: 0.8047\n",
            "Epoch 84, Batch 197/224, Training Loss: 0.8659\n",
            "Epoch 84, Batch 198/224, Training Loss: 0.3558\n",
            "Epoch 84, Batch 199/224, Training Loss: 0.2993\n",
            "Epoch 84, Batch 200/224, Training Loss: 0.6680\n",
            "Epoch 84, Batch 201/224, Training Loss: 0.2871\n",
            "Epoch 84, Batch 202/224, Training Loss: 0.5678\n",
            "Epoch 84, Batch 203/224, Training Loss: 0.4637\n",
            "Epoch 84, Batch 204/224, Training Loss: 0.4224\n",
            "Epoch 84, Batch 205/224, Training Loss: 0.2402\n",
            "Epoch 84, Batch 206/224, Training Loss: 0.3638\n",
            "Epoch 84, Batch 207/224, Training Loss: 0.3952\n",
            "Epoch 84, Batch 208/224, Training Loss: 0.4231\n",
            "Epoch 84, Batch 209/224, Training Loss: 0.2722\n",
            "Epoch 84, Batch 210/224, Training Loss: 0.3023\n",
            "Epoch 84, Batch 211/224, Training Loss: 0.2843\n",
            "Epoch 84, Batch 212/224, Training Loss: 0.2978\n",
            "Epoch 84, Batch 213/224, Training Loss: 0.4228\n",
            "Epoch 84, Batch 214/224, Training Loss: 0.4378\n",
            "Epoch 84, Batch 215/224, Training Loss: 0.3520\n",
            "Epoch 84, Batch 216/224, Training Loss: 0.3446\n",
            "Epoch 84, Batch 217/224, Training Loss: 0.8968\n",
            "Epoch 84, Batch 218/224, Training Loss: 0.4265\n",
            "Epoch 84, Batch 219/224, Training Loss: 0.5164\n",
            "Epoch 84, Batch 220/224, Training Loss: 0.4298\n",
            "Epoch 84, Batch 221/224, Training Loss: 0.3672\n",
            "Epoch 84, Batch 222/224, Training Loss: 0.3353\n",
            "Epoch 84, Batch 223/224, Training Loss: 0.4597\n",
            "Epoch 84/100, Training Loss: 0.4059, Test Loss: 3.0673\n",
            "Epoch 85, Batch 0/224, Training Loss: 0.4098\n",
            "Epoch 85, Batch 1/224, Training Loss: 0.4996\n",
            "Epoch 85, Batch 2/224, Training Loss: 0.3769\n",
            "Epoch 85, Batch 3/224, Training Loss: 0.3779\n",
            "Epoch 85, Batch 4/224, Training Loss: 0.4036\n",
            "Epoch 85, Batch 5/224, Training Loss: 0.2366\n",
            "Epoch 85, Batch 6/224, Training Loss: 0.2768\n",
            "Epoch 85, Batch 7/224, Training Loss: 0.4922\n",
            "Epoch 85, Batch 8/224, Training Loss: 0.5454\n",
            "Epoch 85, Batch 9/224, Training Loss: 0.4342\n",
            "Epoch 85, Batch 10/224, Training Loss: 0.3721\n",
            "Epoch 85, Batch 11/224, Training Loss: 0.2868\n",
            "Epoch 85, Batch 12/224, Training Loss: 0.3091\n",
            "Epoch 85, Batch 13/224, Training Loss: 0.2620\n",
            "Epoch 85, Batch 14/224, Training Loss: 0.3994\n",
            "Epoch 85, Batch 15/224, Training Loss: 0.3803\n",
            "Epoch 85, Batch 16/224, Training Loss: 0.2901\n",
            "Epoch 85, Batch 17/224, Training Loss: 0.3259\n",
            "Epoch 85, Batch 18/224, Training Loss: 0.3332\n",
            "Epoch 85, Batch 19/224, Training Loss: 0.3171\n",
            "Epoch 85, Batch 20/224, Training Loss: 0.6098\n",
            "Epoch 85, Batch 21/224, Training Loss: 0.3755\n",
            "Epoch 85, Batch 22/224, Training Loss: 0.3316\n",
            "Epoch 85, Batch 23/224, Training Loss: 0.3520\n",
            "Epoch 85, Batch 24/224, Training Loss: 0.3549\n",
            "Epoch 85, Batch 25/224, Training Loss: 0.2652\n",
            "Epoch 85, Batch 26/224, Training Loss: 0.8480\n",
            "Epoch 85, Batch 27/224, Training Loss: 0.5661\n",
            "Epoch 85, Batch 28/224, Training Loss: 0.2632\n",
            "Epoch 85, Batch 29/224, Training Loss: 0.3911\n",
            "Epoch 85, Batch 30/224, Training Loss: 0.3545\n",
            "Epoch 85, Batch 31/224, Training Loss: 0.2537\n",
            "Epoch 85, Batch 32/224, Training Loss: 0.2342\n",
            "Epoch 85, Batch 33/224, Training Loss: 0.4930\n",
            "Epoch 85, Batch 34/224, Training Loss: 0.3234\n",
            "Epoch 85, Batch 35/224, Training Loss: 0.6219\n",
            "Epoch 85, Batch 36/224, Training Loss: 0.3082\n",
            "Epoch 85, Batch 37/224, Training Loss: 0.2199\n",
            "Epoch 85, Batch 38/224, Training Loss: 0.3435\n",
            "Epoch 85, Batch 39/224, Training Loss: 0.2905\n",
            "Epoch 85, Batch 40/224, Training Loss: 0.4436\n",
            "Epoch 85, Batch 41/224, Training Loss: 0.3118\n",
            "Epoch 85, Batch 42/224, Training Loss: 0.5216\n",
            "Epoch 85, Batch 43/224, Training Loss: 0.3973\n",
            "Epoch 85, Batch 44/224, Training Loss: 0.6979\n",
            "Epoch 85, Batch 45/224, Training Loss: 0.3057\n",
            "Epoch 85, Batch 46/224, Training Loss: 0.3297\n",
            "Epoch 85, Batch 47/224, Training Loss: 0.4711\n",
            "Epoch 85, Batch 48/224, Training Loss: 0.3581\n",
            "Epoch 85, Batch 49/224, Training Loss: 0.4683\n",
            "Epoch 85, Batch 50/224, Training Loss: 0.3272\n",
            "Epoch 85, Batch 51/224, Training Loss: 0.3381\n",
            "Epoch 85, Batch 52/224, Training Loss: 0.3614\n",
            "Epoch 85, Batch 53/224, Training Loss: 0.2678\n",
            "Epoch 85, Batch 54/224, Training Loss: 0.8755\n",
            "Epoch 85, Batch 55/224, Training Loss: 0.4744\n",
            "Epoch 85, Batch 56/224, Training Loss: 0.3953\n",
            "Epoch 85, Batch 57/224, Training Loss: 0.3625\n",
            "Epoch 85, Batch 58/224, Training Loss: 0.2963\n",
            "Epoch 85, Batch 59/224, Training Loss: 0.2815\n",
            "Epoch 85, Batch 60/224, Training Loss: 0.3214\n",
            "Epoch 85, Batch 61/224, Training Loss: 0.4515\n",
            "Epoch 85, Batch 62/224, Training Loss: 0.5452\n",
            "Epoch 85, Batch 63/224, Training Loss: 0.3308\n",
            "Epoch 85, Batch 64/224, Training Loss: 0.3089\n",
            "Epoch 85, Batch 65/224, Training Loss: 0.3588\n",
            "Epoch 85, Batch 66/224, Training Loss: 0.6703\n",
            "Epoch 85, Batch 67/224, Training Loss: 0.4843\n",
            "Epoch 85, Batch 68/224, Training Loss: 0.3577\n",
            "Epoch 85, Batch 69/224, Training Loss: 0.4371\n",
            "Epoch 85, Batch 70/224, Training Loss: 0.2984\n",
            "Epoch 85, Batch 71/224, Training Loss: 0.3214\n",
            "Epoch 85, Batch 72/224, Training Loss: 0.4370\n",
            "Epoch 85, Batch 73/224, Training Loss: 0.8037\n",
            "Epoch 85, Batch 74/224, Training Loss: 0.3103\n",
            "Epoch 85, Batch 75/224, Training Loss: 0.3731\n",
            "Epoch 85, Batch 76/224, Training Loss: 0.5285\n",
            "Epoch 85, Batch 77/224, Training Loss: 0.2785\n",
            "Epoch 85, Batch 78/224, Training Loss: 0.4265\n",
            "Epoch 85, Batch 79/224, Training Loss: 0.3389\n",
            "Epoch 85, Batch 80/224, Training Loss: 0.3650\n",
            "Epoch 85, Batch 81/224, Training Loss: 0.5152\n",
            "Epoch 85, Batch 82/224, Training Loss: 0.3109\n",
            "Epoch 85, Batch 83/224, Training Loss: 0.3338\n",
            "Epoch 85, Batch 84/224, Training Loss: 0.3077\n",
            "Epoch 85, Batch 85/224, Training Loss: 0.3351\n",
            "Epoch 85, Batch 86/224, Training Loss: 1.0730\n",
            "Epoch 85, Batch 87/224, Training Loss: 0.3133\n",
            "Epoch 85, Batch 88/224, Training Loss: 0.4441\n",
            "Epoch 85, Batch 89/224, Training Loss: 0.3141\n",
            "Epoch 85, Batch 90/224, Training Loss: 0.2846\n",
            "Epoch 85, Batch 91/224, Training Loss: 0.3791\n",
            "Epoch 85, Batch 92/224, Training Loss: 0.6754\n",
            "Epoch 85, Batch 93/224, Training Loss: 0.3782\n",
            "Epoch 85, Batch 94/224, Training Loss: 0.3094\n",
            "Epoch 85, Batch 95/224, Training Loss: 0.3668\n",
            "Epoch 85, Batch 96/224, Training Loss: 0.3625\n",
            "Epoch 85, Batch 97/224, Training Loss: 0.4792\n",
            "Epoch 85, Batch 98/224, Training Loss: 0.3960\n",
            "Epoch 85, Batch 99/224, Training Loss: 0.5533\n",
            "Epoch 85, Batch 100/224, Training Loss: 0.3472\n",
            "Epoch 85, Batch 101/224, Training Loss: 0.6099\n",
            "Epoch 85, Batch 102/224, Training Loss: 0.3400\n",
            "Epoch 85, Batch 103/224, Training Loss: 0.2687\n",
            "Epoch 85, Batch 104/224, Training Loss: 0.3927\n",
            "Epoch 85, Batch 105/224, Training Loss: 0.4777\n",
            "Epoch 85, Batch 106/224, Training Loss: 0.3040\n",
            "Epoch 85, Batch 107/224, Training Loss: 0.2372\n",
            "Epoch 85, Batch 108/224, Training Loss: 0.6186\n",
            "Epoch 85, Batch 109/224, Training Loss: 0.3847\n",
            "Epoch 85, Batch 110/224, Training Loss: 0.3611\n",
            "Epoch 85, Batch 111/224, Training Loss: 0.4726\n",
            "Epoch 85, Batch 112/224, Training Loss: 0.4522\n",
            "Epoch 85, Batch 113/224, Training Loss: 0.5057\n",
            "Epoch 85, Batch 114/224, Training Loss: 0.3124\n",
            "Epoch 85, Batch 115/224, Training Loss: 0.3917\n",
            "Epoch 85, Batch 116/224, Training Loss: 0.4685\n",
            "Epoch 85, Batch 117/224, Training Loss: 0.2673\n",
            "Epoch 85, Batch 118/224, Training Loss: 0.2974\n",
            "Epoch 85, Batch 119/224, Training Loss: 0.7616\n",
            "Epoch 85, Batch 120/224, Training Loss: 0.5198\n",
            "Epoch 85, Batch 121/224, Training Loss: 0.3709\n",
            "Epoch 85, Batch 122/224, Training Loss: 0.2778\n",
            "Epoch 85, Batch 123/224, Training Loss: 0.3234\n",
            "Epoch 85, Batch 124/224, Training Loss: 0.3202\n",
            "Epoch 85, Batch 125/224, Training Loss: 0.3154\n",
            "Epoch 85, Batch 126/224, Training Loss: 0.2790\n",
            "Epoch 85, Batch 127/224, Training Loss: 0.3257\n",
            "Epoch 85, Batch 128/224, Training Loss: 0.3813\n",
            "Epoch 85, Batch 129/224, Training Loss: 0.2724\n",
            "Epoch 85, Batch 130/224, Training Loss: 0.3558\n",
            "Epoch 85, Batch 131/224, Training Loss: 0.4655\n",
            "Epoch 85, Batch 132/224, Training Loss: 0.4689\n",
            "Epoch 85, Batch 133/224, Training Loss: 0.4369\n",
            "Epoch 85, Batch 134/224, Training Loss: 0.3926\n",
            "Epoch 85, Batch 135/224, Training Loss: 0.6125\n",
            "Epoch 85, Batch 136/224, Training Loss: 0.2733\n",
            "Epoch 85, Batch 137/224, Training Loss: 0.3258\n",
            "Epoch 85, Batch 138/224, Training Loss: 0.3775\n",
            "Epoch 85, Batch 139/224, Training Loss: 0.5293\n",
            "Epoch 85, Batch 140/224, Training Loss: 0.3566\n",
            "Epoch 85, Batch 141/224, Training Loss: 0.4105\n",
            "Epoch 85, Batch 142/224, Training Loss: 0.3306\n",
            "Epoch 85, Batch 143/224, Training Loss: 0.4414\n",
            "Epoch 85, Batch 144/224, Training Loss: 0.5899\n",
            "Epoch 85, Batch 145/224, Training Loss: 0.4638\n",
            "Epoch 85, Batch 146/224, Training Loss: 0.5040\n",
            "Epoch 85, Batch 147/224, Training Loss: 0.4433\n",
            "Epoch 85, Batch 148/224, Training Loss: 0.3883\n",
            "Epoch 85, Batch 149/224, Training Loss: 0.3083\n",
            "Epoch 85, Batch 150/224, Training Loss: 1.1878\n",
            "Epoch 85, Batch 151/224, Training Loss: 0.4692\n",
            "Epoch 85, Batch 152/224, Training Loss: 0.3020\n",
            "Epoch 85, Batch 153/224, Training Loss: 0.3966\n",
            "Epoch 85, Batch 154/224, Training Loss: 0.3535\n",
            "Epoch 85, Batch 155/224, Training Loss: 0.6126\n",
            "Epoch 85, Batch 156/224, Training Loss: 0.4376\n",
            "Epoch 85, Batch 157/224, Training Loss: 0.3976\n",
            "Epoch 85, Batch 158/224, Training Loss: 0.3336\n",
            "Epoch 85, Batch 159/224, Training Loss: 0.2963\n",
            "Epoch 85, Batch 160/224, Training Loss: 0.5091\n",
            "Epoch 85, Batch 161/224, Training Loss: 0.2907\n",
            "Epoch 85, Batch 162/224, Training Loss: 0.3086\n",
            "Epoch 85, Batch 163/224, Training Loss: 0.3908\n",
            "Epoch 85, Batch 164/224, Training Loss: 0.4553\n",
            "Epoch 85, Batch 165/224, Training Loss: 0.3450\n",
            "Epoch 85, Batch 166/224, Training Loss: 0.3991\n",
            "Epoch 85, Batch 167/224, Training Loss: 0.3409\n",
            "Epoch 85, Batch 168/224, Training Loss: 0.6254\n",
            "Epoch 85, Batch 169/224, Training Loss: 0.3385\n",
            "Epoch 85, Batch 170/224, Training Loss: 0.4122\n",
            "Epoch 85, Batch 171/224, Training Loss: 0.3859\n",
            "Epoch 85, Batch 172/224, Training Loss: 0.3774\n",
            "Epoch 85, Batch 173/224, Training Loss: 0.3692\n",
            "Epoch 85, Batch 174/224, Training Loss: 0.4809\n",
            "Epoch 85, Batch 175/224, Training Loss: 0.3466\n",
            "Epoch 85, Batch 176/224, Training Loss: 0.2521\n",
            "Epoch 85, Batch 177/224, Training Loss: 0.4283\n",
            "Epoch 85, Batch 178/224, Training Loss: 0.5214\n",
            "Epoch 85, Batch 179/224, Training Loss: 0.3340\n",
            "Epoch 85, Batch 180/224, Training Loss: 0.2930\n",
            "Epoch 85, Batch 181/224, Training Loss: 0.3779\n",
            "Epoch 85, Batch 182/224, Training Loss: 0.5549\n",
            "Epoch 85, Batch 183/224, Training Loss: 0.3118\n",
            "Epoch 85, Batch 184/224, Training Loss: 0.8102\n",
            "Epoch 85, Batch 185/224, Training Loss: 1.2465\n",
            "Epoch 85, Batch 186/224, Training Loss: 0.3720\n",
            "Epoch 85, Batch 187/224, Training Loss: 0.3446\n",
            "Epoch 85, Batch 188/224, Training Loss: 0.5069\n",
            "Epoch 85, Batch 189/224, Training Loss: 0.4080\n",
            "Epoch 85, Batch 190/224, Training Loss: 0.3583\n",
            "Epoch 85, Batch 191/224, Training Loss: 0.4277\n",
            "Epoch 85, Batch 192/224, Training Loss: 0.5862\n",
            "Epoch 85, Batch 193/224, Training Loss: 0.4429\n",
            "Epoch 85, Batch 194/224, Training Loss: 0.2138\n",
            "Epoch 85, Batch 195/224, Training Loss: 0.2707\n",
            "Epoch 85, Batch 196/224, Training Loss: 0.4955\n",
            "Epoch 85, Batch 197/224, Training Loss: 0.4447\n",
            "Epoch 85, Batch 198/224, Training Loss: 0.3681\n",
            "Epoch 85, Batch 199/224, Training Loss: 0.3107\n",
            "Epoch 85, Batch 200/224, Training Loss: 0.3462\n",
            "Epoch 85, Batch 201/224, Training Loss: 0.5292\n",
            "Epoch 85, Batch 202/224, Training Loss: 0.4696\n",
            "Epoch 85, Batch 203/224, Training Loss: 0.3013\n",
            "Epoch 85, Batch 204/224, Training Loss: 0.2844\n",
            "Epoch 85, Batch 205/224, Training Loss: 0.6459\n",
            "Epoch 85, Batch 206/224, Training Loss: 0.2333\n",
            "Epoch 85, Batch 207/224, Training Loss: 0.4181\n",
            "Epoch 85, Batch 208/224, Training Loss: 0.4184\n",
            "Epoch 85, Batch 209/224, Training Loss: 0.4013\n",
            "Epoch 85, Batch 210/224, Training Loss: 0.3316\n",
            "Epoch 85, Batch 211/224, Training Loss: 0.4301\n",
            "Epoch 85, Batch 212/224, Training Loss: 0.3554\n",
            "Epoch 85, Batch 213/224, Training Loss: 0.2814\n",
            "Epoch 85, Batch 214/224, Training Loss: 0.5150\n",
            "Epoch 85, Batch 215/224, Training Loss: 0.3919\n",
            "Epoch 85, Batch 216/224, Training Loss: 0.7742\n",
            "Epoch 85, Batch 217/224, Training Loss: 0.3255\n",
            "Epoch 85, Batch 218/224, Training Loss: 0.3113\n",
            "Epoch 85, Batch 219/224, Training Loss: 0.4449\n",
            "Epoch 85, Batch 220/224, Training Loss: 0.3487\n",
            "Epoch 85, Batch 221/224, Training Loss: 0.3159\n",
            "Epoch 85, Batch 222/224, Training Loss: 0.3386\n",
            "Epoch 85, Batch 223/224, Training Loss: 0.8098\n",
            "Epoch 85/100, Training Loss: 0.4120, Test Loss: 3.1560\n",
            "Epoch 86, Batch 0/224, Training Loss: 0.3556\n",
            "Epoch 86, Batch 1/224, Training Loss: 0.3118\n",
            "Epoch 86, Batch 2/224, Training Loss: 0.2996\n",
            "Epoch 86, Batch 3/224, Training Loss: 0.3171\n",
            "Epoch 86, Batch 4/224, Training Loss: 0.3731\n",
            "Epoch 86, Batch 5/224, Training Loss: 0.2294\n",
            "Epoch 86, Batch 6/224, Training Loss: 0.2261\n",
            "Epoch 86, Batch 7/224, Training Loss: 0.5069\n",
            "Epoch 86, Batch 8/224, Training Loss: 0.3508\n",
            "Epoch 86, Batch 9/224, Training Loss: 0.2451\n",
            "Epoch 86, Batch 10/224, Training Loss: 0.5888\n",
            "Epoch 86, Batch 11/224, Training Loss: 0.3322\n",
            "Epoch 86, Batch 12/224, Training Loss: 0.3415\n",
            "Epoch 86, Batch 13/224, Training Loss: 0.3582\n",
            "Epoch 86, Batch 14/224, Training Loss: 0.2760\n",
            "Epoch 86, Batch 15/224, Training Loss: 0.3037\n",
            "Epoch 86, Batch 16/224, Training Loss: 0.3905\n",
            "Epoch 86, Batch 17/224, Training Loss: 0.2362\n",
            "Epoch 86, Batch 18/224, Training Loss: 0.2785\n",
            "Epoch 86, Batch 19/224, Training Loss: 0.5158\n",
            "Epoch 86, Batch 20/224, Training Loss: 0.3482\n",
            "Epoch 86, Batch 21/224, Training Loss: 0.3880\n",
            "Epoch 86, Batch 22/224, Training Loss: 0.4134\n",
            "Epoch 86, Batch 23/224, Training Loss: 0.3673\n",
            "Epoch 86, Batch 24/224, Training Loss: 0.3598\n",
            "Epoch 86, Batch 25/224, Training Loss: 0.5539\n",
            "Epoch 86, Batch 26/224, Training Loss: 0.3091\n",
            "Epoch 86, Batch 27/224, Training Loss: 0.2850\n",
            "Epoch 86, Batch 28/224, Training Loss: 0.3306\n",
            "Epoch 86, Batch 29/224, Training Loss: 0.2902\n",
            "Epoch 86, Batch 30/224, Training Loss: 0.3042\n",
            "Epoch 86, Batch 31/224, Training Loss: 0.3174\n",
            "Epoch 86, Batch 32/224, Training Loss: 0.4184\n",
            "Epoch 86, Batch 33/224, Training Loss: 0.4162\n",
            "Epoch 86, Batch 34/224, Training Loss: 0.2892\n",
            "Epoch 86, Batch 35/224, Training Loss: 0.2702\n",
            "Epoch 86, Batch 36/224, Training Loss: 0.4441\n",
            "Epoch 86, Batch 37/224, Training Loss: 0.3898\n",
            "Epoch 86, Batch 38/224, Training Loss: 0.3646\n",
            "Epoch 86, Batch 39/224, Training Loss: 0.4711\n",
            "Epoch 86, Batch 40/224, Training Loss: 0.4799\n",
            "Epoch 86, Batch 41/224, Training Loss: 0.5379\n",
            "Epoch 86, Batch 42/224, Training Loss: 0.2565\n",
            "Epoch 86, Batch 43/224, Training Loss: 0.3471\n",
            "Epoch 86, Batch 44/224, Training Loss: 0.4881\n",
            "Epoch 86, Batch 45/224, Training Loss: 0.2100\n",
            "Epoch 86, Batch 46/224, Training Loss: 0.3583\n",
            "Epoch 86, Batch 47/224, Training Loss: 0.3024\n",
            "Epoch 86, Batch 48/224, Training Loss: 0.7904\n",
            "Epoch 86, Batch 49/224, Training Loss: 0.3227\n",
            "Epoch 86, Batch 50/224, Training Loss: 0.2983\n",
            "Epoch 86, Batch 51/224, Training Loss: 0.3812\n",
            "Epoch 86, Batch 52/224, Training Loss: 0.3444\n",
            "Epoch 86, Batch 53/224, Training Loss: 0.5810\n",
            "Epoch 86, Batch 54/224, Training Loss: 0.3802\n",
            "Epoch 86, Batch 55/224, Training Loss: 0.2589\n",
            "Epoch 86, Batch 56/224, Training Loss: 0.4732\n",
            "Epoch 86, Batch 57/224, Training Loss: 0.3179\n",
            "Epoch 86, Batch 58/224, Training Loss: 0.3296\n",
            "Epoch 86, Batch 59/224, Training Loss: 0.3620\n",
            "Epoch 86, Batch 60/224, Training Loss: 0.2972\n",
            "Epoch 86, Batch 61/224, Training Loss: 0.3283\n",
            "Epoch 86, Batch 62/224, Training Loss: 0.3433\n",
            "Epoch 86, Batch 63/224, Training Loss: 0.4685\n",
            "Epoch 86, Batch 64/224, Training Loss: 0.2763\n",
            "Epoch 86, Batch 65/224, Training Loss: 0.4179\n",
            "Epoch 86, Batch 66/224, Training Loss: 0.6774\n",
            "Epoch 86, Batch 67/224, Training Loss: 0.3572\n",
            "Epoch 86, Batch 68/224, Training Loss: 0.7107\n",
            "Epoch 86, Batch 69/224, Training Loss: 0.3045\n",
            "Epoch 86, Batch 70/224, Training Loss: 0.3371\n",
            "Epoch 86, Batch 71/224, Training Loss: 0.5601\n",
            "Epoch 86, Batch 72/224, Training Loss: 0.3006\n",
            "Epoch 86, Batch 73/224, Training Loss: 0.2318\n",
            "Epoch 86, Batch 74/224, Training Loss: 0.2618\n",
            "Epoch 86, Batch 75/224, Training Loss: 0.3639\n",
            "Epoch 86, Batch 76/224, Training Loss: 0.5951\n",
            "Epoch 86, Batch 77/224, Training Loss: 0.5486\n",
            "Epoch 86, Batch 78/224, Training Loss: 0.3712\n",
            "Epoch 86, Batch 79/224, Training Loss: 0.3128\n",
            "Epoch 86, Batch 80/224, Training Loss: 0.4041\n",
            "Epoch 86, Batch 81/224, Training Loss: 0.3042\n",
            "Epoch 86, Batch 82/224, Training Loss: 0.4866\n",
            "Epoch 86, Batch 83/224, Training Loss: 0.4044\n",
            "Epoch 86, Batch 84/224, Training Loss: 0.2692\n",
            "Epoch 86, Batch 85/224, Training Loss: 0.3403\n",
            "Epoch 86, Batch 86/224, Training Loss: 0.7115\n",
            "Epoch 86, Batch 87/224, Training Loss: 0.4675\n",
            "Epoch 86, Batch 88/224, Training Loss: 0.5383\n",
            "Epoch 86, Batch 89/224, Training Loss: 0.2812\n",
            "Epoch 86, Batch 90/224, Training Loss: 0.4832\n",
            "Epoch 86, Batch 91/224, Training Loss: 0.3591\n",
            "Epoch 86, Batch 92/224, Training Loss: 0.6582\n",
            "Epoch 86, Batch 93/224, Training Loss: 0.6115\n",
            "Epoch 86, Batch 94/224, Training Loss: 0.5442\n",
            "Epoch 86, Batch 95/224, Training Loss: 0.3240\n",
            "Epoch 86, Batch 96/224, Training Loss: 0.2999\n",
            "Epoch 86, Batch 97/224, Training Loss: 0.2768\n",
            "Epoch 86, Batch 98/224, Training Loss: 0.3120\n",
            "Epoch 86, Batch 99/224, Training Loss: 0.3770\n",
            "Epoch 86, Batch 100/224, Training Loss: 0.3329\n",
            "Epoch 86, Batch 101/224, Training Loss: 0.4489\n",
            "Epoch 86, Batch 102/224, Training Loss: 0.3229\n",
            "Epoch 86, Batch 103/224, Training Loss: 0.4536\n",
            "Epoch 86, Batch 104/224, Training Loss: 0.2883\n",
            "Epoch 86, Batch 105/224, Training Loss: 0.3568\n",
            "Epoch 86, Batch 106/224, Training Loss: 0.3432\n",
            "Epoch 86, Batch 107/224, Training Loss: 0.5257\n",
            "Epoch 86, Batch 108/224, Training Loss: 0.4742\n",
            "Epoch 86, Batch 109/224, Training Loss: 0.4748\n",
            "Epoch 86, Batch 110/224, Training Loss: 0.5032\n",
            "Epoch 86, Batch 111/224, Training Loss: 0.5547\n",
            "Epoch 86, Batch 112/224, Training Loss: 0.5633\n",
            "Epoch 86, Batch 113/224, Training Loss: 0.4562\n",
            "Epoch 86, Batch 114/224, Training Loss: 0.8236\n",
            "Epoch 86, Batch 115/224, Training Loss: 0.4008\n",
            "Epoch 86, Batch 116/224, Training Loss: 0.4454\n",
            "Epoch 86, Batch 117/224, Training Loss: 0.3933\n",
            "Epoch 86, Batch 118/224, Training Loss: 0.3940\n",
            "Epoch 86, Batch 119/224, Training Loss: 0.2913\n",
            "Epoch 86, Batch 120/224, Training Loss: 0.7142\n",
            "Epoch 86, Batch 121/224, Training Loss: 0.3136\n",
            "Epoch 86, Batch 122/224, Training Loss: 0.5919\n",
            "Epoch 86, Batch 123/224, Training Loss: 0.3717\n",
            "Epoch 86, Batch 124/224, Training Loss: 0.3488\n",
            "Epoch 86, Batch 125/224, Training Loss: 0.6306\n",
            "Epoch 86, Batch 126/224, Training Loss: 0.7473\n",
            "Epoch 86, Batch 127/224, Training Loss: 0.3797\n",
            "Epoch 86, Batch 128/224, Training Loss: 0.4492\n",
            "Epoch 86, Batch 129/224, Training Loss: 0.3182\n",
            "Epoch 86, Batch 130/224, Training Loss: 0.3334\n",
            "Epoch 86, Batch 131/224, Training Loss: 1.2445\n",
            "Epoch 86, Batch 132/224, Training Loss: 0.5921\n",
            "Epoch 86, Batch 133/224, Training Loss: 0.3625\n",
            "Epoch 86, Batch 134/224, Training Loss: 0.3668\n",
            "Epoch 86, Batch 135/224, Training Loss: 0.5456\n",
            "Epoch 86, Batch 136/224, Training Loss: 0.3486\n",
            "Epoch 86, Batch 137/224, Training Loss: 0.2694\n",
            "Epoch 86, Batch 138/224, Training Loss: 0.2602\n",
            "Epoch 86, Batch 139/224, Training Loss: 0.2878\n",
            "Epoch 86, Batch 140/224, Training Loss: 0.3211\n",
            "Epoch 86, Batch 141/224, Training Loss: 0.3242\n",
            "Epoch 86, Batch 142/224, Training Loss: 0.3806\n",
            "Epoch 86, Batch 143/224, Training Loss: 0.4359\n",
            "Epoch 86, Batch 144/224, Training Loss: 0.3821\n",
            "Epoch 86, Batch 145/224, Training Loss: 0.3677\n",
            "Epoch 86, Batch 146/224, Training Loss: 0.3464\n",
            "Epoch 86, Batch 147/224, Training Loss: 0.2841\n",
            "Epoch 86, Batch 148/224, Training Loss: 0.2943\n",
            "Epoch 86, Batch 149/224, Training Loss: 0.5758\n",
            "Epoch 86, Batch 150/224, Training Loss: 0.4698\n",
            "Epoch 86, Batch 151/224, Training Loss: 0.4332\n",
            "Epoch 86, Batch 152/224, Training Loss: 0.3859\n",
            "Epoch 86, Batch 153/224, Training Loss: 0.3822\n",
            "Epoch 86, Batch 154/224, Training Loss: 0.4230\n",
            "Epoch 86, Batch 155/224, Training Loss: 0.4173\n",
            "Epoch 86, Batch 156/224, Training Loss: 0.3710\n",
            "Epoch 86, Batch 157/224, Training Loss: 0.7012\n",
            "Epoch 86, Batch 158/224, Training Loss: 0.3022\n",
            "Epoch 86, Batch 159/224, Training Loss: 0.3363\n",
            "Epoch 86, Batch 160/224, Training Loss: 0.8490\n",
            "Epoch 86, Batch 161/224, Training Loss: 0.2405\n",
            "Epoch 86, Batch 162/224, Training Loss: 0.2902\n",
            "Epoch 86, Batch 163/224, Training Loss: 0.4664\n",
            "Epoch 86, Batch 164/224, Training Loss: 0.5850\n",
            "Epoch 86, Batch 165/224, Training Loss: 0.3681\n",
            "Epoch 86, Batch 166/224, Training Loss: 0.4894\n",
            "Epoch 86, Batch 167/224, Training Loss: 0.2843\n",
            "Epoch 86, Batch 168/224, Training Loss: 0.3328\n",
            "Epoch 86, Batch 169/224, Training Loss: 0.3569\n",
            "Epoch 86, Batch 170/224, Training Loss: 0.2885\n",
            "Epoch 86, Batch 171/224, Training Loss: 0.4736\n",
            "Epoch 86, Batch 172/224, Training Loss: 0.3949\n",
            "Epoch 86, Batch 173/224, Training Loss: 0.5496\n",
            "Epoch 86, Batch 174/224, Training Loss: 0.4533\n",
            "Epoch 86, Batch 175/224, Training Loss: 0.2863\n",
            "Epoch 86, Batch 176/224, Training Loss: 0.3265\n",
            "Epoch 86, Batch 177/224, Training Loss: 0.2778\n",
            "Epoch 86, Batch 178/224, Training Loss: 0.7530\n",
            "Epoch 86, Batch 179/224, Training Loss: 0.3611\n",
            "Epoch 86, Batch 180/224, Training Loss: 0.4036\n",
            "Epoch 86, Batch 181/224, Training Loss: 0.3588\n",
            "Epoch 86, Batch 182/224, Training Loss: 0.2866\n",
            "Epoch 86, Batch 183/224, Training Loss: 0.3705\n",
            "Epoch 86, Batch 184/224, Training Loss: 0.8130\n",
            "Epoch 86, Batch 185/224, Training Loss: 0.3456\n",
            "Epoch 86, Batch 186/224, Training Loss: 0.4205\n",
            "Epoch 86, Batch 187/224, Training Loss: 0.2741\n",
            "Epoch 86, Batch 188/224, Training Loss: 0.3808\n",
            "Epoch 86, Batch 189/224, Training Loss: 0.2334\n",
            "Epoch 86, Batch 190/224, Training Loss: 0.3493\n",
            "Epoch 86, Batch 191/224, Training Loss: 0.3539\n",
            "Epoch 86, Batch 192/224, Training Loss: 0.2395\n",
            "Epoch 86, Batch 193/224, Training Loss: 0.2466\n",
            "Epoch 86, Batch 194/224, Training Loss: 0.4301\n",
            "Epoch 86, Batch 195/224, Training Loss: 0.3606\n",
            "Epoch 86, Batch 196/224, Training Loss: 0.3852\n",
            "Epoch 86, Batch 197/224, Training Loss: 0.3634\n",
            "Epoch 86, Batch 198/224, Training Loss: 0.3284\n",
            "Epoch 86, Batch 199/224, Training Loss: 0.3904\n",
            "Epoch 86, Batch 200/224, Training Loss: 0.2763\n",
            "Epoch 86, Batch 201/224, Training Loss: 0.3701\n",
            "Epoch 86, Batch 202/224, Training Loss: 0.4039\n",
            "Epoch 86, Batch 203/224, Training Loss: 0.3130\n",
            "Epoch 86, Batch 204/224, Training Loss: 0.7144\n",
            "Epoch 86, Batch 205/224, Training Loss: 0.7669\n",
            "Epoch 86, Batch 206/224, Training Loss: 0.7581\n",
            "Epoch 86, Batch 207/224, Training Loss: 0.3389\n",
            "Epoch 86, Batch 208/224, Training Loss: 0.4135\n",
            "Epoch 86, Batch 209/224, Training Loss: 0.4340\n",
            "Epoch 86, Batch 210/224, Training Loss: 0.4075\n",
            "Epoch 86, Batch 211/224, Training Loss: 0.3188\n",
            "Epoch 86, Batch 212/224, Training Loss: 0.9941\n",
            "Epoch 86, Batch 213/224, Training Loss: 0.5383\n",
            "Epoch 86, Batch 214/224, Training Loss: 0.7167\n",
            "Epoch 86, Batch 215/224, Training Loss: 0.3356\n",
            "Epoch 86, Batch 216/224, Training Loss: 1.2083\n",
            "Epoch 86, Batch 217/224, Training Loss: 0.3222\n",
            "Epoch 86, Batch 218/224, Training Loss: 0.2909\n",
            "Epoch 86, Batch 219/224, Training Loss: 0.3345\n",
            "Epoch 86, Batch 220/224, Training Loss: 0.3112\n",
            "Epoch 86, Batch 221/224, Training Loss: 0.2314\n",
            "Epoch 86, Batch 222/224, Training Loss: 0.2805\n",
            "Epoch 86, Batch 223/224, Training Loss: 0.3812\n",
            "Epoch 86/100, Training Loss: 0.4106, Test Loss: 3.2318\n",
            "Epoch 87, Batch 0/224, Training Loss: 0.6388\n",
            "Epoch 87, Batch 1/224, Training Loss: 0.6116\n",
            "Epoch 87, Batch 2/224, Training Loss: 0.3106\n",
            "Epoch 87, Batch 3/224, Training Loss: 0.3960\n",
            "Epoch 87, Batch 4/224, Training Loss: 0.3698\n",
            "Epoch 87, Batch 5/224, Training Loss: 0.2541\n",
            "Epoch 87, Batch 6/224, Training Loss: 0.3921\n",
            "Epoch 87, Batch 7/224, Training Loss: 0.4923\n",
            "Epoch 87, Batch 8/224, Training Loss: 0.4968\n",
            "Epoch 87, Batch 9/224, Training Loss: 0.2965\n",
            "Epoch 87, Batch 10/224, Training Loss: 0.5029\n",
            "Epoch 87, Batch 11/224, Training Loss: 0.2543\n",
            "Epoch 87, Batch 12/224, Training Loss: 0.3266\n",
            "Epoch 87, Batch 13/224, Training Loss: 0.3778\n",
            "Epoch 87, Batch 14/224, Training Loss: 0.5650\n",
            "Epoch 87, Batch 15/224, Training Loss: 0.8225\n",
            "Epoch 87, Batch 16/224, Training Loss: 0.4444\n",
            "Epoch 87, Batch 17/224, Training Loss: 0.3331\n",
            "Epoch 87, Batch 18/224, Training Loss: 0.2070\n",
            "Epoch 87, Batch 19/224, Training Loss: 0.3804\n",
            "Epoch 87, Batch 20/224, Training Loss: 0.4650\n",
            "Epoch 87, Batch 21/224, Training Loss: 0.2453\n",
            "Epoch 87, Batch 22/224, Training Loss: 0.2941\n",
            "Epoch 87, Batch 23/224, Training Loss: 0.3564\n",
            "Epoch 87, Batch 24/224, Training Loss: 0.3722\n",
            "Epoch 87, Batch 25/224, Training Loss: 0.2201\n",
            "Epoch 87, Batch 26/224, Training Loss: 0.3330\n",
            "Epoch 87, Batch 27/224, Training Loss: 0.2452\n",
            "Epoch 87, Batch 28/224, Training Loss: 0.3656\n",
            "Epoch 87, Batch 29/224, Training Loss: 0.5312\n",
            "Epoch 87, Batch 30/224, Training Loss: 0.4586\n",
            "Epoch 87, Batch 31/224, Training Loss: 0.2355\n",
            "Epoch 87, Batch 32/224, Training Loss: 0.8107\n",
            "Epoch 87, Batch 33/224, Training Loss: 0.2726\n",
            "Epoch 87, Batch 34/224, Training Loss: 0.4538\n",
            "Epoch 87, Batch 35/224, Training Loss: 0.7314\n",
            "Epoch 87, Batch 36/224, Training Loss: 0.4120\n",
            "Epoch 87, Batch 37/224, Training Loss: 0.9330\n",
            "Epoch 87, Batch 38/224, Training Loss: 0.3153\n",
            "Epoch 87, Batch 39/224, Training Loss: 0.3031\n",
            "Epoch 87, Batch 40/224, Training Loss: 0.3279\n",
            "Epoch 87, Batch 41/224, Training Loss: 0.2981\n",
            "Epoch 87, Batch 42/224, Training Loss: 0.2271\n",
            "Epoch 87, Batch 43/224, Training Loss: 0.3745\n",
            "Epoch 87, Batch 44/224, Training Loss: 0.2957\n",
            "Epoch 87, Batch 45/224, Training Loss: 0.2910\n",
            "Epoch 87, Batch 46/224, Training Loss: 0.3573\n",
            "Epoch 87, Batch 47/224, Training Loss: 0.3844\n",
            "Epoch 87, Batch 48/224, Training Loss: 0.3416\n",
            "Epoch 87, Batch 49/224, Training Loss: 0.5705\n",
            "Epoch 87, Batch 50/224, Training Loss: 0.5488\n",
            "Epoch 87, Batch 51/224, Training Loss: 0.2887\n",
            "Epoch 87, Batch 52/224, Training Loss: 0.2898\n",
            "Epoch 87, Batch 53/224, Training Loss: 0.3681\n",
            "Epoch 87, Batch 54/224, Training Loss: 0.3621\n",
            "Epoch 87, Batch 55/224, Training Loss: 0.5456\n",
            "Epoch 87, Batch 56/224, Training Loss: 0.3933\n",
            "Epoch 87, Batch 57/224, Training Loss: 0.3077\n",
            "Epoch 87, Batch 58/224, Training Loss: 0.3375\n",
            "Epoch 87, Batch 59/224, Training Loss: 0.5996\n",
            "Epoch 87, Batch 60/224, Training Loss: 0.3092\n",
            "Epoch 87, Batch 61/224, Training Loss: 0.2826\n",
            "Epoch 87, Batch 62/224, Training Loss: 0.2318\n",
            "Epoch 87, Batch 63/224, Training Loss: 0.3945\n",
            "Epoch 87, Batch 64/224, Training Loss: 0.9250\n",
            "Epoch 87, Batch 65/224, Training Loss: 0.2588\n",
            "Epoch 87, Batch 66/224, Training Loss: 0.6784\n",
            "Epoch 87, Batch 67/224, Training Loss: 0.2544\n",
            "Epoch 87, Batch 68/224, Training Loss: 0.3565\n",
            "Epoch 87, Batch 69/224, Training Loss: 0.5848\n",
            "Epoch 87, Batch 70/224, Training Loss: 0.3523\n",
            "Epoch 87, Batch 71/224, Training Loss: 0.3798\n",
            "Epoch 87, Batch 72/224, Training Loss: 0.4547\n",
            "Epoch 87, Batch 73/224, Training Loss: 0.3099\n",
            "Epoch 87, Batch 74/224, Training Loss: 0.3683\n",
            "Epoch 87, Batch 75/224, Training Loss: 0.5182\n",
            "Epoch 87, Batch 76/224, Training Loss: 0.3462\n",
            "Epoch 87, Batch 77/224, Training Loss: 0.4579\n",
            "Epoch 87, Batch 78/224, Training Loss: 0.4823\n",
            "Epoch 87, Batch 79/224, Training Loss: 0.2503\n",
            "Epoch 87, Batch 80/224, Training Loss: 0.3118\n",
            "Epoch 87, Batch 81/224, Training Loss: 0.3032\n",
            "Epoch 87, Batch 82/224, Training Loss: 0.4458\n",
            "Epoch 87, Batch 83/224, Training Loss: 0.3156\n",
            "Epoch 87, Batch 84/224, Training Loss: 0.6822\n",
            "Epoch 87, Batch 85/224, Training Loss: 0.3404\n",
            "Epoch 87, Batch 86/224, Training Loss: 0.2477\n",
            "Epoch 87, Batch 87/224, Training Loss: 0.3328\n",
            "Epoch 87, Batch 88/224, Training Loss: 0.4288\n",
            "Epoch 87, Batch 89/224, Training Loss: 0.3733\n",
            "Epoch 87, Batch 90/224, Training Loss: 0.3152\n",
            "Epoch 87, Batch 91/224, Training Loss: 0.2413\n",
            "Epoch 87, Batch 92/224, Training Loss: 0.4204\n",
            "Epoch 87, Batch 93/224, Training Loss: 0.3183\n",
            "Epoch 87, Batch 94/224, Training Loss: 0.4925\n",
            "Epoch 87, Batch 95/224, Training Loss: 0.2575\n",
            "Epoch 87, Batch 96/224, Training Loss: 0.2646\n",
            "Epoch 87, Batch 97/224, Training Loss: 0.8915\n",
            "Epoch 87, Batch 98/224, Training Loss: 0.6539\n",
            "Epoch 87, Batch 99/224, Training Loss: 0.3318\n",
            "Epoch 87, Batch 100/224, Training Loss: 0.4630\n",
            "Epoch 87, Batch 101/224, Training Loss: 0.5730\n",
            "Epoch 87, Batch 102/224, Training Loss: 0.2684\n",
            "Epoch 87, Batch 103/224, Training Loss: 0.3733\n",
            "Epoch 87, Batch 104/224, Training Loss: 0.4032\n",
            "Epoch 87, Batch 105/224, Training Loss: 0.2946\n",
            "Epoch 87, Batch 106/224, Training Loss: 0.2640\n",
            "Epoch 87, Batch 107/224, Training Loss: 0.5866\n",
            "Epoch 87, Batch 108/224, Training Loss: 0.7251\n",
            "Epoch 87, Batch 109/224, Training Loss: 0.3101\n",
            "Epoch 87, Batch 110/224, Training Loss: 0.4471\n",
            "Epoch 87, Batch 111/224, Training Loss: 0.7743\n",
            "Epoch 87, Batch 112/224, Training Loss: 0.3244\n",
            "Epoch 87, Batch 113/224, Training Loss: 0.6285\n",
            "Epoch 87, Batch 114/224, Training Loss: 0.3905\n",
            "Epoch 87, Batch 115/224, Training Loss: 0.4449\n",
            "Epoch 87, Batch 116/224, Training Loss: 0.2825\n",
            "Epoch 87, Batch 117/224, Training Loss: 0.2831\n",
            "Epoch 87, Batch 118/224, Training Loss: 0.3050\n",
            "Epoch 87, Batch 119/224, Training Loss: 0.3854\n",
            "Epoch 87, Batch 120/224, Training Loss: 0.3116\n",
            "Epoch 87, Batch 121/224, Training Loss: 0.3269\n",
            "Epoch 87, Batch 122/224, Training Loss: 0.3648\n",
            "Epoch 87, Batch 123/224, Training Loss: 0.3457\n",
            "Epoch 87, Batch 124/224, Training Loss: 0.7593\n",
            "Epoch 87, Batch 125/224, Training Loss: 0.2449\n",
            "Epoch 87, Batch 126/224, Training Loss: 0.2937\n",
            "Epoch 87, Batch 127/224, Training Loss: 0.5240\n",
            "Epoch 87, Batch 128/224, Training Loss: 0.3305\n",
            "Epoch 87, Batch 129/224, Training Loss: 0.3229\n",
            "Epoch 87, Batch 130/224, Training Loss: 0.5540\n",
            "Epoch 87, Batch 131/224, Training Loss: 0.3820\n",
            "Epoch 87, Batch 132/224, Training Loss: 0.4760\n",
            "Epoch 87, Batch 133/224, Training Loss: 0.3299\n",
            "Epoch 87, Batch 134/224, Training Loss: 0.3822\n",
            "Epoch 87, Batch 135/224, Training Loss: 0.2291\n",
            "Epoch 87, Batch 136/224, Training Loss: 0.3913\n",
            "Epoch 87, Batch 137/224, Training Loss: 0.3438\n",
            "Epoch 87, Batch 138/224, Training Loss: 0.7817\n",
            "Epoch 87, Batch 139/224, Training Loss: 0.4091\n",
            "Epoch 87, Batch 140/224, Training Loss: 0.6055\n",
            "Epoch 87, Batch 141/224, Training Loss: 0.6046\n",
            "Epoch 87, Batch 142/224, Training Loss: 0.3106\n",
            "Epoch 87, Batch 143/224, Training Loss: 0.3947\n",
            "Epoch 87, Batch 144/224, Training Loss: 0.4101\n",
            "Epoch 87, Batch 145/224, Training Loss: 0.3517\n",
            "Epoch 87, Batch 146/224, Training Loss: 0.4515\n",
            "Epoch 87, Batch 147/224, Training Loss: 0.3676\n",
            "Epoch 87, Batch 148/224, Training Loss: 0.3770\n",
            "Epoch 87, Batch 149/224, Training Loss: 0.5881\n",
            "Epoch 87, Batch 150/224, Training Loss: 0.2119\n",
            "Epoch 87, Batch 151/224, Training Loss: 0.3796\n",
            "Epoch 87, Batch 152/224, Training Loss: 0.4311\n",
            "Epoch 87, Batch 153/224, Training Loss: 0.2845\n",
            "Epoch 87, Batch 154/224, Training Loss: 0.3729\n",
            "Epoch 87, Batch 155/224, Training Loss: 0.8852\n",
            "Epoch 87, Batch 156/224, Training Loss: 0.6569\n",
            "Epoch 87, Batch 157/224, Training Loss: 0.4248\n",
            "Epoch 87, Batch 158/224, Training Loss: 0.2858\n",
            "Epoch 87, Batch 159/224, Training Loss: 0.3776\n",
            "Epoch 87, Batch 160/224, Training Loss: 0.4141\n",
            "Epoch 87, Batch 161/224, Training Loss: 0.2982\n",
            "Epoch 87, Batch 162/224, Training Loss: 0.2611\n",
            "Epoch 87, Batch 163/224, Training Loss: 0.3306\n",
            "Epoch 87, Batch 164/224, Training Loss: 0.2497\n",
            "Epoch 87, Batch 165/224, Training Loss: 0.3914\n",
            "Epoch 87, Batch 166/224, Training Loss: 0.3912\n",
            "Epoch 87, Batch 167/224, Training Loss: 0.2560\n",
            "Epoch 87, Batch 168/224, Training Loss: 0.3491\n",
            "Epoch 87, Batch 169/224, Training Loss: 0.4321\n",
            "Epoch 87, Batch 170/224, Training Loss: 0.2702\n",
            "Epoch 87, Batch 171/224, Training Loss: 0.3194\n",
            "Epoch 87, Batch 172/224, Training Loss: 0.2423\n",
            "Epoch 87, Batch 173/224, Training Loss: 0.3729\n",
            "Epoch 87, Batch 174/224, Training Loss: 0.2776\n",
            "Epoch 87, Batch 175/224, Training Loss: 0.4289\n",
            "Epoch 87, Batch 176/224, Training Loss: 0.3248\n",
            "Epoch 87, Batch 177/224, Training Loss: 0.3065\n",
            "Epoch 87, Batch 178/224, Training Loss: 0.4618\n",
            "Epoch 87, Batch 179/224, Training Loss: 0.3568\n",
            "Epoch 87, Batch 180/224, Training Loss: 0.3553\n",
            "Epoch 87, Batch 181/224, Training Loss: 0.8344\n",
            "Epoch 87, Batch 182/224, Training Loss: 0.4192\n",
            "Epoch 87, Batch 183/224, Training Loss: 0.4330\n",
            "Epoch 87, Batch 184/224, Training Loss: 0.2032\n",
            "Epoch 87, Batch 185/224, Training Loss: 0.4141\n",
            "Epoch 87, Batch 186/224, Training Loss: 0.4713\n",
            "Epoch 87, Batch 187/224, Training Loss: 0.2660\n",
            "Epoch 87, Batch 188/224, Training Loss: 0.4263\n",
            "Epoch 87, Batch 189/224, Training Loss: 0.3128\n",
            "Epoch 87, Batch 190/224, Training Loss: 0.4069\n",
            "Epoch 87, Batch 191/224, Training Loss: 0.4790\n",
            "Epoch 87, Batch 192/224, Training Loss: 0.4004\n",
            "Epoch 87, Batch 193/224, Training Loss: 0.2764\n",
            "Epoch 87, Batch 194/224, Training Loss: 0.2587\n",
            "Epoch 87, Batch 195/224, Training Loss: 0.5429\n",
            "Epoch 87, Batch 196/224, Training Loss: 0.3412\n",
            "Epoch 87, Batch 197/224, Training Loss: 0.5001\n",
            "Epoch 87, Batch 198/224, Training Loss: 0.3589\n",
            "Epoch 87, Batch 199/224, Training Loss: 0.5165\n",
            "Epoch 87, Batch 200/224, Training Loss: 0.3511\n",
            "Epoch 87, Batch 201/224, Training Loss: 0.6162\n",
            "Epoch 87, Batch 202/224, Training Loss: 0.2976\n",
            "Epoch 87, Batch 203/224, Training Loss: 0.2529\n",
            "Epoch 87, Batch 204/224, Training Loss: 0.3228\n",
            "Epoch 87, Batch 205/224, Training Loss: 0.3106\n",
            "Epoch 87, Batch 206/224, Training Loss: 0.3822\n",
            "Epoch 87, Batch 207/224, Training Loss: 0.6557\n",
            "Epoch 87, Batch 208/224, Training Loss: 0.5910\n",
            "Epoch 87, Batch 209/224, Training Loss: 0.4214\n",
            "Epoch 87, Batch 210/224, Training Loss: 0.4644\n",
            "Epoch 87, Batch 211/224, Training Loss: 0.3585\n",
            "Epoch 87, Batch 212/224, Training Loss: 0.5243\n",
            "Epoch 87, Batch 213/224, Training Loss: 0.4167\n",
            "Epoch 87, Batch 214/224, Training Loss: 0.5283\n",
            "Epoch 87, Batch 215/224, Training Loss: 0.2209\n",
            "Epoch 87, Batch 216/224, Training Loss: 0.3579\n",
            "Epoch 87, Batch 217/224, Training Loss: 0.4510\n",
            "Epoch 87, Batch 218/224, Training Loss: 0.3698\n",
            "Epoch 87, Batch 219/224, Training Loss: 0.3346\n",
            "Epoch 87, Batch 220/224, Training Loss: 0.3955\n",
            "Epoch 87, Batch 221/224, Training Loss: 0.5247\n",
            "Epoch 87, Batch 222/224, Training Loss: 0.3150\n",
            "Epoch 87, Batch 223/224, Training Loss: 0.3341\n",
            "Epoch 87/100, Training Loss: 0.4047, Test Loss: 3.1820\n",
            "Epoch 88, Batch 0/224, Training Loss: 0.2922\n",
            "Epoch 88, Batch 1/224, Training Loss: 0.2996\n",
            "Epoch 88, Batch 2/224, Training Loss: 0.3066\n",
            "Epoch 88, Batch 3/224, Training Loss: 0.4961\n",
            "Epoch 88, Batch 4/224, Training Loss: 0.3208\n",
            "Epoch 88, Batch 5/224, Training Loss: 0.3939\n",
            "Epoch 88, Batch 6/224, Training Loss: 0.4287\n",
            "Epoch 88, Batch 7/224, Training Loss: 0.5005\n",
            "Epoch 88, Batch 8/224, Training Loss: 0.3504\n",
            "Epoch 88, Batch 9/224, Training Loss: 0.3360\n",
            "Epoch 88, Batch 10/224, Training Loss: 0.4817\n",
            "Epoch 88, Batch 11/224, Training Loss: 0.3532\n",
            "Epoch 88, Batch 12/224, Training Loss: 0.3248\n",
            "Epoch 88, Batch 13/224, Training Loss: 0.7031\n",
            "Epoch 88, Batch 14/224, Training Loss: 0.3375\n",
            "Epoch 88, Batch 15/224, Training Loss: 0.3622\n",
            "Epoch 88, Batch 16/224, Training Loss: 0.3481\n",
            "Epoch 88, Batch 17/224, Training Loss: 0.3239\n",
            "Epoch 88, Batch 18/224, Training Loss: 0.2719\n",
            "Epoch 88, Batch 19/224, Training Loss: 0.2710\n",
            "Epoch 88, Batch 20/224, Training Loss: 0.2543\n",
            "Epoch 88, Batch 21/224, Training Loss: 0.5339\n",
            "Epoch 88, Batch 22/224, Training Loss: 0.4528\n",
            "Epoch 88, Batch 23/224, Training Loss: 0.5219\n",
            "Epoch 88, Batch 24/224, Training Loss: 0.5808\n",
            "Epoch 88, Batch 25/224, Training Loss: 0.1913\n",
            "Epoch 88, Batch 26/224, Training Loss: 0.5816\n",
            "Epoch 88, Batch 27/224, Training Loss: 0.4775\n",
            "Epoch 88, Batch 28/224, Training Loss: 0.3567\n",
            "Epoch 88, Batch 29/224, Training Loss: 0.3301\n",
            "Epoch 88, Batch 30/224, Training Loss: 0.4137\n",
            "Epoch 88, Batch 31/224, Training Loss: 0.3611\n",
            "Epoch 88, Batch 32/224, Training Loss: 0.2749\n",
            "Epoch 88, Batch 33/224, Training Loss: 0.2565\n",
            "Epoch 88, Batch 34/224, Training Loss: 0.3970\n",
            "Epoch 88, Batch 35/224, Training Loss: 0.2417\n",
            "Epoch 88, Batch 36/224, Training Loss: 0.3624\n",
            "Epoch 88, Batch 37/224, Training Loss: 0.2874\n",
            "Epoch 88, Batch 38/224, Training Loss: 0.4700\n",
            "Epoch 88, Batch 39/224, Training Loss: 0.2678\n",
            "Epoch 88, Batch 40/224, Training Loss: 0.3203\n",
            "Epoch 88, Batch 41/224, Training Loss: 0.2669\n",
            "Epoch 88, Batch 42/224, Training Loss: 0.2775\n",
            "Epoch 88, Batch 43/224, Training Loss: 0.2513\n",
            "Epoch 88, Batch 44/224, Training Loss: 0.3518\n",
            "Epoch 88, Batch 45/224, Training Loss: 0.3382\n",
            "Epoch 88, Batch 46/224, Training Loss: 0.3604\n",
            "Epoch 88, Batch 47/224, Training Loss: 0.3329\n",
            "Epoch 88, Batch 48/224, Training Loss: 0.3884\n",
            "Epoch 88, Batch 49/224, Training Loss: 0.3101\n",
            "Epoch 88, Batch 50/224, Training Loss: 0.2440\n",
            "Epoch 88, Batch 51/224, Training Loss: 0.4202\n",
            "Epoch 88, Batch 52/224, Training Loss: 0.5030\n",
            "Epoch 88, Batch 53/224, Training Loss: 0.3281\n",
            "Epoch 88, Batch 54/224, Training Loss: 0.3381\n",
            "Epoch 88, Batch 55/224, Training Loss: 0.3287\n",
            "Epoch 88, Batch 56/224, Training Loss: 0.4348\n",
            "Epoch 88, Batch 57/224, Training Loss: 0.3353\n",
            "Epoch 88, Batch 58/224, Training Loss: 0.3161\n",
            "Epoch 88, Batch 59/224, Training Loss: 0.3397\n",
            "Epoch 88, Batch 60/224, Training Loss: 0.3831\n",
            "Epoch 88, Batch 61/224, Training Loss: 0.3575\n",
            "Epoch 88, Batch 62/224, Training Loss: 0.2812\n",
            "Epoch 88, Batch 63/224, Training Loss: 0.3877\n",
            "Epoch 88, Batch 64/224, Training Loss: 0.2522\n",
            "Epoch 88, Batch 65/224, Training Loss: 0.2719\n",
            "Epoch 88, Batch 66/224, Training Loss: 0.2653\n",
            "Epoch 88, Batch 67/224, Training Loss: 0.4635\n",
            "Epoch 88, Batch 68/224, Training Loss: 0.2623\n",
            "Epoch 88, Batch 69/224, Training Loss: 0.5882\n",
            "Epoch 88, Batch 70/224, Training Loss: 0.2973\n",
            "Epoch 88, Batch 71/224, Training Loss: 0.3791\n",
            "Epoch 88, Batch 72/224, Training Loss: 0.3705\n",
            "Epoch 88, Batch 73/224, Training Loss: 0.3019\n",
            "Epoch 88, Batch 74/224, Training Loss: 0.3901\n",
            "Epoch 88, Batch 75/224, Training Loss: 0.3544\n",
            "Epoch 88, Batch 76/224, Training Loss: 0.2565\n",
            "Epoch 88, Batch 77/224, Training Loss: 0.4845\n",
            "Epoch 88, Batch 78/224, Training Loss: 0.6807\n",
            "Epoch 88, Batch 79/224, Training Loss: 0.9668\n",
            "Epoch 88, Batch 80/224, Training Loss: 0.5814\n",
            "Epoch 88, Batch 81/224, Training Loss: 0.5245\n",
            "Epoch 88, Batch 82/224, Training Loss: 0.3720\n",
            "Epoch 88, Batch 83/224, Training Loss: 0.2702\n",
            "Epoch 88, Batch 84/224, Training Loss: 0.3249\n",
            "Epoch 88, Batch 85/224, Training Loss: 0.3326\n",
            "Epoch 88, Batch 86/224, Training Loss: 0.3701\n",
            "Epoch 88, Batch 87/224, Training Loss: 0.7292\n",
            "Epoch 88, Batch 88/224, Training Loss: 0.3279\n",
            "Epoch 88, Batch 89/224, Training Loss: 0.2875\n",
            "Epoch 88, Batch 90/224, Training Loss: 0.3190\n",
            "Epoch 88, Batch 91/224, Training Loss: 0.4424\n",
            "Epoch 88, Batch 92/224, Training Loss: 0.3839\n",
            "Epoch 88, Batch 93/224, Training Loss: 0.3182\n",
            "Epoch 88, Batch 94/224, Training Loss: 0.2627\n",
            "Epoch 88, Batch 95/224, Training Loss: 0.3400\n",
            "Epoch 88, Batch 96/224, Training Loss: 0.3905\n",
            "Epoch 88, Batch 97/224, Training Loss: 0.3843\n",
            "Epoch 88, Batch 98/224, Training Loss: 0.1848\n",
            "Epoch 88, Batch 99/224, Training Loss: 0.3366\n",
            "Epoch 88, Batch 100/224, Training Loss: 0.4932\n",
            "Epoch 88, Batch 101/224, Training Loss: 0.9412\n",
            "Epoch 88, Batch 102/224, Training Loss: 0.2991\n",
            "Epoch 88, Batch 103/224, Training Loss: 0.7722\n",
            "Epoch 88, Batch 104/224, Training Loss: 0.4681\n",
            "Epoch 88, Batch 105/224, Training Loss: 0.3455\n",
            "Epoch 88, Batch 106/224, Training Loss: 0.3998\n",
            "Epoch 88, Batch 107/224, Training Loss: 0.3801\n",
            "Epoch 88, Batch 108/224, Training Loss: 0.3690\n",
            "Epoch 88, Batch 109/224, Training Loss: 0.4550\n",
            "Epoch 88, Batch 110/224, Training Loss: 0.4353\n",
            "Epoch 88, Batch 111/224, Training Loss: 0.3723\n",
            "Epoch 88, Batch 112/224, Training Loss: 0.3535\n",
            "Epoch 88, Batch 113/224, Training Loss: 0.4048\n",
            "Epoch 88, Batch 114/224, Training Loss: 0.2225\n",
            "Epoch 88, Batch 115/224, Training Loss: 0.4783\n",
            "Epoch 88, Batch 116/224, Training Loss: 0.3060\n",
            "Epoch 88, Batch 117/224, Training Loss: 0.3294\n",
            "Epoch 88, Batch 118/224, Training Loss: 0.2534\n",
            "Epoch 88, Batch 119/224, Training Loss: 0.3523\n",
            "Epoch 88, Batch 120/224, Training Loss: 0.2254\n",
            "Epoch 88, Batch 121/224, Training Loss: 0.5824\n",
            "Epoch 88, Batch 122/224, Training Loss: 0.5202\n",
            "Epoch 88, Batch 123/224, Training Loss: 0.3363\n",
            "Epoch 88, Batch 124/224, Training Loss: 0.4736\n",
            "Epoch 88, Batch 125/224, Training Loss: 0.3732\n",
            "Epoch 88, Batch 126/224, Training Loss: 0.5332\n",
            "Epoch 88, Batch 127/224, Training Loss: 0.3235\n",
            "Epoch 88, Batch 128/224, Training Loss: 0.4040\n",
            "Epoch 88, Batch 129/224, Training Loss: 0.2286\n",
            "Epoch 88, Batch 130/224, Training Loss: 0.4830\n",
            "Epoch 88, Batch 131/224, Training Loss: 0.4490\n",
            "Epoch 88, Batch 132/224, Training Loss: 0.3832\n",
            "Epoch 88, Batch 133/224, Training Loss: 0.3248\n",
            "Epoch 88, Batch 134/224, Training Loss: 0.4607\n",
            "Epoch 88, Batch 135/224, Training Loss: 0.3642\n",
            "Epoch 88, Batch 136/224, Training Loss: 0.3596\n",
            "Epoch 88, Batch 137/224, Training Loss: 0.3318\n",
            "Epoch 88, Batch 138/224, Training Loss: 0.5684\n",
            "Epoch 88, Batch 139/224, Training Loss: 0.4150\n",
            "Epoch 88, Batch 140/224, Training Loss: 0.3465\n",
            "Epoch 88, Batch 141/224, Training Loss: 0.3919\n",
            "Epoch 88, Batch 142/224, Training Loss: 0.4926\n",
            "Epoch 88, Batch 143/224, Training Loss: 0.4234\n",
            "Epoch 88, Batch 144/224, Training Loss: 0.5033\n",
            "Epoch 88, Batch 145/224, Training Loss: 0.3170\n",
            "Epoch 88, Batch 146/224, Training Loss: 0.5017\n",
            "Epoch 88, Batch 147/224, Training Loss: 0.6591\n",
            "Epoch 88, Batch 148/224, Training Loss: 0.3459\n",
            "Epoch 88, Batch 149/224, Training Loss: 0.3815\n",
            "Epoch 88, Batch 150/224, Training Loss: 0.5530\n",
            "Epoch 88, Batch 151/224, Training Loss: 0.2951\n",
            "Epoch 88, Batch 152/224, Training Loss: 0.2901\n",
            "Epoch 88, Batch 153/224, Training Loss: 0.3662\n",
            "Epoch 88, Batch 154/224, Training Loss: 1.0327\n",
            "Epoch 88, Batch 155/224, Training Loss: 0.4516\n",
            "Epoch 88, Batch 156/224, Training Loss: 0.4321\n",
            "Epoch 88, Batch 157/224, Training Loss: 0.5601\n",
            "Epoch 88, Batch 158/224, Training Loss: 0.3160\n",
            "Epoch 88, Batch 159/224, Training Loss: 0.5147\n",
            "Epoch 88, Batch 160/224, Training Loss: 0.2941\n",
            "Epoch 88, Batch 161/224, Training Loss: 0.5224\n",
            "Epoch 88, Batch 162/224, Training Loss: 0.3283\n",
            "Epoch 88, Batch 163/224, Training Loss: 0.3378\n",
            "Epoch 88, Batch 164/224, Training Loss: 0.4374\n",
            "Epoch 88, Batch 165/224, Training Loss: 0.4026\n",
            "Epoch 88, Batch 166/224, Training Loss: 0.3780\n",
            "Epoch 88, Batch 167/224, Training Loss: 0.3470\n",
            "Epoch 88, Batch 168/224, Training Loss: 0.3199\n",
            "Epoch 88, Batch 169/224, Training Loss: 0.4010\n",
            "Epoch 88, Batch 170/224, Training Loss: 0.2934\n",
            "Epoch 88, Batch 171/224, Training Loss: 0.3677\n",
            "Epoch 88, Batch 172/224, Training Loss: 0.4701\n",
            "Epoch 88, Batch 173/224, Training Loss: 0.5475\n",
            "Epoch 88, Batch 174/224, Training Loss: 0.3682\n",
            "Epoch 88, Batch 175/224, Training Loss: 0.6845\n",
            "Epoch 88, Batch 176/224, Training Loss: 0.3912\n",
            "Epoch 88, Batch 177/224, Training Loss: 0.3173\n",
            "Epoch 88, Batch 178/224, Training Loss: 0.5927\n",
            "Epoch 88, Batch 179/224, Training Loss: 0.4834\n",
            "Epoch 88, Batch 180/224, Training Loss: 0.3855\n",
            "Epoch 88, Batch 181/224, Training Loss: 0.3928\n",
            "Epoch 88, Batch 182/224, Training Loss: 0.4430\n",
            "Epoch 88, Batch 183/224, Training Loss: 0.3008\n",
            "Epoch 88, Batch 184/224, Training Loss: 0.7900\n",
            "Epoch 88, Batch 185/224, Training Loss: 0.5791\n",
            "Epoch 88, Batch 186/224, Training Loss: 0.3515\n",
            "Epoch 88, Batch 187/224, Training Loss: 0.6003\n",
            "Epoch 88, Batch 188/224, Training Loss: 0.8896\n",
            "Epoch 88, Batch 189/224, Training Loss: 0.2641\n",
            "Epoch 88, Batch 190/224, Training Loss: 0.4075\n",
            "Epoch 88, Batch 191/224, Training Loss: 0.3468\n",
            "Epoch 88, Batch 192/224, Training Loss: 0.5266\n",
            "Epoch 88, Batch 193/224, Training Loss: 0.2596\n",
            "Epoch 88, Batch 194/224, Training Loss: 0.2759\n",
            "Epoch 88, Batch 195/224, Training Loss: 0.4327\n",
            "Epoch 88, Batch 196/224, Training Loss: 0.2876\n",
            "Epoch 88, Batch 197/224, Training Loss: 0.3062\n",
            "Epoch 88, Batch 198/224, Training Loss: 0.6338\n",
            "Epoch 88, Batch 199/224, Training Loss: 0.3403\n",
            "Epoch 88, Batch 200/224, Training Loss: 0.3339\n",
            "Epoch 88, Batch 201/224, Training Loss: 0.4339\n",
            "Epoch 88, Batch 202/224, Training Loss: 0.5356\n",
            "Epoch 88, Batch 203/224, Training Loss: 0.4068\n",
            "Epoch 88, Batch 204/224, Training Loss: 0.3238\n",
            "Epoch 88, Batch 205/224, Training Loss: 0.4182\n",
            "Epoch 88, Batch 206/224, Training Loss: 0.3124\n",
            "Epoch 88, Batch 207/224, Training Loss: 0.3142\n",
            "Epoch 88, Batch 208/224, Training Loss: 0.6182\n",
            "Epoch 88, Batch 209/224, Training Loss: 0.4101\n",
            "Epoch 88, Batch 210/224, Training Loss: 1.0123\n",
            "Epoch 88, Batch 211/224, Training Loss: 0.3225\n",
            "Epoch 88, Batch 212/224, Training Loss: 0.3733\n",
            "Epoch 88, Batch 213/224, Training Loss: 0.4157\n",
            "Epoch 88, Batch 214/224, Training Loss: 0.9855\n",
            "Epoch 88, Batch 215/224, Training Loss: 0.3237\n",
            "Epoch 88, Batch 216/224, Training Loss: 0.3937\n",
            "Epoch 88, Batch 217/224, Training Loss: 0.4245\n",
            "Epoch 88, Batch 218/224, Training Loss: 0.2596\n",
            "Epoch 88, Batch 219/224, Training Loss: 0.2755\n",
            "Epoch 88, Batch 220/224, Training Loss: 0.2741\n",
            "Epoch 88, Batch 221/224, Training Loss: 0.6073\n",
            "Epoch 88, Batch 222/224, Training Loss: 0.3599\n",
            "Epoch 88, Batch 223/224, Training Loss: 0.3839\n",
            "Epoch 88/100, Training Loss: 0.4051, Test Loss: 3.1962\n",
            "Epoch 89, Batch 0/224, Training Loss: 0.3670\n",
            "Epoch 89, Batch 1/224, Training Loss: 0.4517\n",
            "Epoch 89, Batch 2/224, Training Loss: 0.3262\n",
            "Epoch 89, Batch 3/224, Training Loss: 0.2436\n",
            "Epoch 89, Batch 4/224, Training Loss: 0.2972\n",
            "Epoch 89, Batch 5/224, Training Loss: 0.3691\n",
            "Epoch 89, Batch 6/224, Training Loss: 0.5948\n",
            "Epoch 89, Batch 7/224, Training Loss: 0.9996\n",
            "Epoch 89, Batch 8/224, Training Loss: 0.4465\n",
            "Epoch 89, Batch 9/224, Training Loss: 0.4281\n",
            "Epoch 89, Batch 10/224, Training Loss: 0.3570\n",
            "Epoch 89, Batch 11/224, Training Loss: 0.3382\n",
            "Epoch 89, Batch 12/224, Training Loss: 0.3323\n",
            "Epoch 89, Batch 13/224, Training Loss: 0.3059\n",
            "Epoch 89, Batch 14/224, Training Loss: 0.3171\n",
            "Epoch 89, Batch 15/224, Training Loss: 0.3353\n",
            "Epoch 89, Batch 16/224, Training Loss: 0.2319\n",
            "Epoch 89, Batch 17/224, Training Loss: 0.6131\n",
            "Epoch 89, Batch 18/224, Training Loss: 0.3635\n",
            "Epoch 89, Batch 19/224, Training Loss: 0.2962\n",
            "Epoch 89, Batch 20/224, Training Loss: 0.2357\n",
            "Epoch 89, Batch 21/224, Training Loss: 0.4826\n",
            "Epoch 89, Batch 22/224, Training Loss: 0.3638\n",
            "Epoch 89, Batch 23/224, Training Loss: 0.2861\n",
            "Epoch 89, Batch 24/224, Training Loss: 0.3546\n",
            "Epoch 89, Batch 25/224, Training Loss: 0.2298\n",
            "Epoch 89, Batch 26/224, Training Loss: 0.3628\n",
            "Epoch 89, Batch 27/224, Training Loss: 0.3848\n",
            "Epoch 89, Batch 28/224, Training Loss: 0.3291\n",
            "Epoch 89, Batch 29/224, Training Loss: 0.3146\n",
            "Epoch 89, Batch 30/224, Training Loss: 0.3643\n",
            "Epoch 89, Batch 31/224, Training Loss: 0.4040\n",
            "Epoch 89, Batch 32/224, Training Loss: 0.3358\n",
            "Epoch 89, Batch 33/224, Training Loss: 0.2756\n",
            "Epoch 89, Batch 34/224, Training Loss: 0.5929\n",
            "Epoch 89, Batch 35/224, Training Loss: 0.3714\n",
            "Epoch 89, Batch 36/224, Training Loss: 0.4229\n",
            "Epoch 89, Batch 37/224, Training Loss: 0.3839\n",
            "Epoch 89, Batch 38/224, Training Loss: 0.4998\n",
            "Epoch 89, Batch 39/224, Training Loss: 0.7980\n",
            "Epoch 89, Batch 40/224, Training Loss: 0.7297\n",
            "Epoch 89, Batch 41/224, Training Loss: 0.3064\n",
            "Epoch 89, Batch 42/224, Training Loss: 0.3655\n",
            "Epoch 89, Batch 43/224, Training Loss: 0.4364\n",
            "Epoch 89, Batch 44/224, Training Loss: 0.4466\n",
            "Epoch 89, Batch 45/224, Training Loss: 0.4834\n",
            "Epoch 89, Batch 46/224, Training Loss: 0.3016\n",
            "Epoch 89, Batch 47/224, Training Loss: 0.2842\n",
            "Epoch 89, Batch 48/224, Training Loss: 0.2556\n",
            "Epoch 89, Batch 49/224, Training Loss: 0.4882\n",
            "Epoch 89, Batch 50/224, Training Loss: 0.4750\n",
            "Epoch 89, Batch 51/224, Training Loss: 0.7998\n",
            "Epoch 89, Batch 52/224, Training Loss: 0.5019\n",
            "Epoch 89, Batch 53/224, Training Loss: 0.5837\n",
            "Epoch 89, Batch 54/224, Training Loss: 0.3054\n",
            "Epoch 89, Batch 55/224, Training Loss: 0.4586\n",
            "Epoch 89, Batch 56/224, Training Loss: 0.3510\n",
            "Epoch 89, Batch 57/224, Training Loss: 0.3023\n",
            "Epoch 89, Batch 58/224, Training Loss: 0.5278\n",
            "Epoch 89, Batch 59/224, Training Loss: 0.4578\n",
            "Epoch 89, Batch 60/224, Training Loss: 0.2790\n",
            "Epoch 89, Batch 61/224, Training Loss: 0.8548\n",
            "Epoch 89, Batch 62/224, Training Loss: 0.3040\n",
            "Epoch 89, Batch 63/224, Training Loss: 0.2881\n",
            "Epoch 89, Batch 64/224, Training Loss: 0.3308\n",
            "Epoch 89, Batch 65/224, Training Loss: 0.3603\n",
            "Epoch 89, Batch 66/224, Training Loss: 0.4003\n",
            "Epoch 89, Batch 67/224, Training Loss: 0.2692\n",
            "Epoch 89, Batch 68/224, Training Loss: 0.2723\n",
            "Epoch 89, Batch 69/224, Training Loss: 0.3383\n",
            "Epoch 89, Batch 70/224, Training Loss: 0.2385\n",
            "Epoch 89, Batch 71/224, Training Loss: 0.2946\n",
            "Epoch 89, Batch 72/224, Training Loss: 0.5466\n",
            "Epoch 89, Batch 73/224, Training Loss: 0.4083\n",
            "Epoch 89, Batch 74/224, Training Loss: 0.3906\n",
            "Epoch 89, Batch 75/224, Training Loss: 0.2794\n",
            "Epoch 89, Batch 76/224, Training Loss: 0.2324\n",
            "Epoch 89, Batch 77/224, Training Loss: 0.2866\n",
            "Epoch 89, Batch 78/224, Training Loss: 0.3529\n",
            "Epoch 89, Batch 79/224, Training Loss: 0.4234\n",
            "Epoch 89, Batch 80/224, Training Loss: 0.2922\n",
            "Epoch 89, Batch 81/224, Training Loss: 0.4859\n",
            "Epoch 89, Batch 82/224, Training Loss: 0.2552\n",
            "Epoch 89, Batch 83/224, Training Loss: 0.2995\n",
            "Epoch 89, Batch 84/224, Training Loss: 0.3190\n",
            "Epoch 89, Batch 85/224, Training Loss: 0.2302\n",
            "Epoch 89, Batch 86/224, Training Loss: 0.3300\n",
            "Epoch 89, Batch 87/224, Training Loss: 0.7969\n",
            "Epoch 89, Batch 88/224, Training Loss: 0.4312\n",
            "Epoch 89, Batch 89/224, Training Loss: 0.3048\n",
            "Epoch 89, Batch 90/224, Training Loss: 0.2787\n",
            "Epoch 89, Batch 91/224, Training Loss: 0.5104\n",
            "Epoch 89, Batch 92/224, Training Loss: 0.2946\n",
            "Epoch 89, Batch 93/224, Training Loss: 0.5017\n",
            "Epoch 89, Batch 94/224, Training Loss: 0.3678\n",
            "Epoch 89, Batch 95/224, Training Loss: 0.3341\n",
            "Epoch 89, Batch 96/224, Training Loss: 0.2804\n",
            "Epoch 89, Batch 97/224, Training Loss: 0.2829\n",
            "Epoch 89, Batch 98/224, Training Loss: 0.3255\n",
            "Epoch 89, Batch 99/224, Training Loss: 0.5237\n",
            "Epoch 89, Batch 100/224, Training Loss: 0.3135\n",
            "Epoch 89, Batch 101/224, Training Loss: 0.4736\n",
            "Epoch 89, Batch 102/224, Training Loss: 0.4081\n",
            "Epoch 89, Batch 103/224, Training Loss: 1.0393\n",
            "Epoch 89, Batch 104/224, Training Loss: 0.4095\n",
            "Epoch 89, Batch 105/224, Training Loss: 0.6590\n",
            "Epoch 89, Batch 106/224, Training Loss: 0.3237\n",
            "Epoch 89, Batch 107/224, Training Loss: 0.4697\n",
            "Epoch 89, Batch 108/224, Training Loss: 0.4715\n",
            "Epoch 89, Batch 109/224, Training Loss: 0.3601\n",
            "Epoch 89, Batch 110/224, Training Loss: 0.3532\n",
            "Epoch 89, Batch 111/224, Training Loss: 0.3667\n",
            "Epoch 89, Batch 112/224, Training Loss: 0.3792\n",
            "Epoch 89, Batch 113/224, Training Loss: 0.3299\n",
            "Epoch 89, Batch 114/224, Training Loss: 0.3444\n",
            "Epoch 89, Batch 115/224, Training Loss: 0.3489\n",
            "Epoch 89, Batch 116/224, Training Loss: 0.3527\n",
            "Epoch 89, Batch 117/224, Training Loss: 0.4181\n",
            "Epoch 89, Batch 118/224, Training Loss: 0.9207\n",
            "Epoch 89, Batch 119/224, Training Loss: 0.3601\n",
            "Epoch 89, Batch 120/224, Training Loss: 0.2341\n",
            "Epoch 89, Batch 121/224, Training Loss: 0.2960\n",
            "Epoch 89, Batch 122/224, Training Loss: 0.3938\n",
            "Epoch 89, Batch 123/224, Training Loss: 0.3473\n",
            "Epoch 89, Batch 124/224, Training Loss: 0.6669\n",
            "Epoch 89, Batch 125/224, Training Loss: 0.2592\n",
            "Epoch 89, Batch 126/224, Training Loss: 0.3352\n",
            "Epoch 89, Batch 127/224, Training Loss: 0.2150\n",
            "Epoch 89, Batch 128/224, Training Loss: 0.7604\n",
            "Epoch 89, Batch 129/224, Training Loss: 0.3474\n",
            "Epoch 89, Batch 130/224, Training Loss: 0.4228\n",
            "Epoch 89, Batch 131/224, Training Loss: 0.3245\n",
            "Epoch 89, Batch 132/224, Training Loss: 0.3838\n",
            "Epoch 89, Batch 133/224, Training Loss: 0.2387\n",
            "Epoch 89, Batch 134/224, Training Loss: 0.5504\n",
            "Epoch 89, Batch 135/224, Training Loss: 0.4551\n",
            "Epoch 89, Batch 136/224, Training Loss: 0.3423\n",
            "Epoch 89, Batch 137/224, Training Loss: 0.3630\n",
            "Epoch 89, Batch 138/224, Training Loss: 0.3784\n",
            "Epoch 89, Batch 139/224, Training Loss: 0.3793\n",
            "Epoch 89, Batch 140/224, Training Loss: 0.8058\n",
            "Epoch 89, Batch 141/224, Training Loss: 0.2547\n",
            "Epoch 89, Batch 142/224, Training Loss: 0.2706\n",
            "Epoch 89, Batch 143/224, Training Loss: 0.2648\n",
            "Epoch 89, Batch 144/224, Training Loss: 0.8140\n",
            "Epoch 89, Batch 145/224, Training Loss: 0.4838\n",
            "Epoch 89, Batch 146/224, Training Loss: 0.3851\n",
            "Epoch 89, Batch 147/224, Training Loss: 0.3154\n",
            "Epoch 89, Batch 148/224, Training Loss: 0.3305\n",
            "Epoch 89, Batch 149/224, Training Loss: 0.4028\n",
            "Epoch 89, Batch 150/224, Training Loss: 0.4406\n",
            "Epoch 89, Batch 151/224, Training Loss: 0.4112\n",
            "Epoch 89, Batch 152/224, Training Loss: 0.6183\n",
            "Epoch 89, Batch 153/224, Training Loss: 0.3908\n",
            "Epoch 89, Batch 154/224, Training Loss: 0.5948\n",
            "Epoch 89, Batch 155/224, Training Loss: 0.3591\n",
            "Epoch 89, Batch 156/224, Training Loss: 0.3362\n",
            "Epoch 89, Batch 157/224, Training Loss: 0.3979\n",
            "Epoch 89, Batch 158/224, Training Loss: 0.4883\n",
            "Epoch 89, Batch 159/224, Training Loss: 0.3901\n",
            "Epoch 89, Batch 160/224, Training Loss: 0.3376\n",
            "Epoch 89, Batch 161/224, Training Loss: 0.5145\n",
            "Epoch 89, Batch 162/224, Training Loss: 0.3431\n",
            "Epoch 89, Batch 163/224, Training Loss: 0.4022\n",
            "Epoch 89, Batch 164/224, Training Loss: 0.2907\n",
            "Epoch 89, Batch 165/224, Training Loss: 0.3582\n",
            "Epoch 89, Batch 166/224, Training Loss: 0.3448\n",
            "Epoch 89, Batch 167/224, Training Loss: 0.2622\n",
            "Epoch 89, Batch 168/224, Training Loss: 0.5467\n",
            "Epoch 89, Batch 169/224, Training Loss: 0.6738\n",
            "Epoch 89, Batch 170/224, Training Loss: 0.5182\n",
            "Epoch 89, Batch 171/224, Training Loss: 0.4177\n",
            "Epoch 89, Batch 172/224, Training Loss: 0.3163\n",
            "Epoch 89, Batch 173/224, Training Loss: 0.3902\n",
            "Epoch 89, Batch 174/224, Training Loss: 0.2710\n",
            "Epoch 89, Batch 175/224, Training Loss: 0.4305\n",
            "Epoch 89, Batch 176/224, Training Loss: 0.2514\n",
            "Epoch 89, Batch 177/224, Training Loss: 0.4187\n",
            "Epoch 89, Batch 178/224, Training Loss: 0.2942\n",
            "Epoch 89, Batch 179/224, Training Loss: 0.4072\n",
            "Epoch 89, Batch 180/224, Training Loss: 0.3658\n",
            "Epoch 89, Batch 181/224, Training Loss: 0.3063\n",
            "Epoch 89, Batch 182/224, Training Loss: 0.3519\n",
            "Epoch 89, Batch 183/224, Training Loss: 0.4266\n",
            "Epoch 89, Batch 184/224, Training Loss: 0.3007\n",
            "Epoch 89, Batch 185/224, Training Loss: 0.2191\n",
            "Epoch 89, Batch 186/224, Training Loss: 0.2776\n",
            "Epoch 89, Batch 187/224, Training Loss: 0.3504\n",
            "Epoch 89, Batch 188/224, Training Loss: 0.9882\n",
            "Epoch 89, Batch 189/224, Training Loss: 0.2820\n",
            "Epoch 89, Batch 190/224, Training Loss: 0.3240\n",
            "Epoch 89, Batch 191/224, Training Loss: 0.2147\n",
            "Epoch 89, Batch 192/224, Training Loss: 0.2399\n",
            "Epoch 89, Batch 193/224, Training Loss: 0.2755\n",
            "Epoch 89, Batch 194/224, Training Loss: 0.3061\n",
            "Epoch 89, Batch 195/224, Training Loss: 0.3786\n",
            "Epoch 89, Batch 196/224, Training Loss: 0.4055\n",
            "Epoch 89, Batch 197/224, Training Loss: 0.4258\n",
            "Epoch 89, Batch 198/224, Training Loss: 0.4057\n",
            "Epoch 89, Batch 199/224, Training Loss: 0.3762\n",
            "Epoch 89, Batch 200/224, Training Loss: 0.3457\n",
            "Epoch 89, Batch 201/224, Training Loss: 0.3113\n",
            "Epoch 89, Batch 202/224, Training Loss: 0.6145\n",
            "Epoch 89, Batch 203/224, Training Loss: 0.3511\n",
            "Epoch 89, Batch 204/224, Training Loss: 0.5195\n",
            "Epoch 89, Batch 205/224, Training Loss: 0.2852\n",
            "Epoch 89, Batch 206/224, Training Loss: 0.2950\n",
            "Epoch 89, Batch 207/224, Training Loss: 0.7248\n",
            "Epoch 89, Batch 208/224, Training Loss: 0.3058\n",
            "Epoch 89, Batch 209/224, Training Loss: 0.3483\n",
            "Epoch 89, Batch 210/224, Training Loss: 0.4324\n",
            "Epoch 89, Batch 211/224, Training Loss: 0.6484\n",
            "Epoch 89, Batch 212/224, Training Loss: 0.3673\n",
            "Epoch 89, Batch 213/224, Training Loss: 0.3470\n",
            "Epoch 89, Batch 214/224, Training Loss: 0.3701\n",
            "Epoch 89, Batch 215/224, Training Loss: 0.3977\n",
            "Epoch 89, Batch 216/224, Training Loss: 0.3811\n",
            "Epoch 89, Batch 217/224, Training Loss: 0.5973\n",
            "Epoch 89, Batch 218/224, Training Loss: 0.3066\n",
            "Epoch 89, Batch 219/224, Training Loss: 0.3160\n",
            "Epoch 89, Batch 220/224, Training Loss: 0.3801\n",
            "Epoch 89, Batch 221/224, Training Loss: 0.3832\n",
            "Epoch 89, Batch 222/224, Training Loss: 0.4442\n",
            "Epoch 89, Batch 223/224, Training Loss: 0.2438\n",
            "Epoch 89/100, Training Loss: 0.3997, Test Loss: 3.2084\n",
            "Epoch 90, Batch 0/224, Training Loss: 0.4339\n",
            "Epoch 90, Batch 1/224, Training Loss: 0.4835\n",
            "Epoch 90, Batch 2/224, Training Loss: 0.2919\n",
            "Epoch 90, Batch 3/224, Training Loss: 0.3459\n",
            "Epoch 90, Batch 4/224, Training Loss: 0.3941\n",
            "Epoch 90, Batch 5/224, Training Loss: 0.2840\n",
            "Epoch 90, Batch 6/224, Training Loss: 0.5806\n",
            "Epoch 90, Batch 7/224, Training Loss: 0.6108\n",
            "Epoch 90, Batch 8/224, Training Loss: 0.2168\n",
            "Epoch 90, Batch 9/224, Training Loss: 0.4616\n",
            "Epoch 90, Batch 10/224, Training Loss: 0.4142\n",
            "Epoch 90, Batch 11/224, Training Loss: 0.4721\n",
            "Epoch 90, Batch 12/224, Training Loss: 0.3631\n",
            "Epoch 90, Batch 13/224, Training Loss: 0.4855\n",
            "Epoch 90, Batch 14/224, Training Loss: 0.3360\n",
            "Epoch 90, Batch 15/224, Training Loss: 0.2437\n",
            "Epoch 90, Batch 16/224, Training Loss: 0.3540\n",
            "Epoch 90, Batch 17/224, Training Loss: 0.2918\n",
            "Epoch 90, Batch 18/224, Training Loss: 0.4997\n",
            "Epoch 90, Batch 19/224, Training Loss: 0.3934\n",
            "Epoch 90, Batch 20/224, Training Loss: 0.4647\n",
            "Epoch 90, Batch 21/224, Training Loss: 0.9415\n",
            "Epoch 90, Batch 22/224, Training Loss: 0.2927\n",
            "Epoch 90, Batch 23/224, Training Loss: 0.1928\n",
            "Epoch 90, Batch 24/224, Training Loss: 0.5646\n",
            "Epoch 90, Batch 25/224, Training Loss: 0.4927\n",
            "Epoch 90, Batch 26/224, Training Loss: 0.3387\n",
            "Epoch 90, Batch 27/224, Training Loss: 0.3386\n",
            "Epoch 90, Batch 28/224, Training Loss: 0.4168\n",
            "Epoch 90, Batch 29/224, Training Loss: 0.6272\n",
            "Epoch 90, Batch 30/224, Training Loss: 0.3781\n",
            "Epoch 90, Batch 31/224, Training Loss: 0.4205\n",
            "Epoch 90, Batch 32/224, Training Loss: 0.5269\n",
            "Epoch 90, Batch 33/224, Training Loss: 0.3167\n",
            "Epoch 90, Batch 34/224, Training Loss: 0.3692\n",
            "Epoch 90, Batch 35/224, Training Loss: 0.3828\n",
            "Epoch 90, Batch 36/224, Training Loss: 0.3704\n",
            "Epoch 90, Batch 37/224, Training Loss: 0.3324\n",
            "Epoch 90, Batch 38/224, Training Loss: 0.2791\n",
            "Epoch 90, Batch 39/224, Training Loss: 0.7801\n",
            "Epoch 90, Batch 40/224, Training Loss: 0.5566\n",
            "Epoch 90, Batch 41/224, Training Loss: 0.4200\n",
            "Epoch 90, Batch 42/224, Training Loss: 0.2593\n",
            "Epoch 90, Batch 43/224, Training Loss: 0.2861\n",
            "Epoch 90, Batch 44/224, Training Loss: 0.3610\n",
            "Epoch 90, Batch 45/224, Training Loss: 0.3561\n",
            "Epoch 90, Batch 46/224, Training Loss: 0.7151\n",
            "Epoch 90, Batch 47/224, Training Loss: 0.2953\n",
            "Epoch 90, Batch 48/224, Training Loss: 0.4865\n",
            "Epoch 90, Batch 49/224, Training Loss: 0.5647\n",
            "Epoch 90, Batch 50/224, Training Loss: 0.3578\n",
            "Epoch 90, Batch 51/224, Training Loss: 0.3220\n",
            "Epoch 90, Batch 52/224, Training Loss: 0.3118\n",
            "Epoch 90, Batch 53/224, Training Loss: 0.3543\n",
            "Epoch 90, Batch 54/224, Training Loss: 0.3066\n",
            "Epoch 90, Batch 55/224, Training Loss: 0.7846\n",
            "Epoch 90, Batch 56/224, Training Loss: 0.3071\n",
            "Epoch 90, Batch 57/224, Training Loss: 0.4120\n",
            "Epoch 90, Batch 58/224, Training Loss: 0.3790\n",
            "Epoch 90, Batch 59/224, Training Loss: 0.3673\n",
            "Epoch 90, Batch 60/224, Training Loss: 0.4433\n",
            "Epoch 90, Batch 61/224, Training Loss: 0.5639\n",
            "Epoch 90, Batch 62/224, Training Loss: 0.3280\n",
            "Epoch 90, Batch 63/224, Training Loss: 0.4187\n",
            "Epoch 90, Batch 64/224, Training Loss: 0.3443\n",
            "Epoch 90, Batch 65/224, Training Loss: 0.5303\n",
            "Epoch 90, Batch 66/224, Training Loss: 0.5515\n",
            "Epoch 90, Batch 67/224, Training Loss: 0.3254\n",
            "Epoch 90, Batch 68/224, Training Loss: 0.3460\n",
            "Epoch 90, Batch 69/224, Training Loss: 0.3418\n",
            "Epoch 90, Batch 70/224, Training Loss: 0.3162\n",
            "Epoch 90, Batch 71/224, Training Loss: 0.3130\n",
            "Epoch 90, Batch 72/224, Training Loss: 0.2481\n",
            "Epoch 90, Batch 73/224, Training Loss: 0.3625\n",
            "Epoch 90, Batch 74/224, Training Loss: 0.2505\n",
            "Epoch 90, Batch 75/224, Training Loss: 0.3847\n",
            "Epoch 90, Batch 76/224, Training Loss: 0.2480\n",
            "Epoch 90, Batch 77/224, Training Loss: 0.3268\n",
            "Epoch 90, Batch 78/224, Training Loss: 0.3043\n",
            "Epoch 90, Batch 79/224, Training Loss: 0.2843\n",
            "Epoch 90, Batch 80/224, Training Loss: 0.3171\n",
            "Epoch 90, Batch 81/224, Training Loss: 0.2689\n",
            "Epoch 90, Batch 82/224, Training Loss: 0.2878\n",
            "Epoch 90, Batch 83/224, Training Loss: 0.3777\n",
            "Epoch 90, Batch 84/224, Training Loss: 0.6321\n",
            "Epoch 90, Batch 85/224, Training Loss: 0.3114\n",
            "Epoch 90, Batch 86/224, Training Loss: 0.3306\n",
            "Epoch 90, Batch 87/224, Training Loss: 0.3621\n",
            "Epoch 90, Batch 88/224, Training Loss: 0.4236\n",
            "Epoch 90, Batch 89/224, Training Loss: 0.3733\n",
            "Epoch 90, Batch 90/224, Training Loss: 0.6195\n",
            "Epoch 90, Batch 91/224, Training Loss: 0.3022\n",
            "Epoch 90, Batch 92/224, Training Loss: 0.4509\n",
            "Epoch 90, Batch 93/224, Training Loss: 0.2728\n",
            "Epoch 90, Batch 94/224, Training Loss: 0.3775\n",
            "Epoch 90, Batch 95/224, Training Loss: 1.0314\n",
            "Epoch 90, Batch 96/224, Training Loss: 0.8552\n",
            "Epoch 90, Batch 97/224, Training Loss: 0.3375\n",
            "Epoch 90, Batch 98/224, Training Loss: 0.6512\n",
            "Epoch 90, Batch 99/224, Training Loss: 0.2929\n",
            "Epoch 90, Batch 100/224, Training Loss: 0.2725\n",
            "Epoch 90, Batch 101/224, Training Loss: 0.5262\n",
            "Epoch 90, Batch 102/224, Training Loss: 0.3418\n",
            "Epoch 90, Batch 103/224, Training Loss: 0.9108\n",
            "Epoch 90, Batch 104/224, Training Loss: 0.4607\n",
            "Epoch 90, Batch 105/224, Training Loss: 0.4428\n",
            "Epoch 90, Batch 106/224, Training Loss: 0.3932\n",
            "Epoch 90, Batch 107/224, Training Loss: 0.3053\n",
            "Epoch 90, Batch 108/224, Training Loss: 0.3619\n",
            "Epoch 90, Batch 109/224, Training Loss: 0.3214\n",
            "Epoch 90, Batch 110/224, Training Loss: 0.4881\n",
            "Epoch 90, Batch 111/224, Training Loss: 0.4216\n",
            "Epoch 90, Batch 112/224, Training Loss: 0.5746\n",
            "Epoch 90, Batch 113/224, Training Loss: 0.3308\n",
            "Epoch 90, Batch 114/224, Training Loss: 0.3785\n",
            "Epoch 90, Batch 115/224, Training Loss: 0.4108\n",
            "Epoch 90, Batch 116/224, Training Loss: 0.5807\n",
            "Epoch 90, Batch 117/224, Training Loss: 0.4283\n",
            "Epoch 90, Batch 118/224, Training Loss: 0.3244\n",
            "Epoch 90, Batch 119/224, Training Loss: 0.3525\n",
            "Epoch 90, Batch 120/224, Training Loss: 0.3455\n",
            "Epoch 90, Batch 121/224, Training Loss: 0.3920\n",
            "Epoch 90, Batch 122/224, Training Loss: 0.5308\n",
            "Epoch 90, Batch 123/224, Training Loss: 0.2831\n",
            "Epoch 90, Batch 124/224, Training Loss: 0.3740\n",
            "Epoch 90, Batch 125/224, Training Loss: 0.3430\n",
            "Epoch 90, Batch 126/224, Training Loss: 0.7689\n",
            "Epoch 90, Batch 127/224, Training Loss: 0.4480\n",
            "Epoch 90, Batch 128/224, Training Loss: 0.3668\n",
            "Epoch 90, Batch 129/224, Training Loss: 0.3927\n",
            "Epoch 90, Batch 130/224, Training Loss: 0.3684\n",
            "Epoch 90, Batch 131/224, Training Loss: 0.3803\n",
            "Epoch 90, Batch 132/224, Training Loss: 0.3005\n",
            "Epoch 90, Batch 133/224, Training Loss: 0.2349\n",
            "Epoch 90, Batch 134/224, Training Loss: 0.2699\n",
            "Epoch 90, Batch 135/224, Training Loss: 0.2233\n",
            "Epoch 90, Batch 136/224, Training Loss: 0.2699\n",
            "Epoch 90, Batch 137/224, Training Loss: 0.2953\n",
            "Epoch 90, Batch 138/224, Training Loss: 0.3562\n",
            "Epoch 90, Batch 139/224, Training Loss: 0.3376\n",
            "Epoch 90, Batch 140/224, Training Loss: 0.2863\n",
            "Epoch 90, Batch 141/224, Training Loss: 0.4253\n",
            "Epoch 90, Batch 142/224, Training Loss: 0.3911\n",
            "Epoch 90, Batch 143/224, Training Loss: 0.2815\n",
            "Epoch 90, Batch 144/224, Training Loss: 0.2675\n",
            "Epoch 90, Batch 145/224, Training Loss: 0.4566\n",
            "Epoch 90, Batch 146/224, Training Loss: 0.2849\n",
            "Epoch 90, Batch 147/224, Training Loss: 0.3512\n",
            "Epoch 90, Batch 148/224, Training Loss: 0.5998\n",
            "Epoch 90, Batch 149/224, Training Loss: 0.3771\n",
            "Epoch 90, Batch 150/224, Training Loss: 0.4140\n",
            "Epoch 90, Batch 151/224, Training Loss: 0.2510\n",
            "Epoch 90, Batch 152/224, Training Loss: 0.3414\n",
            "Epoch 90, Batch 153/224, Training Loss: 0.2820\n",
            "Epoch 90, Batch 154/224, Training Loss: 0.3679\n",
            "Epoch 90, Batch 155/224, Training Loss: 0.2790\n",
            "Epoch 90, Batch 156/224, Training Loss: 0.3755\n",
            "Epoch 90, Batch 157/224, Training Loss: 0.5267\n",
            "Epoch 90, Batch 158/224, Training Loss: 0.4561\n",
            "Epoch 90, Batch 159/224, Training Loss: 0.3549\n",
            "Epoch 90, Batch 160/224, Training Loss: 0.2884\n",
            "Epoch 90, Batch 161/224, Training Loss: 0.4625\n",
            "Epoch 90, Batch 162/224, Training Loss: 0.2922\n",
            "Epoch 90, Batch 163/224, Training Loss: 0.4458\n",
            "Epoch 90, Batch 164/224, Training Loss: 0.2340\n",
            "Epoch 90, Batch 165/224, Training Loss: 0.4077\n",
            "Epoch 90, Batch 166/224, Training Loss: 0.2582\n",
            "Epoch 90, Batch 167/224, Training Loss: 0.6195\n",
            "Epoch 90, Batch 168/224, Training Loss: 0.6196\n",
            "Epoch 90, Batch 169/224, Training Loss: 0.3435\n",
            "Epoch 90, Batch 170/224, Training Loss: 0.3939\n",
            "Epoch 90, Batch 171/224, Training Loss: 0.2241\n",
            "Epoch 90, Batch 172/224, Training Loss: 0.4335\n",
            "Epoch 90, Batch 173/224, Training Loss: 0.4525\n",
            "Epoch 90, Batch 174/224, Training Loss: 0.5745\n",
            "Epoch 90, Batch 175/224, Training Loss: 0.8281\n",
            "Epoch 90, Batch 176/224, Training Loss: 0.4715\n",
            "Epoch 90, Batch 177/224, Training Loss: 0.4378\n",
            "Epoch 90, Batch 178/224, Training Loss: 0.3115\n",
            "Epoch 90, Batch 179/224, Training Loss: 0.3030\n",
            "Epoch 90, Batch 180/224, Training Loss: 0.2580\n",
            "Epoch 90, Batch 181/224, Training Loss: 0.3572\n",
            "Epoch 90, Batch 182/224, Training Loss: 0.7775\n",
            "Epoch 90, Batch 183/224, Training Loss: 0.4515\n",
            "Epoch 90, Batch 184/224, Training Loss: 0.5546\n",
            "Epoch 90, Batch 185/224, Training Loss: 0.2834\n",
            "Epoch 90, Batch 186/224, Training Loss: 0.4914\n",
            "Epoch 90, Batch 187/224, Training Loss: 0.3632\n",
            "Epoch 90, Batch 188/224, Training Loss: 0.2930\n",
            "Epoch 90, Batch 189/224, Training Loss: 0.3456\n",
            "Epoch 90, Batch 190/224, Training Loss: 0.3146\n",
            "Epoch 90, Batch 191/224, Training Loss: 0.3781\n",
            "Epoch 90, Batch 192/224, Training Loss: 0.3425\n",
            "Epoch 90, Batch 193/224, Training Loss: 0.3840\n",
            "Epoch 90, Batch 194/224, Training Loss: 0.4127\n",
            "Epoch 90, Batch 195/224, Training Loss: 0.2419\n",
            "Epoch 90, Batch 196/224, Training Loss: 0.2480\n",
            "Epoch 90, Batch 197/224, Training Loss: 0.3659\n",
            "Epoch 90, Batch 198/224, Training Loss: 0.4491\n",
            "Epoch 90, Batch 199/224, Training Loss: 0.2135\n",
            "Epoch 90, Batch 200/224, Training Loss: 0.3307\n",
            "Epoch 90, Batch 201/224, Training Loss: 0.3854\n",
            "Epoch 90, Batch 202/224, Training Loss: 0.2842\n",
            "Epoch 90, Batch 203/224, Training Loss: 0.3381\n",
            "Epoch 90, Batch 204/224, Training Loss: 0.3425\n",
            "Epoch 90, Batch 205/224, Training Loss: 0.3836\n",
            "Epoch 90, Batch 206/224, Training Loss: 0.3400\n",
            "Epoch 90, Batch 207/224, Training Loss: 0.4417\n",
            "Epoch 90, Batch 208/224, Training Loss: 0.3839\n",
            "Epoch 90, Batch 209/224, Training Loss: 0.3031\n",
            "Epoch 90, Batch 210/224, Training Loss: 0.3092\n",
            "Epoch 90, Batch 211/224, Training Loss: 0.2582\n",
            "Epoch 90, Batch 212/224, Training Loss: 0.4143\n",
            "Epoch 90, Batch 213/224, Training Loss: 0.5300\n",
            "Epoch 90, Batch 214/224, Training Loss: 0.3186\n",
            "Epoch 90, Batch 215/224, Training Loss: 0.3568\n",
            "Epoch 90, Batch 216/224, Training Loss: 0.2932\n",
            "Epoch 90, Batch 217/224, Training Loss: 1.0786\n",
            "Epoch 90, Batch 218/224, Training Loss: 0.3072\n",
            "Epoch 90, Batch 219/224, Training Loss: 0.3137\n",
            "Epoch 90, Batch 220/224, Training Loss: 0.3405\n",
            "Epoch 90, Batch 221/224, Training Loss: 0.2420\n",
            "Epoch 90, Batch 222/224, Training Loss: 0.3979\n",
            "Epoch 90, Batch 223/224, Training Loss: 0.3815\n",
            "Epoch 90/100, Training Loss: 0.3990, Test Loss: 3.0900\n",
            "Epoch 91, Batch 0/224, Training Loss: 0.4241\n",
            "Epoch 91, Batch 1/224, Training Loss: 0.4620\n",
            "Epoch 91, Batch 2/224, Training Loss: 0.3294\n",
            "Epoch 91, Batch 3/224, Training Loss: 0.4158\n",
            "Epoch 91, Batch 4/224, Training Loss: 0.3775\n",
            "Epoch 91, Batch 5/224, Training Loss: 0.5543\n",
            "Epoch 91, Batch 6/224, Training Loss: 0.5272\n",
            "Epoch 91, Batch 7/224, Training Loss: 0.2115\n",
            "Epoch 91, Batch 8/224, Training Loss: 0.6534\n",
            "Epoch 91, Batch 9/224, Training Loss: 0.2748\n",
            "Epoch 91, Batch 10/224, Training Loss: 0.3503\n",
            "Epoch 91, Batch 11/224, Training Loss: 0.3172\n",
            "Epoch 91, Batch 12/224, Training Loss: 0.3387\n",
            "Epoch 91, Batch 13/224, Training Loss: 0.2297\n",
            "Epoch 91, Batch 14/224, Training Loss: 0.2050\n",
            "Epoch 91, Batch 15/224, Training Loss: 0.4649\n",
            "Epoch 91, Batch 16/224, Training Loss: 0.5374\n",
            "Epoch 91, Batch 17/224, Training Loss: 0.3428\n",
            "Epoch 91, Batch 18/224, Training Loss: 0.2952\n",
            "Epoch 91, Batch 19/224, Training Loss: 0.4450\n",
            "Epoch 91, Batch 20/224, Training Loss: 0.3080\n",
            "Epoch 91, Batch 21/224, Training Loss: 0.3470\n",
            "Epoch 91, Batch 22/224, Training Loss: 0.2791\n",
            "Epoch 91, Batch 23/224, Training Loss: 0.8237\n",
            "Epoch 91, Batch 24/224, Training Loss: 0.4073\n",
            "Epoch 91, Batch 25/224, Training Loss: 0.2300\n",
            "Epoch 91, Batch 26/224, Training Loss: 0.2769\n",
            "Epoch 91, Batch 27/224, Training Loss: 0.2590\n",
            "Epoch 91, Batch 28/224, Training Loss: 0.4003\n",
            "Epoch 91, Batch 29/224, Training Loss: 0.1734\n",
            "Epoch 91, Batch 30/224, Training Loss: 0.3708\n",
            "Epoch 91, Batch 31/224, Training Loss: 0.3003\n",
            "Epoch 91, Batch 32/224, Training Loss: 0.3751\n",
            "Epoch 91, Batch 33/224, Training Loss: 0.3375\n",
            "Epoch 91, Batch 34/224, Training Loss: 0.4999\n",
            "Epoch 91, Batch 35/224, Training Loss: 0.2299\n",
            "Epoch 91, Batch 36/224, Training Loss: 0.2328\n",
            "Epoch 91, Batch 37/224, Training Loss: 0.2800\n",
            "Epoch 91, Batch 38/224, Training Loss: 0.2509\n",
            "Epoch 91, Batch 39/224, Training Loss: 0.2692\n",
            "Epoch 91, Batch 40/224, Training Loss: 0.3227\n",
            "Epoch 91, Batch 41/224, Training Loss: 0.3527\n",
            "Epoch 91, Batch 42/224, Training Loss: 0.2672\n",
            "Epoch 91, Batch 43/224, Training Loss: 0.2787\n",
            "Epoch 91, Batch 44/224, Training Loss: 0.2330\n",
            "Epoch 91, Batch 45/224, Training Loss: 0.3575\n",
            "Epoch 91, Batch 46/224, Training Loss: 0.2956\n",
            "Epoch 91, Batch 47/224, Training Loss: 0.2895\n",
            "Epoch 91, Batch 48/224, Training Loss: 0.3979\n",
            "Epoch 91, Batch 49/224, Training Loss: 0.3498\n",
            "Epoch 91, Batch 50/224, Training Loss: 0.3957\n",
            "Epoch 91, Batch 51/224, Training Loss: 0.3997\n",
            "Epoch 91, Batch 52/224, Training Loss: 0.4421\n",
            "Epoch 91, Batch 53/224, Training Loss: 0.5819\n",
            "Epoch 91, Batch 54/224, Training Loss: 0.4325\n",
            "Epoch 91, Batch 55/224, Training Loss: 0.3257\n",
            "Epoch 91, Batch 56/224, Training Loss: 0.2493\n",
            "Epoch 91, Batch 57/224, Training Loss: 0.2604\n",
            "Epoch 91, Batch 58/224, Training Loss: 0.4128\n",
            "Epoch 91, Batch 59/224, Training Loss: 0.3913\n",
            "Epoch 91, Batch 60/224, Training Loss: 0.2848\n",
            "Epoch 91, Batch 61/224, Training Loss: 0.2733\n",
            "Epoch 91, Batch 62/224, Training Loss: 0.4008\n",
            "Epoch 91, Batch 63/224, Training Loss: 0.3715\n",
            "Epoch 91, Batch 64/224, Training Loss: 0.3965\n",
            "Epoch 91, Batch 65/224, Training Loss: 0.3129\n",
            "Epoch 91, Batch 66/224, Training Loss: 0.2944\n",
            "Epoch 91, Batch 67/224, Training Loss: 0.4404\n",
            "Epoch 91, Batch 68/224, Training Loss: 0.3447\n",
            "Epoch 91, Batch 69/224, Training Loss: 0.5032\n",
            "Epoch 91, Batch 70/224, Training Loss: 0.5928\n",
            "Epoch 91, Batch 71/224, Training Loss: 0.3204\n",
            "Epoch 91, Batch 72/224, Training Loss: 0.5630\n",
            "Epoch 91, Batch 73/224, Training Loss: 0.8481\n",
            "Epoch 91, Batch 74/224, Training Loss: 0.2656\n",
            "Epoch 91, Batch 75/224, Training Loss: 0.3776\n",
            "Epoch 91, Batch 76/224, Training Loss: 0.8061\n",
            "Epoch 91, Batch 77/224, Training Loss: 0.7094\n",
            "Epoch 91, Batch 78/224, Training Loss: 0.2926\n",
            "Epoch 91, Batch 79/224, Training Loss: 0.3449\n",
            "Epoch 91, Batch 80/224, Training Loss: 0.3689\n",
            "Epoch 91, Batch 81/224, Training Loss: 0.3666\n",
            "Epoch 91, Batch 82/224, Training Loss: 0.3237\n",
            "Epoch 91, Batch 83/224, Training Loss: 0.3352\n",
            "Epoch 91, Batch 84/224, Training Loss: 0.2229\n",
            "Epoch 91, Batch 85/224, Training Loss: 0.5465\n",
            "Epoch 91, Batch 86/224, Training Loss: 0.4137\n",
            "Epoch 91, Batch 87/224, Training Loss: 0.2692\n",
            "Epoch 91, Batch 88/224, Training Loss: 0.3777\n",
            "Epoch 91, Batch 89/224, Training Loss: 0.2631\n",
            "Epoch 91, Batch 90/224, Training Loss: 0.2295\n",
            "Epoch 91, Batch 91/224, Training Loss: 0.2306\n",
            "Epoch 91, Batch 92/224, Training Loss: 0.3695\n",
            "Epoch 91, Batch 93/224, Training Loss: 0.2942\n",
            "Epoch 91, Batch 94/224, Training Loss: 0.3867\n",
            "Epoch 91, Batch 95/224, Training Loss: 0.3172\n",
            "Epoch 91, Batch 96/224, Training Loss: 0.3866\n",
            "Epoch 91, Batch 97/224, Training Loss: 0.3771\n",
            "Epoch 91, Batch 98/224, Training Loss: 0.4348\n",
            "Epoch 91, Batch 99/224, Training Loss: 0.4313\n",
            "Epoch 91, Batch 100/224, Training Loss: 0.4545\n",
            "Epoch 91, Batch 101/224, Training Loss: 0.2205\n",
            "Epoch 91, Batch 102/224, Training Loss: 0.2754\n",
            "Epoch 91, Batch 103/224, Training Loss: 0.3492\n",
            "Epoch 91, Batch 104/224, Training Loss: 0.3341\n",
            "Epoch 91, Batch 105/224, Training Loss: 0.3500\n",
            "Epoch 91, Batch 106/224, Training Loss: 0.2718\n",
            "Epoch 91, Batch 107/224, Training Loss: 0.3783\n",
            "Epoch 91, Batch 108/224, Training Loss: 0.4327\n",
            "Epoch 91, Batch 109/224, Training Loss: 0.7180\n",
            "Epoch 91, Batch 110/224, Training Loss: 0.4769\n",
            "Epoch 91, Batch 111/224, Training Loss: 0.3123\n",
            "Epoch 91, Batch 112/224, Training Loss: 0.4116\n",
            "Epoch 91, Batch 113/224, Training Loss: 0.2591\n",
            "Epoch 91, Batch 114/224, Training Loss: 0.3042\n",
            "Epoch 91, Batch 115/224, Training Loss: 0.2903\n",
            "Epoch 91, Batch 116/224, Training Loss: 1.0069\n",
            "Epoch 91, Batch 117/224, Training Loss: 0.8013\n",
            "Epoch 91, Batch 118/224, Training Loss: 0.3923\n",
            "Epoch 91, Batch 119/224, Training Loss: 0.4440\n",
            "Epoch 91, Batch 120/224, Training Loss: 0.2604\n",
            "Epoch 91, Batch 121/224, Training Loss: 0.2899\n",
            "Epoch 91, Batch 122/224, Training Loss: 0.4107\n",
            "Epoch 91, Batch 123/224, Training Loss: 0.3475\n",
            "Epoch 91, Batch 124/224, Training Loss: 0.2133\n",
            "Epoch 91, Batch 125/224, Training Loss: 1.0765\n",
            "Epoch 91, Batch 126/224, Training Loss: 0.3450\n",
            "Epoch 91, Batch 127/224, Training Loss: 0.3848\n",
            "Epoch 91, Batch 128/224, Training Loss: 0.3856\n",
            "Epoch 91, Batch 129/224, Training Loss: 0.3523\n",
            "Epoch 91, Batch 130/224, Training Loss: 0.5310\n",
            "Epoch 91, Batch 131/224, Training Loss: 0.3322\n",
            "Epoch 91, Batch 132/224, Training Loss: 0.7122\n",
            "Epoch 91, Batch 133/224, Training Loss: 0.2966\n",
            "Epoch 91, Batch 134/224, Training Loss: 0.3417\n",
            "Epoch 91, Batch 135/224, Training Loss: 0.3134\n",
            "Epoch 91, Batch 136/224, Training Loss: 0.4000\n",
            "Epoch 91, Batch 137/224, Training Loss: 0.3989\n",
            "Epoch 91, Batch 138/224, Training Loss: 0.4973\n",
            "Epoch 91, Batch 139/224, Training Loss: 0.2842\n",
            "Epoch 91, Batch 140/224, Training Loss: 0.3596\n",
            "Epoch 91, Batch 141/224, Training Loss: 0.4996\n",
            "Epoch 91, Batch 142/224, Training Loss: 0.3395\n",
            "Epoch 91, Batch 143/224, Training Loss: 0.2832\n",
            "Epoch 91, Batch 144/224, Training Loss: 0.2951\n",
            "Epoch 91, Batch 145/224, Training Loss: 0.5093\n",
            "Epoch 91, Batch 146/224, Training Loss: 0.3343\n",
            "Epoch 91, Batch 147/224, Training Loss: 0.3706\n",
            "Epoch 91, Batch 148/224, Training Loss: 0.5281\n",
            "Epoch 91, Batch 149/224, Training Loss: 0.3845\n",
            "Epoch 91, Batch 150/224, Training Loss: 0.3470\n",
            "Epoch 91, Batch 151/224, Training Loss: 0.3505\n",
            "Epoch 91, Batch 152/224, Training Loss: 0.3489\n",
            "Epoch 91, Batch 153/224, Training Loss: 0.2168\n",
            "Epoch 91, Batch 154/224, Training Loss: 0.3743\n",
            "Epoch 91, Batch 155/224, Training Loss: 0.3809\n",
            "Epoch 91, Batch 156/224, Training Loss: 0.3486\n",
            "Epoch 91, Batch 157/224, Training Loss: 0.3719\n",
            "Epoch 91, Batch 158/224, Training Loss: 0.2635\n",
            "Epoch 91, Batch 159/224, Training Loss: 0.9507\n",
            "Epoch 91, Batch 160/224, Training Loss: 0.3583\n",
            "Epoch 91, Batch 161/224, Training Loss: 0.2922\n",
            "Epoch 91, Batch 162/224, Training Loss: 0.3014\n",
            "Epoch 91, Batch 163/224, Training Loss: 0.2623\n",
            "Epoch 91, Batch 164/224, Training Loss: 0.3638\n",
            "Epoch 91, Batch 165/224, Training Loss: 0.2981\n",
            "Epoch 91, Batch 166/224, Training Loss: 0.3348\n",
            "Epoch 91, Batch 167/224, Training Loss: 0.2809\n",
            "Epoch 91, Batch 168/224, Training Loss: 0.1978\n",
            "Epoch 91, Batch 169/224, Training Loss: 1.0920\n",
            "Epoch 91, Batch 170/224, Training Loss: 0.2560\n",
            "Epoch 91, Batch 171/224, Training Loss: 0.3440\n",
            "Epoch 91, Batch 172/224, Training Loss: 0.3006\n",
            "Epoch 91, Batch 173/224, Training Loss: 0.4005\n",
            "Epoch 91, Batch 174/224, Training Loss: 0.3664\n",
            "Epoch 91, Batch 175/224, Training Loss: 0.6260\n",
            "Epoch 91, Batch 176/224, Training Loss: 0.3001\n",
            "Epoch 91, Batch 177/224, Training Loss: 0.5924\n",
            "Epoch 91, Batch 178/224, Training Loss: 0.3988\n",
            "Epoch 91, Batch 179/224, Training Loss: 0.4516\n",
            "Epoch 91, Batch 180/224, Training Loss: 0.4007\n",
            "Epoch 91, Batch 181/224, Training Loss: 0.3009\n",
            "Epoch 91, Batch 182/224, Training Loss: 0.4161\n",
            "Epoch 91, Batch 183/224, Training Loss: 0.6247\n",
            "Epoch 91, Batch 184/224, Training Loss: 0.4598\n",
            "Epoch 91, Batch 185/224, Training Loss: 0.3621\n",
            "Epoch 91, Batch 186/224, Training Loss: 0.4677\n",
            "Epoch 91, Batch 187/224, Training Loss: 0.9618\n",
            "Epoch 91, Batch 188/224, Training Loss: 0.3600\n",
            "Epoch 91, Batch 189/224, Training Loss: 0.2948\n",
            "Epoch 91, Batch 190/224, Training Loss: 0.2441\n",
            "Epoch 91, Batch 191/224, Training Loss: 0.3111\n",
            "Epoch 91, Batch 192/224, Training Loss: 0.4130\n",
            "Epoch 91, Batch 193/224, Training Loss: 0.3734\n",
            "Epoch 91, Batch 194/224, Training Loss: 0.3881\n",
            "Epoch 91, Batch 195/224, Training Loss: 0.3288\n",
            "Epoch 91, Batch 196/224, Training Loss: 0.4472\n",
            "Epoch 91, Batch 197/224, Training Loss: 0.2876\n",
            "Epoch 91, Batch 198/224, Training Loss: 0.3626\n",
            "Epoch 91, Batch 199/224, Training Loss: 0.3195\n",
            "Epoch 91, Batch 200/224, Training Loss: 0.5031\n",
            "Epoch 91, Batch 201/224, Training Loss: 0.2355\n",
            "Epoch 91, Batch 202/224, Training Loss: 0.4836\n",
            "Epoch 91, Batch 203/224, Training Loss: 0.3119\n",
            "Epoch 91, Batch 204/224, Training Loss: 0.5273\n",
            "Epoch 91, Batch 205/224, Training Loss: 0.3854\n",
            "Epoch 91, Batch 206/224, Training Loss: 0.3989\n",
            "Epoch 91, Batch 207/224, Training Loss: 0.2631\n",
            "Epoch 91, Batch 208/224, Training Loss: 0.3135\n",
            "Epoch 91, Batch 209/224, Training Loss: 0.5070\n",
            "Epoch 91, Batch 210/224, Training Loss: 0.2851\n",
            "Epoch 91, Batch 211/224, Training Loss: 0.3204\n",
            "Epoch 91, Batch 212/224, Training Loss: 0.2274\n",
            "Epoch 91, Batch 213/224, Training Loss: 0.3970\n",
            "Epoch 91, Batch 214/224, Training Loss: 0.4069\n",
            "Epoch 91, Batch 215/224, Training Loss: 0.3291\n",
            "Epoch 91, Batch 216/224, Training Loss: 0.2950\n",
            "Epoch 91, Batch 217/224, Training Loss: 0.3230\n",
            "Epoch 91, Batch 218/224, Training Loss: 0.6436\n",
            "Epoch 91, Batch 219/224, Training Loss: 0.4893\n",
            "Epoch 91, Batch 220/224, Training Loss: 0.3142\n",
            "Epoch 91, Batch 221/224, Training Loss: 0.5107\n",
            "Epoch 91, Batch 222/224, Training Loss: 0.5593\n",
            "Epoch 91, Batch 223/224, Training Loss: 0.2887\n",
            "Epoch 91/100, Training Loss: 0.3880, Test Loss: 3.1285\n",
            "Epoch 92, Batch 0/224, Training Loss: 0.3545\n",
            "Epoch 92, Batch 1/224, Training Loss: 0.5649\n",
            "Epoch 92, Batch 2/224, Training Loss: 0.4083\n",
            "Epoch 92, Batch 3/224, Training Loss: 0.3806\n",
            "Epoch 92, Batch 4/224, Training Loss: 0.2970\n",
            "Epoch 92, Batch 5/224, Training Loss: 0.4367\n",
            "Epoch 92, Batch 6/224, Training Loss: 0.2607\n",
            "Epoch 92, Batch 7/224, Training Loss: 0.3090\n",
            "Epoch 92, Batch 8/224, Training Loss: 0.2842\n",
            "Epoch 92, Batch 9/224, Training Loss: 0.3532\n",
            "Epoch 92, Batch 10/224, Training Loss: 0.3811\n",
            "Epoch 92, Batch 11/224, Training Loss: 0.3205\n",
            "Epoch 92, Batch 12/224, Training Loss: 0.4940\n",
            "Epoch 92, Batch 13/224, Training Loss: 0.2747\n",
            "Epoch 92, Batch 14/224, Training Loss: 0.2377\n",
            "Epoch 92, Batch 15/224, Training Loss: 0.4045\n",
            "Epoch 92, Batch 16/224, Training Loss: 0.3149\n",
            "Epoch 92, Batch 17/224, Training Loss: 0.6428\n",
            "Epoch 92, Batch 18/224, Training Loss: 0.5295\n",
            "Epoch 92, Batch 19/224, Training Loss: 0.4292\n",
            "Epoch 92, Batch 20/224, Training Loss: 0.3739\n",
            "Epoch 92, Batch 21/224, Training Loss: 0.3304\n",
            "Epoch 92, Batch 22/224, Training Loss: 0.3742\n",
            "Epoch 92, Batch 23/224, Training Loss: 0.2734\n",
            "Epoch 92, Batch 24/224, Training Loss: 0.5995\n",
            "Epoch 92, Batch 25/224, Training Loss: 0.2849\n",
            "Epoch 92, Batch 26/224, Training Loss: 0.3419\n",
            "Epoch 92, Batch 27/224, Training Loss: 0.3978\n",
            "Epoch 92, Batch 28/224, Training Loss: 0.3314\n",
            "Epoch 92, Batch 29/224, Training Loss: 0.5241\n",
            "Epoch 92, Batch 30/224, Training Loss: 0.3127\n",
            "Epoch 92, Batch 31/224, Training Loss: 0.5304\n",
            "Epoch 92, Batch 32/224, Training Loss: 0.3960\n",
            "Epoch 92, Batch 33/224, Training Loss: 0.3549\n",
            "Epoch 92, Batch 34/224, Training Loss: 0.5126\n",
            "Epoch 92, Batch 35/224, Training Loss: 0.4081\n",
            "Epoch 92, Batch 36/224, Training Loss: 0.3793\n",
            "Epoch 92, Batch 37/224, Training Loss: 0.2845\n",
            "Epoch 92, Batch 38/224, Training Loss: 0.2740\n",
            "Epoch 92, Batch 39/224, Training Loss: 0.3827\n",
            "Epoch 92, Batch 40/224, Training Loss: 0.4111\n",
            "Epoch 92, Batch 41/224, Training Loss: 0.2450\n",
            "Epoch 92, Batch 42/224, Training Loss: 0.3143\n",
            "Epoch 92, Batch 43/224, Training Loss: 0.2893\n",
            "Epoch 92, Batch 44/224, Training Loss: 0.7933\n",
            "Epoch 92, Batch 45/224, Training Loss: 0.3946\n",
            "Epoch 92, Batch 46/224, Training Loss: 0.3001\n",
            "Epoch 92, Batch 47/224, Training Loss: 0.3442\n",
            "Epoch 92, Batch 48/224, Training Loss: 0.3078\n",
            "Epoch 92, Batch 49/224, Training Loss: 0.3485\n",
            "Epoch 92, Batch 50/224, Training Loss: 0.2413\n",
            "Epoch 92, Batch 51/224, Training Loss: 0.3225\n",
            "Epoch 92, Batch 52/224, Training Loss: 0.1931\n",
            "Epoch 92, Batch 53/224, Training Loss: 0.2444\n",
            "Epoch 92, Batch 54/224, Training Loss: 0.3693\n",
            "Epoch 92, Batch 55/224, Training Loss: 0.3386\n",
            "Epoch 92, Batch 56/224, Training Loss: 0.5395\n",
            "Epoch 92, Batch 57/224, Training Loss: 0.2106\n",
            "Epoch 92, Batch 58/224, Training Loss: 0.4722\n",
            "Epoch 92, Batch 59/224, Training Loss: 0.2916\n",
            "Epoch 92, Batch 60/224, Training Loss: 0.3904\n",
            "Epoch 92, Batch 61/224, Training Loss: 0.3528\n",
            "Epoch 92, Batch 62/224, Training Loss: 0.4209\n",
            "Epoch 92, Batch 63/224, Training Loss: 0.5354\n",
            "Epoch 92, Batch 64/224, Training Loss: 0.3169\n",
            "Epoch 92, Batch 65/224, Training Loss: 0.3182\n",
            "Epoch 92, Batch 66/224, Training Loss: 0.2756\n",
            "Epoch 92, Batch 67/224, Training Loss: 0.4356\n",
            "Epoch 92, Batch 68/224, Training Loss: 0.3413\n",
            "Epoch 92, Batch 69/224, Training Loss: 0.2570\n",
            "Epoch 92, Batch 70/224, Training Loss: 0.4997\n",
            "Epoch 92, Batch 71/224, Training Loss: 0.5448\n",
            "Epoch 92, Batch 72/224, Training Loss: 0.2438\n",
            "Epoch 92, Batch 73/224, Training Loss: 0.3398\n",
            "Epoch 92, Batch 74/224, Training Loss: 0.6011\n",
            "Epoch 92, Batch 75/224, Training Loss: 0.4108\n",
            "Epoch 92, Batch 76/224, Training Loss: 0.3044\n",
            "Epoch 92, Batch 77/224, Training Loss: 0.2253\n",
            "Epoch 92, Batch 78/224, Training Loss: 0.2417\n",
            "Epoch 92, Batch 79/224, Training Loss: 0.3376\n",
            "Epoch 92, Batch 80/224, Training Loss: 0.3471\n",
            "Epoch 92, Batch 81/224, Training Loss: 0.3505\n",
            "Epoch 92, Batch 82/224, Training Loss: 0.4668\n",
            "Epoch 92, Batch 83/224, Training Loss: 0.5998\n",
            "Epoch 92, Batch 84/224, Training Loss: 0.2855\n",
            "Epoch 92, Batch 85/224, Training Loss: 0.2043\n",
            "Epoch 92, Batch 86/224, Training Loss: 0.3911\n",
            "Epoch 92, Batch 87/224, Training Loss: 0.3111\n",
            "Epoch 92, Batch 88/224, Training Loss: 0.4301\n",
            "Epoch 92, Batch 89/224, Training Loss: 0.3979\n",
            "Epoch 92, Batch 90/224, Training Loss: 0.3741\n",
            "Epoch 92, Batch 91/224, Training Loss: 0.3918\n",
            "Epoch 92, Batch 92/224, Training Loss: 0.2954\n",
            "Epoch 92, Batch 93/224, Training Loss: 0.3030\n",
            "Epoch 92, Batch 94/224, Training Loss: 0.2919\n",
            "Epoch 92, Batch 95/224, Training Loss: 0.3580\n",
            "Epoch 92, Batch 96/224, Training Loss: 0.2992\n",
            "Epoch 92, Batch 97/224, Training Loss: 0.4519\n",
            "Epoch 92, Batch 98/224, Training Loss: 0.6276\n",
            "Epoch 92, Batch 99/224, Training Loss: 0.2785\n",
            "Epoch 92, Batch 100/224, Training Loss: 0.2279\n",
            "Epoch 92, Batch 101/224, Training Loss: 0.2406\n",
            "Epoch 92, Batch 102/224, Training Loss: 0.2359\n",
            "Epoch 92, Batch 103/224, Training Loss: 0.2606\n",
            "Epoch 92, Batch 104/224, Training Loss: 0.3720\n",
            "Epoch 92, Batch 105/224, Training Loss: 0.4165\n",
            "Epoch 92, Batch 106/224, Training Loss: 0.2493\n",
            "Epoch 92, Batch 107/224, Training Loss: 0.4973\n",
            "Epoch 92, Batch 108/224, Training Loss: 0.3779\n",
            "Epoch 92, Batch 109/224, Training Loss: 0.4071\n",
            "Epoch 92, Batch 110/224, Training Loss: 0.2908\n",
            "Epoch 92, Batch 111/224, Training Loss: 0.4946\n",
            "Epoch 92, Batch 112/224, Training Loss: 0.2639\n",
            "Epoch 92, Batch 113/224, Training Loss: 0.3257\n",
            "Epoch 92, Batch 114/224, Training Loss: 0.5913\n",
            "Epoch 92, Batch 115/224, Training Loss: 0.4768\n",
            "Epoch 92, Batch 116/224, Training Loss: 0.2396\n",
            "Epoch 92, Batch 117/224, Training Loss: 0.3884\n",
            "Epoch 92, Batch 118/224, Training Loss: 0.3349\n",
            "Epoch 92, Batch 119/224, Training Loss: 0.8800\n",
            "Epoch 92, Batch 120/224, Training Loss: 0.3424\n",
            "Epoch 92, Batch 121/224, Training Loss: 0.2796\n",
            "Epoch 92, Batch 122/224, Training Loss: 0.4127\n",
            "Epoch 92, Batch 123/224, Training Loss: 0.2381\n",
            "Epoch 92, Batch 124/224, Training Loss: 0.3231\n",
            "Epoch 92, Batch 125/224, Training Loss: 0.4978\n",
            "Epoch 92, Batch 126/224, Training Loss: 0.9945\n",
            "Epoch 92, Batch 127/224, Training Loss: 0.5090\n",
            "Epoch 92, Batch 128/224, Training Loss: 0.5336\n",
            "Epoch 92, Batch 129/224, Training Loss: 0.3288\n",
            "Epoch 92, Batch 130/224, Training Loss: 0.2408\n",
            "Epoch 92, Batch 131/224, Training Loss: 0.3376\n",
            "Epoch 92, Batch 132/224, Training Loss: 0.7983\n",
            "Epoch 92, Batch 133/224, Training Loss: 0.3647\n",
            "Epoch 92, Batch 134/224, Training Loss: 0.7814\n",
            "Epoch 92, Batch 135/224, Training Loss: 0.3731\n",
            "Epoch 92, Batch 136/224, Training Loss: 0.4653\n",
            "Epoch 92, Batch 137/224, Training Loss: 0.4363\n",
            "Epoch 92, Batch 138/224, Training Loss: 0.4420\n",
            "Epoch 92, Batch 139/224, Training Loss: 0.4021\n",
            "Epoch 92, Batch 140/224, Training Loss: 0.4706\n",
            "Epoch 92, Batch 141/224, Training Loss: 0.2822\n",
            "Epoch 92, Batch 142/224, Training Loss: 0.3854\n",
            "Epoch 92, Batch 143/224, Training Loss: 0.2681\n",
            "Epoch 92, Batch 144/224, Training Loss: 0.3449\n",
            "Epoch 92, Batch 145/224, Training Loss: 0.3543\n",
            "Epoch 92, Batch 146/224, Training Loss: 0.4009\n",
            "Epoch 92, Batch 147/224, Training Loss: 0.2446\n",
            "Epoch 92, Batch 148/224, Training Loss: 0.4232\n",
            "Epoch 92, Batch 149/224, Training Loss: 0.3125\n",
            "Epoch 92, Batch 150/224, Training Loss: 0.3589\n",
            "Epoch 92, Batch 151/224, Training Loss: 0.2854\n",
            "Epoch 92, Batch 152/224, Training Loss: 0.8697\n",
            "Epoch 92, Batch 153/224, Training Loss: 0.3457\n",
            "Epoch 92, Batch 154/224, Training Loss: 0.4622\n",
            "Epoch 92, Batch 155/224, Training Loss: 0.3352\n",
            "Epoch 92, Batch 156/224, Training Loss: 0.2896\n",
            "Epoch 92, Batch 157/224, Training Loss: 0.4389\n",
            "Epoch 92, Batch 158/224, Training Loss: 0.3801\n",
            "Epoch 92, Batch 159/224, Training Loss: 0.4057\n",
            "Epoch 92, Batch 160/224, Training Loss: 0.5389\n",
            "Epoch 92, Batch 161/224, Training Loss: 0.3617\n",
            "Epoch 92, Batch 162/224, Training Loss: 0.3021\n",
            "Epoch 92, Batch 163/224, Training Loss: 0.5856\n",
            "Epoch 92, Batch 164/224, Training Loss: 0.3595\n",
            "Epoch 92, Batch 165/224, Training Loss: 0.3135\n",
            "Epoch 92, Batch 166/224, Training Loss: 0.3087\n",
            "Epoch 92, Batch 167/224, Training Loss: 0.5163\n",
            "Epoch 92, Batch 168/224, Training Loss: 0.2497\n",
            "Epoch 92, Batch 169/224, Training Loss: 0.3993\n",
            "Epoch 92, Batch 170/224, Training Loss: 0.2709\n",
            "Epoch 92, Batch 171/224, Training Loss: 0.3326\n",
            "Epoch 92, Batch 172/224, Training Loss: 0.4096\n",
            "Epoch 92, Batch 173/224, Training Loss: 0.3139\n",
            "Epoch 92, Batch 174/224, Training Loss: 0.3469\n",
            "Epoch 92, Batch 175/224, Training Loss: 0.3538\n",
            "Epoch 92, Batch 176/224, Training Loss: 0.8058\n",
            "Epoch 92, Batch 177/224, Training Loss: 0.2955\n",
            "Epoch 92, Batch 178/224, Training Loss: 0.2460\n",
            "Epoch 92, Batch 179/224, Training Loss: 0.2801\n",
            "Epoch 92, Batch 180/224, Training Loss: 0.4581\n",
            "Epoch 92, Batch 181/224, Training Loss: 0.5154\n",
            "Epoch 92, Batch 182/224, Training Loss: 0.8984\n",
            "Epoch 92, Batch 183/224, Training Loss: 0.4431\n",
            "Epoch 92, Batch 184/224, Training Loss: 0.3414\n",
            "Epoch 92, Batch 185/224, Training Loss: 0.4788\n",
            "Epoch 92, Batch 186/224, Training Loss: 0.3208\n",
            "Epoch 92, Batch 187/224, Training Loss: 0.6339\n",
            "Epoch 92, Batch 188/224, Training Loss: 0.4431\n",
            "Epoch 92, Batch 189/224, Training Loss: 0.3713\n",
            "Epoch 92, Batch 190/224, Training Loss: 0.3035\n",
            "Epoch 92, Batch 191/224, Training Loss: 0.2557\n",
            "Epoch 92, Batch 192/224, Training Loss: 0.3608\n",
            "Epoch 92, Batch 193/224, Training Loss: 0.3645\n",
            "Epoch 92, Batch 194/224, Training Loss: 0.3780\n",
            "Epoch 92, Batch 195/224, Training Loss: 0.7014\n",
            "Epoch 92, Batch 196/224, Training Loss: 0.3067\n",
            "Epoch 92, Batch 197/224, Training Loss: 0.3587\n",
            "Epoch 92, Batch 198/224, Training Loss: 0.4021\n",
            "Epoch 92, Batch 199/224, Training Loss: 0.2362\n",
            "Epoch 92, Batch 200/224, Training Loss: 0.3823\n",
            "Epoch 92, Batch 201/224, Training Loss: 0.3554\n",
            "Epoch 92, Batch 202/224, Training Loss: 0.4629\n",
            "Epoch 92, Batch 203/224, Training Loss: 0.3052\n",
            "Epoch 92, Batch 204/224, Training Loss: 0.4005\n",
            "Epoch 92, Batch 205/224, Training Loss: 0.2659\n",
            "Epoch 92, Batch 206/224, Training Loss: 0.4048\n",
            "Epoch 92, Batch 207/224, Training Loss: 0.3080\n",
            "Epoch 92, Batch 208/224, Training Loss: 0.6289\n",
            "Epoch 92, Batch 209/224, Training Loss: 0.6202\n",
            "Epoch 92, Batch 210/224, Training Loss: 0.3513\n",
            "Epoch 92, Batch 211/224, Training Loss: 0.6543\n",
            "Epoch 92, Batch 212/224, Training Loss: 0.3449\n",
            "Epoch 92, Batch 213/224, Training Loss: 0.6306\n",
            "Epoch 92, Batch 214/224, Training Loss: 0.4723\n",
            "Epoch 92, Batch 215/224, Training Loss: 0.4578\n",
            "Epoch 92, Batch 216/224, Training Loss: 0.6937\n",
            "Epoch 92, Batch 217/224, Training Loss: 0.6307\n",
            "Epoch 92, Batch 218/224, Training Loss: 0.3385\n",
            "Epoch 92, Batch 219/224, Training Loss: 0.3732\n",
            "Epoch 92, Batch 220/224, Training Loss: 0.3577\n",
            "Epoch 92, Batch 221/224, Training Loss: 0.8889\n",
            "Epoch 92, Batch 222/224, Training Loss: 0.6101\n",
            "Epoch 92, Batch 223/224, Training Loss: 0.6681\n",
            "Epoch 92/100, Training Loss: 0.3985, Test Loss: 3.0526\n",
            "Epoch 93, Batch 0/224, Training Loss: 0.7783\n",
            "Epoch 93, Batch 1/224, Training Loss: 0.2716\n",
            "Epoch 93, Batch 2/224, Training Loss: 0.3178\n",
            "Epoch 93, Batch 3/224, Training Loss: 0.3727\n",
            "Epoch 93, Batch 4/224, Training Loss: 0.3172\n",
            "Epoch 93, Batch 5/224, Training Loss: 0.2488\n",
            "Epoch 93, Batch 6/224, Training Loss: 0.3869\n",
            "Epoch 93, Batch 7/224, Training Loss: 0.2256\n",
            "Epoch 93, Batch 8/224, Training Loss: 0.3598\n",
            "Epoch 93, Batch 9/224, Training Loss: 0.5024\n",
            "Epoch 93, Batch 10/224, Training Loss: 0.3147\n",
            "Epoch 93, Batch 11/224, Training Loss: 0.2374\n",
            "Epoch 93, Batch 12/224, Training Loss: 0.3124\n",
            "Epoch 93, Batch 13/224, Training Loss: 0.2718\n",
            "Epoch 93, Batch 14/224, Training Loss: 0.4867\n",
            "Epoch 93, Batch 15/224, Training Loss: 0.2536\n",
            "Epoch 93, Batch 16/224, Training Loss: 0.4066\n",
            "Epoch 93, Batch 17/224, Training Loss: 0.3825\n",
            "Epoch 93, Batch 18/224, Training Loss: 0.2965\n",
            "Epoch 93, Batch 19/224, Training Loss: 0.1979\n",
            "Epoch 93, Batch 20/224, Training Loss: 0.2918\n",
            "Epoch 93, Batch 21/224, Training Loss: 0.2626\n",
            "Epoch 93, Batch 22/224, Training Loss: 0.3540\n",
            "Epoch 93, Batch 23/224, Training Loss: 0.3354\n",
            "Epoch 93, Batch 24/224, Training Loss: 0.7665\n",
            "Epoch 93, Batch 25/224, Training Loss: 0.3045\n",
            "Epoch 93, Batch 26/224, Training Loss: 0.9633\n",
            "Epoch 93, Batch 27/224, Training Loss: 0.2580\n",
            "Epoch 93, Batch 28/224, Training Loss: 0.5578\n",
            "Epoch 93, Batch 29/224, Training Loss: 0.3800\n",
            "Epoch 93, Batch 30/224, Training Loss: 0.3150\n",
            "Epoch 93, Batch 31/224, Training Loss: 0.8529\n",
            "Epoch 93, Batch 32/224, Training Loss: 0.2726\n",
            "Epoch 93, Batch 33/224, Training Loss: 0.7742\n",
            "Epoch 93, Batch 34/224, Training Loss: 0.2536\n",
            "Epoch 93, Batch 35/224, Training Loss: 0.3274\n",
            "Epoch 93, Batch 36/224, Training Loss: 0.3785\n",
            "Epoch 93, Batch 37/224, Training Loss: 0.3055\n",
            "Epoch 93, Batch 38/224, Training Loss: 0.3162\n",
            "Epoch 93, Batch 39/224, Training Loss: 0.3453\n",
            "Epoch 93, Batch 40/224, Training Loss: 0.6309\n",
            "Epoch 93, Batch 41/224, Training Loss: 0.4154\n",
            "Epoch 93, Batch 42/224, Training Loss: 0.3765\n",
            "Epoch 93, Batch 43/224, Training Loss: 0.3165\n",
            "Epoch 93, Batch 44/224, Training Loss: 0.3572\n",
            "Epoch 93, Batch 45/224, Training Loss: 0.2500\n",
            "Epoch 93, Batch 46/224, Training Loss: 0.4545\n",
            "Epoch 93, Batch 47/224, Training Loss: 0.2842\n",
            "Epoch 93, Batch 48/224, Training Loss: 0.3527\n",
            "Epoch 93, Batch 49/224, Training Loss: 0.4075\n",
            "Epoch 93, Batch 50/224, Training Loss: 0.2928\n",
            "Epoch 93, Batch 51/224, Training Loss: 0.6148\n",
            "Epoch 93, Batch 52/224, Training Loss: 0.2535\n",
            "Epoch 93, Batch 53/224, Training Loss: 0.2797\n",
            "Epoch 93, Batch 54/224, Training Loss: 0.2774\n",
            "Epoch 93, Batch 55/224, Training Loss: 0.2614\n",
            "Epoch 93, Batch 56/224, Training Loss: 0.4043\n",
            "Epoch 93, Batch 57/224, Training Loss: 0.4326\n",
            "Epoch 93, Batch 58/224, Training Loss: 0.3948\n",
            "Epoch 93, Batch 59/224, Training Loss: 0.3967\n",
            "Epoch 93, Batch 60/224, Training Loss: 0.2418\n",
            "Epoch 93, Batch 61/224, Training Loss: 0.2054\n",
            "Epoch 93, Batch 62/224, Training Loss: 0.4427\n",
            "Epoch 93, Batch 63/224, Training Loss: 0.2423\n",
            "Epoch 93, Batch 64/224, Training Loss: 0.2836\n",
            "Epoch 93, Batch 65/224, Training Loss: 0.4285\n",
            "Epoch 93, Batch 66/224, Training Loss: 0.3930\n",
            "Epoch 93, Batch 67/224, Training Loss: 0.3364\n",
            "Epoch 93, Batch 68/224, Training Loss: 0.4102\n",
            "Epoch 93, Batch 69/224, Training Loss: 0.3328\n",
            "Epoch 93, Batch 70/224, Training Loss: 0.6339\n",
            "Epoch 93, Batch 71/224, Training Loss: 0.5273\n",
            "Epoch 93, Batch 72/224, Training Loss: 0.4298\n",
            "Epoch 93, Batch 73/224, Training Loss: 0.3565\n",
            "Epoch 93, Batch 74/224, Training Loss: 0.2756\n",
            "Epoch 93, Batch 75/224, Training Loss: 0.3437\n",
            "Epoch 93, Batch 76/224, Training Loss: 0.4215\n",
            "Epoch 93, Batch 77/224, Training Loss: 0.3099\n",
            "Epoch 93, Batch 78/224, Training Loss: 0.3254\n",
            "Epoch 93, Batch 79/224, Training Loss: 0.7658\n",
            "Epoch 93, Batch 80/224, Training Loss: 0.3923\n",
            "Epoch 93, Batch 81/224, Training Loss: 0.5436\n",
            "Epoch 93, Batch 82/224, Training Loss: 0.2764\n",
            "Epoch 93, Batch 83/224, Training Loss: 0.2384\n",
            "Epoch 93, Batch 84/224, Training Loss: 0.3273\n",
            "Epoch 93, Batch 85/224, Training Loss: 0.3765\n",
            "Epoch 93, Batch 86/224, Training Loss: 0.3935\n",
            "Epoch 93, Batch 87/224, Training Loss: 0.2908\n",
            "Epoch 93, Batch 88/224, Training Loss: 0.4523\n",
            "Epoch 93, Batch 89/224, Training Loss: 0.4114\n",
            "Epoch 93, Batch 90/224, Training Loss: 0.2286\n",
            "Epoch 93, Batch 91/224, Training Loss: 0.2896\n",
            "Epoch 93, Batch 92/224, Training Loss: 0.3772\n",
            "Epoch 93, Batch 93/224, Training Loss: 0.4124\n",
            "Epoch 93, Batch 94/224, Training Loss: 0.3575\n",
            "Epoch 93, Batch 95/224, Training Loss: 0.2995\n",
            "Epoch 93, Batch 96/224, Training Loss: 0.3932\n",
            "Epoch 93, Batch 97/224, Training Loss: 0.4776\n",
            "Epoch 93, Batch 98/224, Training Loss: 0.1962\n",
            "Epoch 93, Batch 99/224, Training Loss: 0.3844\n",
            "Epoch 93, Batch 100/224, Training Loss: 0.4525\n",
            "Epoch 93, Batch 101/224, Training Loss: 0.2452\n",
            "Epoch 93, Batch 102/224, Training Loss: 0.3596\n",
            "Epoch 93, Batch 103/224, Training Loss: 0.4316\n",
            "Epoch 93, Batch 104/224, Training Loss: 0.3567\n",
            "Epoch 93, Batch 105/224, Training Loss: 0.5080\n",
            "Epoch 93, Batch 106/224, Training Loss: 0.4353\n",
            "Epoch 93, Batch 107/224, Training Loss: 0.3263\n",
            "Epoch 93, Batch 108/224, Training Loss: 0.2510\n",
            "Epoch 93, Batch 109/224, Training Loss: 0.6769\n",
            "Epoch 93, Batch 110/224, Training Loss: 0.4431\n",
            "Epoch 93, Batch 111/224, Training Loss: 0.3339\n",
            "Epoch 93, Batch 112/224, Training Loss: 0.7146\n",
            "Epoch 93, Batch 113/224, Training Loss: 0.4968\n",
            "Epoch 93, Batch 114/224, Training Loss: 0.4125\n",
            "Epoch 93, Batch 115/224, Training Loss: 0.1886\n",
            "Epoch 93, Batch 116/224, Training Loss: 0.3978\n",
            "Epoch 93, Batch 117/224, Training Loss: 0.2728\n",
            "Epoch 93, Batch 118/224, Training Loss: 0.3972\n",
            "Epoch 93, Batch 119/224, Training Loss: 0.2641\n",
            "Epoch 93, Batch 120/224, Training Loss: 0.2929\n",
            "Epoch 93, Batch 121/224, Training Loss: 0.3765\n",
            "Epoch 93, Batch 122/224, Training Loss: 0.3198\n",
            "Epoch 93, Batch 123/224, Training Loss: 0.6281\n",
            "Epoch 93, Batch 124/224, Training Loss: 0.3220\n",
            "Epoch 93, Batch 125/224, Training Loss: 0.2685\n",
            "Epoch 93, Batch 126/224, Training Loss: 0.4040\n",
            "Epoch 93, Batch 127/224, Training Loss: 0.3376\n",
            "Epoch 93, Batch 128/224, Training Loss: 0.5271\n",
            "Epoch 93, Batch 129/224, Training Loss: 0.3549\n",
            "Epoch 93, Batch 130/224, Training Loss: 0.3370\n",
            "Epoch 93, Batch 131/224, Training Loss: 0.2612\n",
            "Epoch 93, Batch 132/224, Training Loss: 0.2916\n",
            "Epoch 93, Batch 133/224, Training Loss: 0.5153\n",
            "Epoch 93, Batch 134/224, Training Loss: 0.3486\n",
            "Epoch 93, Batch 135/224, Training Loss: 0.3129\n",
            "Epoch 93, Batch 136/224, Training Loss: 0.3263\n",
            "Epoch 93, Batch 137/224, Training Loss: 0.7136\n",
            "Epoch 93, Batch 138/224, Training Loss: 0.3792\n",
            "Epoch 93, Batch 139/224, Training Loss: 0.5438\n",
            "Epoch 93, Batch 140/224, Training Loss: 0.3574\n",
            "Epoch 93, Batch 141/224, Training Loss: 0.6316\n",
            "Epoch 93, Batch 142/224, Training Loss: 0.4259\n",
            "Epoch 93, Batch 143/224, Training Loss: 0.7256\n",
            "Epoch 93, Batch 144/224, Training Loss: 0.2437\n",
            "Epoch 93, Batch 145/224, Training Loss: 0.5014\n",
            "Epoch 93, Batch 146/224, Training Loss: 0.3999\n",
            "Epoch 93, Batch 147/224, Training Loss: 0.3246\n",
            "Epoch 93, Batch 148/224, Training Loss: 0.2972\n",
            "Epoch 93, Batch 149/224, Training Loss: 0.3520\n",
            "Epoch 93, Batch 150/224, Training Loss: 0.5922\n",
            "Epoch 93, Batch 151/224, Training Loss: 0.3544\n",
            "Epoch 93, Batch 152/224, Training Loss: 0.4342\n",
            "Epoch 93, Batch 153/224, Training Loss: 0.3432\n",
            "Epoch 93, Batch 154/224, Training Loss: 0.9152\n",
            "Epoch 93, Batch 155/224, Training Loss: 1.0215\n",
            "Epoch 93, Batch 156/224, Training Loss: 0.3555\n",
            "Epoch 93, Batch 157/224, Training Loss: 0.4016\n",
            "Epoch 93, Batch 158/224, Training Loss: 0.2549\n",
            "Epoch 93, Batch 159/224, Training Loss: 0.4142\n",
            "Epoch 93, Batch 160/224, Training Loss: 0.4869\n",
            "Epoch 93, Batch 161/224, Training Loss: 0.4207\n",
            "Epoch 93, Batch 162/224, Training Loss: 0.5746\n",
            "Epoch 93, Batch 163/224, Training Loss: 0.3818\n",
            "Epoch 93, Batch 164/224, Training Loss: 0.2960\n",
            "Epoch 93, Batch 165/224, Training Loss: 0.2882\n",
            "Epoch 93, Batch 166/224, Training Loss: 0.4186\n",
            "Epoch 93, Batch 167/224, Training Loss: 0.3415\n",
            "Epoch 93, Batch 168/224, Training Loss: 0.2801\n",
            "Epoch 93, Batch 169/224, Training Loss: 0.2729\n",
            "Epoch 93, Batch 170/224, Training Loss: 0.5648\n",
            "Epoch 93, Batch 171/224, Training Loss: 0.3622\n",
            "Epoch 93, Batch 172/224, Training Loss: 0.2614\n",
            "Epoch 93, Batch 173/224, Training Loss: 0.4762\n",
            "Epoch 93, Batch 174/224, Training Loss: 0.2032\n",
            "Epoch 93, Batch 175/224, Training Loss: 0.3895\n",
            "Epoch 93, Batch 176/224, Training Loss: 0.3448\n",
            "Epoch 93, Batch 177/224, Training Loss: 0.3046\n",
            "Epoch 93, Batch 178/224, Training Loss: 0.3842\n",
            "Epoch 93, Batch 179/224, Training Loss: 0.4262\n",
            "Epoch 93, Batch 180/224, Training Loss: 0.3273\n",
            "Epoch 93, Batch 181/224, Training Loss: 0.3734\n",
            "Epoch 93, Batch 182/224, Training Loss: 0.4909\n",
            "Epoch 93, Batch 183/224, Training Loss: 0.3606\n",
            "Epoch 93, Batch 184/224, Training Loss: 0.4484\n",
            "Epoch 93, Batch 185/224, Training Loss: 0.3566\n",
            "Epoch 93, Batch 186/224, Training Loss: 0.4552\n",
            "Epoch 93, Batch 187/224, Training Loss: 0.3228\n",
            "Epoch 93, Batch 188/224, Training Loss: 0.6519\n",
            "Epoch 93, Batch 189/224, Training Loss: 0.4043\n",
            "Epoch 93, Batch 190/224, Training Loss: 0.4819\n",
            "Epoch 93, Batch 191/224, Training Loss: 0.2913\n",
            "Epoch 93, Batch 192/224, Training Loss: 0.5124\n",
            "Epoch 93, Batch 193/224, Training Loss: 0.4714\n",
            "Epoch 93, Batch 194/224, Training Loss: 0.6048\n",
            "Epoch 93, Batch 195/224, Training Loss: 0.3141\n",
            "Epoch 93, Batch 196/224, Training Loss: 0.4028\n",
            "Epoch 93, Batch 197/224, Training Loss: 0.3095\n",
            "Epoch 93, Batch 198/224, Training Loss: 0.4727\n",
            "Epoch 93, Batch 199/224, Training Loss: 0.3721\n",
            "Epoch 93, Batch 200/224, Training Loss: 0.3319\n",
            "Epoch 93, Batch 201/224, Training Loss: 0.4192\n",
            "Epoch 93, Batch 202/224, Training Loss: 0.9668\n",
            "Epoch 93, Batch 203/224, Training Loss: 0.3291\n",
            "Epoch 93, Batch 204/224, Training Loss: 0.3013\n",
            "Epoch 93, Batch 205/224, Training Loss: 0.4113\n",
            "Epoch 93, Batch 206/224, Training Loss: 0.3520\n",
            "Epoch 93, Batch 207/224, Training Loss: 0.2913\n",
            "Epoch 93, Batch 208/224, Training Loss: 0.4910\n",
            "Epoch 93, Batch 209/224, Training Loss: 0.2751\n",
            "Epoch 93, Batch 210/224, Training Loss: 0.2838\n",
            "Epoch 93, Batch 211/224, Training Loss: 0.3941\n",
            "Epoch 93, Batch 212/224, Training Loss: 0.2828\n",
            "Epoch 93, Batch 213/224, Training Loss: 0.2891\n",
            "Epoch 93, Batch 214/224, Training Loss: 0.6533\n",
            "Epoch 93, Batch 215/224, Training Loss: 0.5175\n",
            "Epoch 93, Batch 216/224, Training Loss: 0.5020\n",
            "Epoch 93, Batch 217/224, Training Loss: 0.3627\n",
            "Epoch 93, Batch 218/224, Training Loss: 0.2352\n",
            "Epoch 93, Batch 219/224, Training Loss: 0.3158\n",
            "Epoch 93, Batch 220/224, Training Loss: 0.3293\n",
            "Epoch 93, Batch 221/224, Training Loss: 0.3746\n",
            "Epoch 93, Batch 222/224, Training Loss: 0.3075\n",
            "Epoch 93, Batch 223/224, Training Loss: 0.3426\n",
            "Epoch 93/100, Training Loss: 0.3941, Test Loss: 3.1643\n",
            "Epoch 94, Batch 0/224, Training Loss: 0.3091\n",
            "Epoch 94, Batch 1/224, Training Loss: 0.2172\n",
            "Epoch 94, Batch 2/224, Training Loss: 0.3208\n",
            "Epoch 94, Batch 3/224, Training Loss: 0.3336\n",
            "Epoch 94, Batch 4/224, Training Loss: 0.3395\n",
            "Epoch 94, Batch 5/224, Training Loss: 0.4034\n",
            "Epoch 94, Batch 6/224, Training Loss: 0.2638\n",
            "Epoch 94, Batch 7/224, Training Loss: 0.2574\n",
            "Epoch 94, Batch 8/224, Training Loss: 0.2930\n",
            "Epoch 94, Batch 9/224, Training Loss: 0.3672\n",
            "Epoch 94, Batch 10/224, Training Loss: 0.2192\n",
            "Epoch 94, Batch 11/224, Training Loss: 0.4234\n",
            "Epoch 94, Batch 12/224, Training Loss: 0.2125\n",
            "Epoch 94, Batch 13/224, Training Loss: 0.3521\n",
            "Epoch 94, Batch 14/224, Training Loss: 0.3251\n",
            "Epoch 94, Batch 15/224, Training Loss: 0.3587\n",
            "Epoch 94, Batch 16/224, Training Loss: 0.3767\n",
            "Epoch 94, Batch 17/224, Training Loss: 0.2905\n",
            "Epoch 94, Batch 18/224, Training Loss: 0.3840\n",
            "Epoch 94, Batch 19/224, Training Loss: 0.4954\n",
            "Epoch 94, Batch 20/224, Training Loss: 0.5741\n",
            "Epoch 94, Batch 21/224, Training Loss: 0.3064\n",
            "Epoch 94, Batch 22/224, Training Loss: 0.4433\n",
            "Epoch 94, Batch 23/224, Training Loss: 0.4138\n",
            "Epoch 94, Batch 24/224, Training Loss: 0.3375\n",
            "Epoch 94, Batch 25/224, Training Loss: 0.2077\n",
            "Epoch 94, Batch 26/224, Training Loss: 0.7207\n",
            "Epoch 94, Batch 27/224, Training Loss: 0.3169\n",
            "Epoch 94, Batch 28/224, Training Loss: 0.5349\n",
            "Epoch 94, Batch 29/224, Training Loss: 0.3877\n",
            "Epoch 94, Batch 30/224, Training Loss: 0.3570\n",
            "Epoch 94, Batch 31/224, Training Loss: 0.3558\n",
            "Epoch 94, Batch 32/224, Training Loss: 0.3165\n",
            "Epoch 94, Batch 33/224, Training Loss: 0.3061\n",
            "Epoch 94, Batch 34/224, Training Loss: 0.2365\n",
            "Epoch 94, Batch 35/224, Training Loss: 0.6036\n",
            "Epoch 94, Batch 36/224, Training Loss: 0.2573\n",
            "Epoch 94, Batch 37/224, Training Loss: 0.5805\n",
            "Epoch 94, Batch 38/224, Training Loss: 0.4438\n",
            "Epoch 94, Batch 39/224, Training Loss: 0.2770\n",
            "Epoch 94, Batch 40/224, Training Loss: 0.8755\n",
            "Epoch 94, Batch 41/224, Training Loss: 0.3766\n",
            "Epoch 94, Batch 42/224, Training Loss: 0.3905\n",
            "Epoch 94, Batch 43/224, Training Loss: 0.2837\n",
            "Epoch 94, Batch 44/224, Training Loss: 0.6268\n",
            "Epoch 94, Batch 45/224, Training Loss: 0.2815\n",
            "Epoch 94, Batch 46/224, Training Loss: 0.5187\n",
            "Epoch 94, Batch 47/224, Training Loss: 0.4400\n",
            "Epoch 94, Batch 48/224, Training Loss: 0.2127\n",
            "Epoch 94, Batch 49/224, Training Loss: 0.3646\n",
            "Epoch 94, Batch 50/224, Training Loss: 0.3834\n",
            "Epoch 94, Batch 51/224, Training Loss: 0.5482\n",
            "Epoch 94, Batch 52/224, Training Loss: 0.3897\n",
            "Epoch 94, Batch 53/224, Training Loss: 0.3450\n",
            "Epoch 94, Batch 54/224, Training Loss: 0.3243\n",
            "Epoch 94, Batch 55/224, Training Loss: 0.2067\n",
            "Epoch 94, Batch 56/224, Training Loss: 0.2352\n",
            "Epoch 94, Batch 57/224, Training Loss: 0.3455\n",
            "Epoch 94, Batch 58/224, Training Loss: 0.3228\n",
            "Epoch 94, Batch 59/224, Training Loss: 0.4104\n",
            "Epoch 94, Batch 60/224, Training Loss: 0.5062\n",
            "Epoch 94, Batch 61/224, Training Loss: 0.8541\n",
            "Epoch 94, Batch 62/224, Training Loss: 0.3219\n",
            "Epoch 94, Batch 63/224, Training Loss: 0.2631\n",
            "Epoch 94, Batch 64/224, Training Loss: 0.4956\n",
            "Epoch 94, Batch 65/224, Training Loss: 0.2641\n",
            "Epoch 94, Batch 66/224, Training Loss: 0.2592\n",
            "Epoch 94, Batch 67/224, Training Loss: 0.5259\n",
            "Epoch 94, Batch 68/224, Training Loss: 0.4067\n",
            "Epoch 94, Batch 69/224, Training Loss: 0.3024\n",
            "Epoch 94, Batch 70/224, Training Loss: 0.3117\n",
            "Epoch 94, Batch 71/224, Training Loss: 0.4205\n",
            "Epoch 94, Batch 72/224, Training Loss: 0.3698\n",
            "Epoch 94, Batch 73/224, Training Loss: 0.2577\n",
            "Epoch 94, Batch 74/224, Training Loss: 0.3688\n",
            "Epoch 94, Batch 75/224, Training Loss: 0.4012\n",
            "Epoch 94, Batch 76/224, Training Loss: 0.3325\n",
            "Epoch 94, Batch 77/224, Training Loss: 0.5452\n",
            "Epoch 94, Batch 78/224, Training Loss: 0.3997\n",
            "Epoch 94, Batch 79/224, Training Loss: 0.4476\n",
            "Epoch 94, Batch 80/224, Training Loss: 0.3759\n",
            "Epoch 94, Batch 81/224, Training Loss: 0.5283\n",
            "Epoch 94, Batch 82/224, Training Loss: 0.3727\n",
            "Epoch 94, Batch 83/224, Training Loss: 0.6144\n",
            "Epoch 94, Batch 84/224, Training Loss: 0.2733\n",
            "Epoch 94, Batch 85/224, Training Loss: 0.3987\n",
            "Epoch 94, Batch 86/224, Training Loss: 0.3623\n",
            "Epoch 94, Batch 87/224, Training Loss: 0.7258\n",
            "Epoch 94, Batch 88/224, Training Loss: 0.4677\n",
            "Epoch 94, Batch 89/224, Training Loss: 0.3284\n",
            "Epoch 94, Batch 90/224, Training Loss: 0.4041\n",
            "Epoch 94, Batch 91/224, Training Loss: 0.2224\n",
            "Epoch 94, Batch 92/224, Training Loss: 0.3259\n",
            "Epoch 94, Batch 93/224, Training Loss: 1.1707\n",
            "Epoch 94, Batch 94/224, Training Loss: 0.4059\n",
            "Epoch 94, Batch 95/224, Training Loss: 0.2811\n",
            "Epoch 94, Batch 96/224, Training Loss: 0.5093\n",
            "Epoch 94, Batch 97/224, Training Loss: 0.3940\n",
            "Epoch 94, Batch 98/224, Training Loss: 0.3096\n",
            "Epoch 94, Batch 99/224, Training Loss: 0.4076\n",
            "Epoch 94, Batch 100/224, Training Loss: 0.3406\n",
            "Epoch 94, Batch 101/224, Training Loss: 0.5228\n",
            "Epoch 94, Batch 102/224, Training Loss: 0.5769\n",
            "Epoch 94, Batch 103/224, Training Loss: 0.3586\n",
            "Epoch 94, Batch 104/224, Training Loss: 0.2594\n",
            "Epoch 94, Batch 105/224, Training Loss: 0.2438\n",
            "Epoch 94, Batch 106/224, Training Loss: 0.2499\n",
            "Epoch 94, Batch 107/224, Training Loss: 0.5606\n",
            "Epoch 94, Batch 108/224, Training Loss: 0.3703\n",
            "Epoch 94, Batch 109/224, Training Loss: 0.9151\n",
            "Epoch 94, Batch 110/224, Training Loss: 0.3316\n",
            "Epoch 94, Batch 111/224, Training Loss: 0.3119\n",
            "Epoch 94, Batch 112/224, Training Loss: 0.4747\n",
            "Epoch 94, Batch 113/224, Training Loss: 0.1982\n",
            "Epoch 94, Batch 114/224, Training Loss: 0.4013\n",
            "Epoch 94, Batch 115/224, Training Loss: 0.3505\n",
            "Epoch 94, Batch 116/224, Training Loss: 0.3381\n",
            "Epoch 94, Batch 117/224, Training Loss: 0.2718\n",
            "Epoch 94, Batch 118/224, Training Loss: 1.0078\n",
            "Epoch 94, Batch 119/224, Training Loss: 0.2479\n",
            "Epoch 94, Batch 120/224, Training Loss: 0.2258\n",
            "Epoch 94, Batch 121/224, Training Loss: 0.3980\n",
            "Epoch 94, Batch 122/224, Training Loss: 0.2837\n",
            "Epoch 94, Batch 123/224, Training Loss: 0.4372\n",
            "Epoch 94, Batch 124/224, Training Loss: 0.2991\n",
            "Epoch 94, Batch 125/224, Training Loss: 0.4360\n",
            "Epoch 94, Batch 126/224, Training Loss: 0.3122\n",
            "Epoch 94, Batch 127/224, Training Loss: 0.2976\n",
            "Epoch 94, Batch 128/224, Training Loss: 0.3658\n",
            "Epoch 94, Batch 129/224, Training Loss: 0.3859\n",
            "Epoch 94, Batch 130/224, Training Loss: 0.3441\n",
            "Epoch 94, Batch 131/224, Training Loss: 0.2479\n",
            "Epoch 94, Batch 132/224, Training Loss: 0.3285\n",
            "Epoch 94, Batch 133/224, Training Loss: 0.5309\n",
            "Epoch 94, Batch 134/224, Training Loss: 0.2658\n",
            "Epoch 94, Batch 135/224, Training Loss: 0.3441\n",
            "Epoch 94, Batch 136/224, Training Loss: 0.4345\n",
            "Epoch 94, Batch 137/224, Training Loss: 0.5940\n",
            "Epoch 94, Batch 138/224, Training Loss: 0.2234\n",
            "Epoch 94, Batch 139/224, Training Loss: 0.3039\n",
            "Epoch 94, Batch 140/224, Training Loss: 0.2514\n",
            "Epoch 94, Batch 141/224, Training Loss: 0.4176\n",
            "Epoch 94, Batch 142/224, Training Loss: 0.3211\n",
            "Epoch 94, Batch 143/224, Training Loss: 0.1985\n",
            "Epoch 94, Batch 144/224, Training Loss: 0.3878\n",
            "Epoch 94, Batch 145/224, Training Loss: 0.3913\n",
            "Epoch 94, Batch 146/224, Training Loss: 0.3348\n",
            "Epoch 94, Batch 147/224, Training Loss: 0.3175\n",
            "Epoch 94, Batch 148/224, Training Loss: 0.3991\n",
            "Epoch 94, Batch 149/224, Training Loss: 0.1848\n",
            "Epoch 94, Batch 150/224, Training Loss: 0.4224\n",
            "Epoch 94, Batch 151/224, Training Loss: 0.2183\n",
            "Epoch 94, Batch 152/224, Training Loss: 0.3781\n",
            "Epoch 94, Batch 153/224, Training Loss: 0.2980\n",
            "Epoch 94, Batch 154/224, Training Loss: 0.2956\n",
            "Epoch 94, Batch 155/224, Training Loss: 0.3610\n",
            "Epoch 94, Batch 156/224, Training Loss: 0.4529\n",
            "Epoch 94, Batch 157/224, Training Loss: 0.3747\n",
            "Epoch 94, Batch 158/224, Training Loss: 0.7662\n",
            "Epoch 94, Batch 159/224, Training Loss: 0.7855\n",
            "Epoch 94, Batch 160/224, Training Loss: 0.3325\n",
            "Epoch 94, Batch 161/224, Training Loss: 0.4857\n",
            "Epoch 94, Batch 162/224, Training Loss: 0.3136\n",
            "Epoch 94, Batch 163/224, Training Loss: 0.2956\n",
            "Epoch 94, Batch 164/224, Training Loss: 0.3072\n",
            "Epoch 94, Batch 165/224, Training Loss: 0.2946\n",
            "Epoch 94, Batch 166/224, Training Loss: 0.5446\n",
            "Epoch 94, Batch 167/224, Training Loss: 0.3957\n",
            "Epoch 94, Batch 168/224, Training Loss: 0.4033\n",
            "Epoch 94, Batch 169/224, Training Loss: 0.2361\n",
            "Epoch 94, Batch 170/224, Training Loss: 0.5764\n",
            "Epoch 94, Batch 171/224, Training Loss: 0.2919\n",
            "Epoch 94, Batch 172/224, Training Loss: 0.3660\n",
            "Epoch 94, Batch 173/224, Training Loss: 0.4414\n",
            "Epoch 94, Batch 174/224, Training Loss: 0.3132\n",
            "Epoch 94, Batch 175/224, Training Loss: 0.3270\n",
            "Epoch 94, Batch 176/224, Training Loss: 0.3169\n",
            "Epoch 94, Batch 177/224, Training Loss: 0.3913\n",
            "Epoch 94, Batch 178/224, Training Loss: 0.3890\n",
            "Epoch 94, Batch 179/224, Training Loss: 0.2829\n",
            "Epoch 94, Batch 180/224, Training Loss: 0.7502\n",
            "Epoch 94, Batch 181/224, Training Loss: 0.2597\n",
            "Epoch 94, Batch 182/224, Training Loss: 0.2768\n",
            "Epoch 94, Batch 183/224, Training Loss: 0.3095\n",
            "Epoch 94, Batch 184/224, Training Loss: 0.1832\n",
            "Epoch 94, Batch 185/224, Training Loss: 0.4012\n",
            "Epoch 94, Batch 186/224, Training Loss: 0.3905\n",
            "Epoch 94, Batch 187/224, Training Loss: 0.2499\n",
            "Epoch 94, Batch 188/224, Training Loss: 0.8069\n",
            "Epoch 94, Batch 189/224, Training Loss: 0.3457\n",
            "Epoch 94, Batch 190/224, Training Loss: 0.4130\n",
            "Epoch 94, Batch 191/224, Training Loss: 0.4539\n",
            "Epoch 94, Batch 192/224, Training Loss: 0.5270\n",
            "Epoch 94, Batch 193/224, Training Loss: 0.3480\n",
            "Epoch 94, Batch 194/224, Training Loss: 0.4792\n",
            "Epoch 94, Batch 195/224, Training Loss: 0.2152\n",
            "Epoch 94, Batch 196/224, Training Loss: 0.3338\n",
            "Epoch 94, Batch 197/224, Training Loss: 0.4049\n",
            "Epoch 94, Batch 198/224, Training Loss: 0.3596\n",
            "Epoch 94, Batch 199/224, Training Loss: 0.2701\n",
            "Epoch 94, Batch 200/224, Training Loss: 0.3783\n",
            "Epoch 94, Batch 201/224, Training Loss: 0.4756\n",
            "Epoch 94, Batch 202/224, Training Loss: 0.4349\n",
            "Epoch 94, Batch 203/224, Training Loss: 0.3560\n",
            "Epoch 94, Batch 204/224, Training Loss: 0.5128\n",
            "Epoch 94, Batch 205/224, Training Loss: 0.2671\n",
            "Epoch 94, Batch 206/224, Training Loss: 1.0071\n",
            "Epoch 94, Batch 207/224, Training Loss: 0.3836\n",
            "Epoch 94, Batch 208/224, Training Loss: 0.3197\n",
            "Epoch 94, Batch 209/224, Training Loss: 0.3168\n",
            "Epoch 94, Batch 210/224, Training Loss: 0.3181\n",
            "Epoch 94, Batch 211/224, Training Loss: 0.7227\n",
            "Epoch 94, Batch 212/224, Training Loss: 0.5514\n",
            "Epoch 94, Batch 213/224, Training Loss: 0.3713\n",
            "Epoch 94, Batch 214/224, Training Loss: 0.3926\n",
            "Epoch 94, Batch 215/224, Training Loss: 0.6750\n",
            "Epoch 94, Batch 216/224, Training Loss: 0.3500\n",
            "Epoch 94, Batch 217/224, Training Loss: 0.3754\n",
            "Epoch 94, Batch 218/224, Training Loss: 0.3583\n",
            "Epoch 94, Batch 219/224, Training Loss: 0.6916\n",
            "Epoch 94, Batch 220/224, Training Loss: 0.5036\n",
            "Epoch 94, Batch 221/224, Training Loss: 0.2755\n",
            "Epoch 94, Batch 222/224, Training Loss: 0.2527\n",
            "Epoch 94, Batch 223/224, Training Loss: 0.3138\n",
            "Epoch 94/100, Training Loss: 0.3927, Test Loss: 3.1355\n",
            "Epoch 95, Batch 0/224, Training Loss: 0.2863\n",
            "Epoch 95, Batch 1/224, Training Loss: 0.4130\n",
            "Epoch 95, Batch 2/224, Training Loss: 0.4185\n",
            "Epoch 95, Batch 3/224, Training Loss: 0.3623\n",
            "Epoch 95, Batch 4/224, Training Loss: 0.3004\n",
            "Epoch 95, Batch 5/224, Training Loss: 0.3185\n",
            "Epoch 95, Batch 6/224, Training Loss: 0.2777\n",
            "Epoch 95, Batch 7/224, Training Loss: 0.2994\n",
            "Epoch 95, Batch 8/224, Training Loss: 0.3760\n",
            "Epoch 95, Batch 9/224, Training Loss: 0.2786\n",
            "Epoch 95, Batch 10/224, Training Loss: 0.5358\n",
            "Epoch 95, Batch 11/224, Training Loss: 0.2869\n",
            "Epoch 95, Batch 12/224, Training Loss: 0.4894\n",
            "Epoch 95, Batch 13/224, Training Loss: 0.2926\n",
            "Epoch 95, Batch 14/224, Training Loss: 0.2891\n",
            "Epoch 95, Batch 15/224, Training Loss: 0.2385\n",
            "Epoch 95, Batch 16/224, Training Loss: 0.2032\n",
            "Epoch 95, Batch 17/224, Training Loss: 0.3435\n",
            "Epoch 95, Batch 18/224, Training Loss: 0.3737\n",
            "Epoch 95, Batch 19/224, Training Loss: 0.2715\n",
            "Epoch 95, Batch 20/224, Training Loss: 0.4373\n",
            "Epoch 95, Batch 21/224, Training Loss: 0.2323\n",
            "Epoch 95, Batch 22/224, Training Loss: 0.2218\n",
            "Epoch 95, Batch 23/224, Training Loss: 0.6088\n",
            "Epoch 95, Batch 24/224, Training Loss: 0.2755\n",
            "Epoch 95, Batch 25/224, Training Loss: 0.2378\n",
            "Epoch 95, Batch 26/224, Training Loss: 0.2783\n",
            "Epoch 95, Batch 27/224, Training Loss: 0.4154\n",
            "Epoch 95, Batch 28/224, Training Loss: 0.3207\n",
            "Epoch 95, Batch 29/224, Training Loss: 0.4304\n",
            "Epoch 95, Batch 30/224, Training Loss: 0.2415\n",
            "Epoch 95, Batch 31/224, Training Loss: 0.2503\n",
            "Epoch 95, Batch 32/224, Training Loss: 0.4119\n",
            "Epoch 95, Batch 33/224, Training Loss: 0.5925\n",
            "Epoch 95, Batch 34/224, Training Loss: 0.3987\n",
            "Epoch 95, Batch 35/224, Training Loss: 0.3675\n",
            "Epoch 95, Batch 36/224, Training Loss: 0.3562\n",
            "Epoch 95, Batch 37/224, Training Loss: 0.5068\n",
            "Epoch 95, Batch 38/224, Training Loss: 0.3539\n",
            "Epoch 95, Batch 39/224, Training Loss: 0.3349\n",
            "Epoch 95, Batch 40/224, Training Loss: 0.3745\n",
            "Epoch 95, Batch 41/224, Training Loss: 0.3933\n",
            "Epoch 95, Batch 42/224, Training Loss: 0.4527\n",
            "Epoch 95, Batch 43/224, Training Loss: 0.2186\n",
            "Epoch 95, Batch 44/224, Training Loss: 0.2166\n",
            "Epoch 95, Batch 45/224, Training Loss: 0.2617\n",
            "Epoch 95, Batch 46/224, Training Loss: 0.3703\n",
            "Epoch 95, Batch 47/224, Training Loss: 0.4016\n",
            "Epoch 95, Batch 48/224, Training Loss: 0.5165\n",
            "Epoch 95, Batch 49/224, Training Loss: 0.7262\n",
            "Epoch 95, Batch 50/224, Training Loss: 0.4881\n",
            "Epoch 95, Batch 51/224, Training Loss: 0.4950\n",
            "Epoch 95, Batch 52/224, Training Loss: 0.3294\n",
            "Epoch 95, Batch 53/224, Training Loss: 0.2017\n",
            "Epoch 95, Batch 54/224, Training Loss: 0.3385\n",
            "Epoch 95, Batch 55/224, Training Loss: 0.4068\n",
            "Epoch 95, Batch 56/224, Training Loss: 0.5269\n",
            "Epoch 95, Batch 57/224, Training Loss: 0.2828\n",
            "Epoch 95, Batch 58/224, Training Loss: 0.2776\n",
            "Epoch 95, Batch 59/224, Training Loss: 0.3178\n",
            "Epoch 95, Batch 60/224, Training Loss: 0.4109\n",
            "Epoch 95, Batch 61/224, Training Loss: 0.1894\n",
            "Epoch 95, Batch 62/224, Training Loss: 0.4620\n",
            "Epoch 95, Batch 63/224, Training Loss: 0.7855\n",
            "Epoch 95, Batch 64/224, Training Loss: 0.2132\n",
            "Epoch 95, Batch 65/224, Training Loss: 0.6483\n",
            "Epoch 95, Batch 66/224, Training Loss: 0.3367\n",
            "Epoch 95, Batch 67/224, Training Loss: 0.2616\n",
            "Epoch 95, Batch 68/224, Training Loss: 0.7702\n",
            "Epoch 95, Batch 69/224, Training Loss: 0.4165\n",
            "Epoch 95, Batch 70/224, Training Loss: 0.8345\n",
            "Epoch 95, Batch 71/224, Training Loss: 0.5346\n",
            "Epoch 95, Batch 72/224, Training Loss: 0.8007\n",
            "Epoch 95, Batch 73/224, Training Loss: 0.3050\n",
            "Epoch 95, Batch 74/224, Training Loss: 0.2323\n",
            "Epoch 95, Batch 75/224, Training Loss: 0.2680\n",
            "Epoch 95, Batch 76/224, Training Loss: 0.3772\n",
            "Epoch 95, Batch 77/224, Training Loss: 0.3955\n",
            "Epoch 95, Batch 78/224, Training Loss: 0.3391\n",
            "Epoch 95, Batch 79/224, Training Loss: 0.3355\n",
            "Epoch 95, Batch 80/224, Training Loss: 0.5584\n",
            "Epoch 95, Batch 81/224, Training Loss: 0.2884\n",
            "Epoch 95, Batch 82/224, Training Loss: 0.4426\n",
            "Epoch 95, Batch 83/224, Training Loss: 0.3155\n",
            "Epoch 95, Batch 84/224, Training Loss: 0.4102\n",
            "Epoch 95, Batch 85/224, Training Loss: 0.7380\n",
            "Epoch 95, Batch 86/224, Training Loss: 0.3484\n",
            "Epoch 95, Batch 87/224, Training Loss: 0.3124\n",
            "Epoch 95, Batch 88/224, Training Loss: 0.3213\n",
            "Epoch 95, Batch 89/224, Training Loss: 0.3310\n",
            "Epoch 95, Batch 90/224, Training Loss: 0.3671\n",
            "Epoch 95, Batch 91/224, Training Loss: 0.3317\n",
            "Epoch 95, Batch 92/224, Training Loss: 0.4177\n",
            "Epoch 95, Batch 93/224, Training Loss: 0.2557\n",
            "Epoch 95, Batch 94/224, Training Loss: 0.5310\n",
            "Epoch 95, Batch 95/224, Training Loss: 0.2566\n",
            "Epoch 95, Batch 96/224, Training Loss: 0.5147\n",
            "Epoch 95, Batch 97/224, Training Loss: 0.5319\n",
            "Epoch 95, Batch 98/224, Training Loss: 0.3271\n",
            "Epoch 95, Batch 99/224, Training Loss: 0.3229\n",
            "Epoch 95, Batch 100/224, Training Loss: 0.4626\n",
            "Epoch 95, Batch 101/224, Training Loss: 0.4386\n",
            "Epoch 95, Batch 102/224, Training Loss: 0.2523\n",
            "Epoch 95, Batch 103/224, Training Loss: 0.3235\n",
            "Epoch 95, Batch 104/224, Training Loss: 0.3144\n",
            "Epoch 95, Batch 105/224, Training Loss: 0.5901\n",
            "Epoch 95, Batch 106/224, Training Loss: 0.2498\n",
            "Epoch 95, Batch 107/224, Training Loss: 0.2853\n",
            "Epoch 95, Batch 108/224, Training Loss: 0.3147\n",
            "Epoch 95, Batch 109/224, Training Loss: 0.3115\n",
            "Epoch 95, Batch 110/224, Training Loss: 0.4987\n",
            "Epoch 95, Batch 111/224, Training Loss: 0.2970\n",
            "Epoch 95, Batch 112/224, Training Loss: 0.3127\n",
            "Epoch 95, Batch 113/224, Training Loss: 0.5039\n",
            "Epoch 95, Batch 114/224, Training Loss: 0.3557\n",
            "Epoch 95, Batch 115/224, Training Loss: 0.3347\n",
            "Epoch 95, Batch 116/224, Training Loss: 0.4933\n",
            "Epoch 95, Batch 117/224, Training Loss: 0.2377\n",
            "Epoch 95, Batch 118/224, Training Loss: 0.4515\n",
            "Epoch 95, Batch 119/224, Training Loss: 0.3958\n",
            "Epoch 95, Batch 120/224, Training Loss: 0.4392\n",
            "Epoch 95, Batch 121/224, Training Loss: 0.3971\n",
            "Epoch 95, Batch 122/224, Training Loss: 0.3067\n",
            "Epoch 95, Batch 123/224, Training Loss: 0.5825\n",
            "Epoch 95, Batch 124/224, Training Loss: 0.4772\n",
            "Epoch 95, Batch 125/224, Training Loss: 0.6127\n",
            "Epoch 95, Batch 126/224, Training Loss: 0.8253\n",
            "Epoch 95, Batch 127/224, Training Loss: 0.3826\n",
            "Epoch 95, Batch 128/224, Training Loss: 0.4401\n",
            "Epoch 95, Batch 129/224, Training Loss: 0.4227\n",
            "Epoch 95, Batch 130/224, Training Loss: 0.2708\n",
            "Epoch 95, Batch 131/224, Training Loss: 0.4349\n",
            "Epoch 95, Batch 132/224, Training Loss: 0.3894\n",
            "Epoch 95, Batch 133/224, Training Loss: 0.7323\n",
            "Epoch 95, Batch 134/224, Training Loss: 0.3362\n",
            "Epoch 95, Batch 135/224, Training Loss: 0.3398\n",
            "Epoch 95, Batch 136/224, Training Loss: 0.4379\n",
            "Epoch 95, Batch 137/224, Training Loss: 0.3302\n",
            "Epoch 95, Batch 138/224, Training Loss: 0.2854\n",
            "Epoch 95, Batch 139/224, Training Loss: 0.2808\n",
            "Epoch 95, Batch 140/224, Training Loss: 0.2586\n",
            "Epoch 95, Batch 141/224, Training Loss: 0.2405\n",
            "Epoch 95, Batch 142/224, Training Loss: 0.3110\n",
            "Epoch 95, Batch 143/224, Training Loss: 0.4024\n",
            "Epoch 95, Batch 144/224, Training Loss: 0.3753\n",
            "Epoch 95, Batch 145/224, Training Loss: 0.3231\n",
            "Epoch 95, Batch 146/224, Training Loss: 0.6100\n",
            "Epoch 95, Batch 147/224, Training Loss: 0.2418\n",
            "Epoch 95, Batch 148/224, Training Loss: 0.5015\n",
            "Epoch 95, Batch 149/224, Training Loss: 0.2967\n",
            "Epoch 95, Batch 150/224, Training Loss: 0.2898\n",
            "Epoch 95, Batch 151/224, Training Loss: 0.2409\n",
            "Epoch 95, Batch 152/224, Training Loss: 0.4888\n",
            "Epoch 95, Batch 153/224, Training Loss: 0.3033\n",
            "Epoch 95, Batch 154/224, Training Loss: 0.3498\n",
            "Epoch 95, Batch 155/224, Training Loss: 0.4415\n",
            "Epoch 95, Batch 156/224, Training Loss: 0.3502\n",
            "Epoch 95, Batch 157/224, Training Loss: 0.3811\n",
            "Epoch 95, Batch 158/224, Training Loss: 0.3979\n",
            "Epoch 95, Batch 159/224, Training Loss: 0.4702\n",
            "Epoch 95, Batch 160/224, Training Loss: 0.3471\n",
            "Epoch 95, Batch 161/224, Training Loss: 0.7591\n",
            "Epoch 95, Batch 162/224, Training Loss: 0.3675\n",
            "Epoch 95, Batch 163/224, Training Loss: 0.3207\n",
            "Epoch 95, Batch 164/224, Training Loss: 0.3672\n",
            "Epoch 95, Batch 165/224, Training Loss: 0.3410\n",
            "Epoch 95, Batch 166/224, Training Loss: 0.2917\n",
            "Epoch 95, Batch 167/224, Training Loss: 0.2723\n",
            "Epoch 95, Batch 168/224, Training Loss: 0.2733\n",
            "Epoch 95, Batch 169/224, Training Loss: 0.5355\n",
            "Epoch 95, Batch 170/224, Training Loss: 0.4300\n",
            "Epoch 95, Batch 171/224, Training Loss: 0.3530\n",
            "Epoch 95, Batch 172/224, Training Loss: 0.2796\n",
            "Epoch 95, Batch 173/224, Training Loss: 0.2860\n",
            "Epoch 95, Batch 174/224, Training Loss: 0.4057\n",
            "Epoch 95, Batch 175/224, Training Loss: 0.2819\n",
            "Epoch 95, Batch 176/224, Training Loss: 0.3809\n",
            "Epoch 95, Batch 177/224, Training Loss: 0.3752\n",
            "Epoch 95, Batch 178/224, Training Loss: 0.2992\n",
            "Epoch 95, Batch 179/224, Training Loss: 0.2449\n",
            "Epoch 95, Batch 180/224, Training Loss: 0.3711\n",
            "Epoch 95, Batch 181/224, Training Loss: 0.2272\n",
            "Epoch 95, Batch 182/224, Training Loss: 0.3617\n",
            "Epoch 95, Batch 183/224, Training Loss: 0.2907\n",
            "Epoch 95, Batch 184/224, Training Loss: 0.3160\n",
            "Epoch 95, Batch 185/224, Training Loss: 0.3156\n",
            "Epoch 95, Batch 186/224, Training Loss: 0.6193\n",
            "Epoch 95, Batch 187/224, Training Loss: 0.2708\n",
            "Epoch 95, Batch 188/224, Training Loss: 0.5001\n",
            "Epoch 95, Batch 189/224, Training Loss: 0.4650\n",
            "Epoch 95, Batch 190/224, Training Loss: 0.2992\n",
            "Epoch 95, Batch 191/224, Training Loss: 0.7192\n",
            "Epoch 95, Batch 192/224, Training Loss: 0.3394\n",
            "Epoch 95, Batch 193/224, Training Loss: 0.3738\n",
            "Epoch 95, Batch 194/224, Training Loss: 0.2314\n",
            "Epoch 95, Batch 195/224, Training Loss: 0.2963\n",
            "Epoch 95, Batch 196/224, Training Loss: 0.3379\n",
            "Epoch 95, Batch 197/224, Training Loss: 0.3950\n",
            "Epoch 95, Batch 198/224, Training Loss: 0.2937\n",
            "Epoch 95, Batch 199/224, Training Loss: 0.4525\n",
            "Epoch 95, Batch 200/224, Training Loss: 0.2757\n",
            "Epoch 95, Batch 201/224, Training Loss: 0.9661\n",
            "Epoch 95, Batch 202/224, Training Loss: 0.2363\n",
            "Epoch 95, Batch 203/224, Training Loss: 0.4163\n",
            "Epoch 95, Batch 204/224, Training Loss: 0.3083\n",
            "Epoch 95, Batch 205/224, Training Loss: 0.3692\n",
            "Epoch 95, Batch 206/224, Training Loss: 0.3472\n",
            "Epoch 95, Batch 207/224, Training Loss: 0.3254\n",
            "Epoch 95, Batch 208/224, Training Loss: 0.2302\n",
            "Epoch 95, Batch 209/224, Training Loss: 0.3394\n",
            "Epoch 95, Batch 210/224, Training Loss: 0.2905\n",
            "Epoch 95, Batch 211/224, Training Loss: 0.4016\n",
            "Epoch 95, Batch 212/224, Training Loss: 0.2871\n",
            "Epoch 95, Batch 213/224, Training Loss: 0.9165\n",
            "Epoch 95, Batch 214/224, Training Loss: 0.4995\n",
            "Epoch 95, Batch 215/224, Training Loss: 0.4485\n",
            "Epoch 95, Batch 216/224, Training Loss: 0.4935\n",
            "Epoch 95, Batch 217/224, Training Loss: 0.2772\n",
            "Epoch 95, Batch 218/224, Training Loss: 0.2374\n",
            "Epoch 95, Batch 219/224, Training Loss: 0.3822\n",
            "Epoch 95, Batch 220/224, Training Loss: 0.3474\n",
            "Epoch 95, Batch 221/224, Training Loss: 0.4491\n",
            "Epoch 95, Batch 222/224, Training Loss: 0.4241\n",
            "Epoch 95, Batch 223/224, Training Loss: 0.3844\n",
            "Epoch 95/100, Training Loss: 0.3845, Test Loss: 3.0292\n",
            "Epoch 96, Batch 0/224, Training Loss: 0.2344\n",
            "Epoch 96, Batch 1/224, Training Loss: 0.3482\n",
            "Epoch 96, Batch 2/224, Training Loss: 0.3843\n",
            "Epoch 96, Batch 3/224, Training Loss: 0.5056\n",
            "Epoch 96, Batch 4/224, Training Loss: 0.3357\n",
            "Epoch 96, Batch 5/224, Training Loss: 0.3577\n",
            "Epoch 96, Batch 6/224, Training Loss: 0.2697\n",
            "Epoch 96, Batch 7/224, Training Loss: 0.1997\n",
            "Epoch 96, Batch 8/224, Training Loss: 0.3587\n",
            "Epoch 96, Batch 9/224, Training Loss: 0.3502\n",
            "Epoch 96, Batch 10/224, Training Loss: 0.7791\n",
            "Epoch 96, Batch 11/224, Training Loss: 0.3886\n",
            "Epoch 96, Batch 12/224, Training Loss: 0.2837\n",
            "Epoch 96, Batch 13/224, Training Loss: 0.2699\n",
            "Epoch 96, Batch 14/224, Training Loss: 0.2080\n",
            "Epoch 96, Batch 15/224, Training Loss: 0.7086\n",
            "Epoch 96, Batch 16/224, Training Loss: 0.2494\n",
            "Epoch 96, Batch 17/224, Training Loss: 0.3246\n",
            "Epoch 96, Batch 18/224, Training Loss: 0.2998\n",
            "Epoch 96, Batch 19/224, Training Loss: 0.2869\n",
            "Epoch 96, Batch 20/224, Training Loss: 0.3065\n",
            "Epoch 96, Batch 21/224, Training Loss: 0.3366\n",
            "Epoch 96, Batch 22/224, Training Loss: 0.4111\n",
            "Epoch 96, Batch 23/224, Training Loss: 0.3181\n",
            "Epoch 96, Batch 24/224, Training Loss: 0.9106\n",
            "Epoch 96, Batch 25/224, Training Loss: 0.4083\n",
            "Epoch 96, Batch 26/224, Training Loss: 0.3246\n",
            "Epoch 96, Batch 27/224, Training Loss: 0.2593\n",
            "Epoch 96, Batch 28/224, Training Loss: 0.3181\n",
            "Epoch 96, Batch 29/224, Training Loss: 0.2703\n",
            "Epoch 96, Batch 30/224, Training Loss: 0.4584\n",
            "Epoch 96, Batch 31/224, Training Loss: 0.3807\n",
            "Epoch 96, Batch 32/224, Training Loss: 0.3617\n",
            "Epoch 96, Batch 33/224, Training Loss: 0.3079\n",
            "Epoch 96, Batch 34/224, Training Loss: 0.3849\n",
            "Epoch 96, Batch 35/224, Training Loss: 0.2598\n",
            "Epoch 96, Batch 36/224, Training Loss: 0.2932\n",
            "Epoch 96, Batch 37/224, Training Loss: 0.4607\n",
            "Epoch 96, Batch 38/224, Training Loss: 0.3093\n",
            "Epoch 96, Batch 39/224, Training Loss: 0.3197\n",
            "Epoch 96, Batch 40/224, Training Loss: 0.3547\n",
            "Epoch 96, Batch 41/224, Training Loss: 0.1994\n",
            "Epoch 96, Batch 42/224, Training Loss: 0.3160\n",
            "Epoch 96, Batch 43/224, Training Loss: 0.2807\n",
            "Epoch 96, Batch 44/224, Training Loss: 0.5896\n",
            "Epoch 96, Batch 45/224, Training Loss: 0.3844\n",
            "Epoch 96, Batch 46/224, Training Loss: 0.3916\n",
            "Epoch 96, Batch 47/224, Training Loss: 0.4039\n",
            "Epoch 96, Batch 48/224, Training Loss: 0.5592\n",
            "Epoch 96, Batch 49/224, Training Loss: 0.4411\n",
            "Epoch 96, Batch 50/224, Training Loss: 0.3423\n",
            "Epoch 96, Batch 51/224, Training Loss: 0.3390\n",
            "Epoch 96, Batch 52/224, Training Loss: 0.3228\n",
            "Epoch 96, Batch 53/224, Training Loss: 0.4260\n",
            "Epoch 96, Batch 54/224, Training Loss: 0.4919\n",
            "Epoch 96, Batch 55/224, Training Loss: 0.2119\n",
            "Epoch 96, Batch 56/224, Training Loss: 0.2742\n",
            "Epoch 96, Batch 57/224, Training Loss: 0.3235\n",
            "Epoch 96, Batch 58/224, Training Loss: 0.3671\n",
            "Epoch 96, Batch 59/224, Training Loss: 0.5769\n",
            "Epoch 96, Batch 60/224, Training Loss: 0.3485\n",
            "Epoch 96, Batch 61/224, Training Loss: 0.3310\n",
            "Epoch 96, Batch 62/224, Training Loss: 0.3616\n",
            "Epoch 96, Batch 63/224, Training Loss: 0.1847\n",
            "Epoch 96, Batch 64/224, Training Loss: 0.5658\n",
            "Epoch 96, Batch 65/224, Training Loss: 0.7907\n",
            "Epoch 96, Batch 66/224, Training Loss: 0.2954\n",
            "Epoch 96, Batch 67/224, Training Loss: 0.3776\n",
            "Epoch 96, Batch 68/224, Training Loss: 0.4467\n",
            "Epoch 96, Batch 69/224, Training Loss: 0.4975\n",
            "Epoch 96, Batch 70/224, Training Loss: 0.5634\n",
            "Epoch 96, Batch 71/224, Training Loss: 0.3898\n",
            "Epoch 96, Batch 72/224, Training Loss: 0.2180\n",
            "Epoch 96, Batch 73/224, Training Loss: 0.4122\n",
            "Epoch 96, Batch 74/224, Training Loss: 0.3547\n",
            "Epoch 96, Batch 75/224, Training Loss: 0.3719\n",
            "Epoch 96, Batch 76/224, Training Loss: 0.5641\n",
            "Epoch 96, Batch 77/224, Training Loss: 0.3275\n",
            "Epoch 96, Batch 78/224, Training Loss: 0.2192\n",
            "Epoch 96, Batch 79/224, Training Loss: 0.2939\n",
            "Epoch 96, Batch 80/224, Training Loss: 0.3029\n",
            "Epoch 96, Batch 81/224, Training Loss: 0.3732\n",
            "Epoch 96, Batch 82/224, Training Loss: 0.3436\n",
            "Epoch 96, Batch 83/224, Training Loss: 0.2858\n",
            "Epoch 96, Batch 84/224, Training Loss: 0.5194\n",
            "Epoch 96, Batch 85/224, Training Loss: 0.3863\n",
            "Epoch 96, Batch 86/224, Training Loss: 0.6906\n",
            "Epoch 96, Batch 87/224, Training Loss: 0.3711\n",
            "Epoch 96, Batch 88/224, Training Loss: 0.3020\n",
            "Epoch 96, Batch 89/224, Training Loss: 0.2784\n",
            "Epoch 96, Batch 90/224, Training Loss: 0.2909\n",
            "Epoch 96, Batch 91/224, Training Loss: 0.2593\n",
            "Epoch 96, Batch 92/224, Training Loss: 0.3495\n",
            "Epoch 96, Batch 93/224, Training Loss: 0.3123\n",
            "Epoch 96, Batch 94/224, Training Loss: 0.4137\n",
            "Epoch 96, Batch 95/224, Training Loss: 0.5899\n",
            "Epoch 96, Batch 96/224, Training Loss: 0.5382\n",
            "Epoch 96, Batch 97/224, Training Loss: 0.5055\n",
            "Epoch 96, Batch 98/224, Training Loss: 0.2788\n",
            "Epoch 96, Batch 99/224, Training Loss: 0.3756\n",
            "Epoch 96, Batch 100/224, Training Loss: 0.2983\n",
            "Epoch 96, Batch 101/224, Training Loss: 0.2964\n",
            "Epoch 96, Batch 102/224, Training Loss: 0.4168\n",
            "Epoch 96, Batch 103/224, Training Loss: 0.5444\n",
            "Epoch 96, Batch 104/224, Training Loss: 0.3047\n",
            "Epoch 96, Batch 105/224, Training Loss: 0.5361\n",
            "Epoch 96, Batch 106/224, Training Loss: 0.3463\n",
            "Epoch 96, Batch 107/224, Training Loss: 0.4012\n",
            "Epoch 96, Batch 108/224, Training Loss: 0.3328\n",
            "Epoch 96, Batch 109/224, Training Loss: 0.4941\n",
            "Epoch 96, Batch 110/224, Training Loss: 0.4284\n",
            "Epoch 96, Batch 111/224, Training Loss: 0.3338\n",
            "Epoch 96, Batch 112/224, Training Loss: 0.2671\n",
            "Epoch 96, Batch 113/224, Training Loss: 0.5860\n",
            "Epoch 96, Batch 114/224, Training Loss: 0.4272\n",
            "Epoch 96, Batch 115/224, Training Loss: 0.4053\n",
            "Epoch 96, Batch 116/224, Training Loss: 0.3817\n",
            "Epoch 96, Batch 117/224, Training Loss: 0.2420\n",
            "Epoch 96, Batch 118/224, Training Loss: 0.2524\n",
            "Epoch 96, Batch 119/224, Training Loss: 0.3331\n",
            "Epoch 96, Batch 120/224, Training Loss: 0.4510\n",
            "Epoch 96, Batch 121/224, Training Loss: 0.3513\n",
            "Epoch 96, Batch 122/224, Training Loss: 0.3353\n",
            "Epoch 96, Batch 123/224, Training Loss: 0.4953\n",
            "Epoch 96, Batch 124/224, Training Loss: 0.2972\n",
            "Epoch 96, Batch 125/224, Training Loss: 0.4515\n",
            "Epoch 96, Batch 126/224, Training Loss: 0.3150\n",
            "Epoch 96, Batch 127/224, Training Loss: 0.3982\n",
            "Epoch 96, Batch 128/224, Training Loss: 0.2690\n",
            "Epoch 96, Batch 129/224, Training Loss: 0.2775\n",
            "Epoch 96, Batch 130/224, Training Loss: 0.5811\n",
            "Epoch 96, Batch 131/224, Training Loss: 0.2920\n",
            "Epoch 96, Batch 132/224, Training Loss: 0.2264\n",
            "Epoch 96, Batch 133/224, Training Loss: 0.2247\n",
            "Epoch 96, Batch 134/224, Training Loss: 0.3150\n",
            "Epoch 96, Batch 135/224, Training Loss: 0.7503\n",
            "Epoch 96, Batch 136/224, Training Loss: 0.2894\n",
            "Epoch 96, Batch 137/224, Training Loss: 0.3839\n",
            "Epoch 96, Batch 138/224, Training Loss: 0.5233\n",
            "Epoch 96, Batch 139/224, Training Loss: 0.3181\n",
            "Epoch 96, Batch 140/224, Training Loss: 0.3109\n",
            "Epoch 96, Batch 141/224, Training Loss: 0.3608\n",
            "Epoch 96, Batch 142/224, Training Loss: 0.3128\n",
            "Epoch 96, Batch 143/224, Training Loss: 0.2599\n",
            "Epoch 96, Batch 144/224, Training Loss: 0.6891\n",
            "Epoch 96, Batch 145/224, Training Loss: 0.2532\n",
            "Epoch 96, Batch 146/224, Training Loss: 0.3873\n",
            "Epoch 96, Batch 147/224, Training Loss: 0.6892\n",
            "Epoch 96, Batch 148/224, Training Loss: 0.4286\n",
            "Epoch 96, Batch 149/224, Training Loss: 0.2203\n",
            "Epoch 96, Batch 150/224, Training Loss: 0.4304\n",
            "Epoch 96, Batch 151/224, Training Loss: 0.2990\n",
            "Epoch 96, Batch 152/224, Training Loss: 0.2836\n",
            "Epoch 96, Batch 153/224, Training Loss: 0.3255\n",
            "Epoch 96, Batch 154/224, Training Loss: 0.3533\n",
            "Epoch 96, Batch 155/224, Training Loss: 0.2522\n",
            "Epoch 96, Batch 156/224, Training Loss: 0.3225\n",
            "Epoch 96, Batch 157/224, Training Loss: 0.1988\n",
            "Epoch 96, Batch 158/224, Training Loss: 0.2703\n",
            "Epoch 96, Batch 159/224, Training Loss: 0.3105\n",
            "Epoch 96, Batch 160/224, Training Loss: 0.4119\n",
            "Epoch 96, Batch 161/224, Training Loss: 0.6042\n",
            "Epoch 96, Batch 162/224, Training Loss: 0.7087\n",
            "Epoch 96, Batch 163/224, Training Loss: 0.3577\n",
            "Epoch 96, Batch 164/224, Training Loss: 0.4463\n",
            "Epoch 96, Batch 165/224, Training Loss: 0.2688\n",
            "Epoch 96, Batch 166/224, Training Loss: 0.3122\n",
            "Epoch 96, Batch 167/224, Training Loss: 0.6429\n",
            "Epoch 96, Batch 168/224, Training Loss: 0.2890\n",
            "Epoch 96, Batch 169/224, Training Loss: 0.4482\n",
            "Epoch 96, Batch 170/224, Training Loss: 0.3020\n",
            "Epoch 96, Batch 171/224, Training Loss: 0.6059\n",
            "Epoch 96, Batch 172/224, Training Loss: 0.2892\n",
            "Epoch 96, Batch 173/224, Training Loss: 0.3009\n",
            "Epoch 96, Batch 174/224, Training Loss: 0.3003\n",
            "Epoch 96, Batch 175/224, Training Loss: 0.6134\n",
            "Epoch 96, Batch 176/224, Training Loss: 0.3386\n",
            "Epoch 96, Batch 177/224, Training Loss: 0.3578\n",
            "Epoch 96, Batch 178/224, Training Loss: 0.4005\n",
            "Epoch 96, Batch 179/224, Training Loss: 0.7263\n",
            "Epoch 96, Batch 180/224, Training Loss: 0.3634\n",
            "Epoch 96, Batch 181/224, Training Loss: 0.2829\n",
            "Epoch 96, Batch 182/224, Training Loss: 0.5770\n",
            "Epoch 96, Batch 183/224, Training Loss: 0.5414\n",
            "Epoch 96, Batch 184/224, Training Loss: 0.4018\n",
            "Epoch 96, Batch 185/224, Training Loss: 0.2361\n",
            "Epoch 96, Batch 186/224, Training Loss: 0.5633\n",
            "Epoch 96, Batch 187/224, Training Loss: 0.2267\n",
            "Epoch 96, Batch 188/224, Training Loss: 0.3313\n",
            "Epoch 96, Batch 189/224, Training Loss: 0.2999\n",
            "Epoch 96, Batch 190/224, Training Loss: 0.2545\n",
            "Epoch 96, Batch 191/224, Training Loss: 0.6818\n",
            "Epoch 96, Batch 192/224, Training Loss: 0.3690\n",
            "Epoch 96, Batch 193/224, Training Loss: 0.2391\n",
            "Epoch 96, Batch 194/224, Training Loss: 0.2633\n",
            "Epoch 96, Batch 195/224, Training Loss: 0.4302\n",
            "Epoch 96, Batch 196/224, Training Loss: 0.2279\n",
            "Epoch 96, Batch 197/224, Training Loss: 0.5780\n",
            "Epoch 96, Batch 198/224, Training Loss: 0.4089\n",
            "Epoch 96, Batch 199/224, Training Loss: 0.3122\n",
            "Epoch 96, Batch 200/224, Training Loss: 0.3139\n",
            "Epoch 96, Batch 201/224, Training Loss: 0.2955\n",
            "Epoch 96, Batch 202/224, Training Loss: 0.2863\n",
            "Epoch 96, Batch 203/224, Training Loss: 0.3729\n",
            "Epoch 96, Batch 204/224, Training Loss: 0.4406\n",
            "Epoch 96, Batch 205/224, Training Loss: 0.4636\n",
            "Epoch 96, Batch 206/224, Training Loss: 0.3627\n",
            "Epoch 96, Batch 207/224, Training Loss: 0.3167\n",
            "Epoch 96, Batch 208/224, Training Loss: 0.5313\n",
            "Epoch 96, Batch 209/224, Training Loss: 0.4384\n",
            "Epoch 96, Batch 210/224, Training Loss: 0.3051\n",
            "Epoch 96, Batch 211/224, Training Loss: 0.4272\n",
            "Epoch 96, Batch 212/224, Training Loss: 0.2956\n",
            "Epoch 96, Batch 213/224, Training Loss: 0.5839\n",
            "Epoch 96, Batch 214/224, Training Loss: 0.2553\n",
            "Epoch 96, Batch 215/224, Training Loss: 0.4320\n",
            "Epoch 96, Batch 216/224, Training Loss: 0.2718\n",
            "Epoch 96, Batch 217/224, Training Loss: 0.4311\n",
            "Epoch 96, Batch 218/224, Training Loss: 0.3231\n",
            "Epoch 96, Batch 219/224, Training Loss: 0.3426\n",
            "Epoch 96, Batch 220/224, Training Loss: 0.3526\n",
            "Epoch 96, Batch 221/224, Training Loss: 0.2805\n",
            "Epoch 96, Batch 222/224, Training Loss: 0.9589\n",
            "Epoch 96, Batch 223/224, Training Loss: 0.3195\n",
            "Epoch 96/100, Training Loss: 0.3824, Test Loss: 3.0273\n",
            "Epoch 97, Batch 0/224, Training Loss: 0.2300\n",
            "Epoch 97, Batch 1/224, Training Loss: 0.2663\n",
            "Epoch 97, Batch 2/224, Training Loss: 0.2741\n",
            "Epoch 97, Batch 3/224, Training Loss: 0.3623\n",
            "Epoch 97, Batch 4/224, Training Loss: 0.2446\n",
            "Epoch 97, Batch 5/224, Training Loss: 0.2835\n",
            "Epoch 97, Batch 6/224, Training Loss: 0.3887\n",
            "Epoch 97, Batch 7/224, Training Loss: 0.6554\n",
            "Epoch 97, Batch 8/224, Training Loss: 0.2476\n",
            "Epoch 97, Batch 9/224, Training Loss: 0.2142\n",
            "Epoch 97, Batch 10/224, Training Loss: 0.2531\n",
            "Epoch 97, Batch 11/224, Training Loss: 0.3730\n",
            "Epoch 97, Batch 12/224, Training Loss: 0.4830\n",
            "Epoch 97, Batch 13/224, Training Loss: 0.5627\n",
            "Epoch 97, Batch 14/224, Training Loss: 0.2068\n",
            "Epoch 97, Batch 15/224, Training Loss: 0.4873\n",
            "Epoch 97, Batch 16/224, Training Loss: 0.4172\n",
            "Epoch 97, Batch 17/224, Training Loss: 0.3957\n",
            "Epoch 97, Batch 18/224, Training Loss: 0.2215\n",
            "Epoch 97, Batch 19/224, Training Loss: 0.3085\n",
            "Epoch 97, Batch 20/224, Training Loss: 0.1880\n",
            "Epoch 97, Batch 21/224, Training Loss: 0.3095\n",
            "Epoch 97, Batch 22/224, Training Loss: 0.4601\n",
            "Epoch 97, Batch 23/224, Training Loss: 0.4255\n",
            "Epoch 97, Batch 24/224, Training Loss: 0.2709\n",
            "Epoch 97, Batch 25/224, Training Loss: 0.3866\n",
            "Epoch 97, Batch 26/224, Training Loss: 0.3672\n",
            "Epoch 97, Batch 27/224, Training Loss: 0.4294\n",
            "Epoch 97, Batch 28/224, Training Loss: 0.3168\n",
            "Epoch 97, Batch 29/224, Training Loss: 0.3844\n",
            "Epoch 97, Batch 30/224, Training Loss: 0.4817\n",
            "Epoch 97, Batch 31/224, Training Loss: 0.5214\n",
            "Epoch 97, Batch 32/224, Training Loss: 0.4472\n",
            "Epoch 97, Batch 33/224, Training Loss: 0.2415\n",
            "Epoch 97, Batch 34/224, Training Loss: 0.3164\n",
            "Epoch 97, Batch 35/224, Training Loss: 0.3273\n",
            "Epoch 97, Batch 36/224, Training Loss: 0.3268\n",
            "Epoch 97, Batch 37/224, Training Loss: 0.3934\n",
            "Epoch 97, Batch 38/224, Training Loss: 0.4662\n",
            "Epoch 97, Batch 39/224, Training Loss: 0.2182\n",
            "Epoch 97, Batch 40/224, Training Loss: 0.5045\n",
            "Epoch 97, Batch 41/224, Training Loss: 0.3401\n",
            "Epoch 97, Batch 42/224, Training Loss: 0.3600\n",
            "Epoch 97, Batch 43/224, Training Loss: 0.2588\n",
            "Epoch 97, Batch 44/224, Training Loss: 0.3733\n",
            "Epoch 97, Batch 45/224, Training Loss: 0.2461\n",
            "Epoch 97, Batch 46/224, Training Loss: 0.4432\n",
            "Epoch 97, Batch 47/224, Training Loss: 0.7705\n",
            "Epoch 97, Batch 48/224, Training Loss: 0.9201\n",
            "Epoch 97, Batch 49/224, Training Loss: 0.3162\n",
            "Epoch 97, Batch 50/224, Training Loss: 0.3627\n",
            "Epoch 97, Batch 51/224, Training Loss: 0.2301\n",
            "Epoch 97, Batch 52/224, Training Loss: 0.2521\n",
            "Epoch 97, Batch 53/224, Training Loss: 0.2360\n",
            "Epoch 97, Batch 54/224, Training Loss: 0.4015\n",
            "Epoch 97, Batch 55/224, Training Loss: 0.3269\n",
            "Epoch 97, Batch 56/224, Training Loss: 0.3169\n",
            "Epoch 97, Batch 57/224, Training Loss: 0.2473\n",
            "Epoch 97, Batch 58/224, Training Loss: 0.6054\n",
            "Epoch 97, Batch 59/224, Training Loss: 0.3828\n",
            "Epoch 97, Batch 60/224, Training Loss: 0.4649\n",
            "Epoch 97, Batch 61/224, Training Loss: 0.3674\n",
            "Epoch 97, Batch 62/224, Training Loss: 0.2281\n",
            "Epoch 97, Batch 63/224, Training Loss: 0.3523\n",
            "Epoch 97, Batch 64/224, Training Loss: 0.4479\n",
            "Epoch 97, Batch 65/224, Training Loss: 0.4339\n",
            "Epoch 97, Batch 66/224, Training Loss: 0.2811\n",
            "Epoch 97, Batch 67/224, Training Loss: 0.3216\n",
            "Epoch 97, Batch 68/224, Training Loss: 0.2049\n",
            "Epoch 97, Batch 69/224, Training Loss: 0.3891\n",
            "Epoch 97, Batch 70/224, Training Loss: 0.3179\n",
            "Epoch 97, Batch 71/224, Training Loss: 0.3231\n",
            "Epoch 97, Batch 72/224, Training Loss: 0.7668\n",
            "Epoch 97, Batch 73/224, Training Loss: 0.1600\n",
            "Epoch 97, Batch 74/224, Training Loss: 0.9051\n",
            "Epoch 97, Batch 75/224, Training Loss: 0.2474\n",
            "Epoch 97, Batch 76/224, Training Loss: 0.2562\n",
            "Epoch 97, Batch 77/224, Training Loss: 0.4417\n",
            "Epoch 97, Batch 78/224, Training Loss: 0.4226\n",
            "Epoch 97, Batch 79/224, Training Loss: 0.4056\n",
            "Epoch 97, Batch 80/224, Training Loss: 0.2967\n",
            "Epoch 97, Batch 81/224, Training Loss: 0.2788\n",
            "Epoch 97, Batch 82/224, Training Loss: 0.4219\n",
            "Epoch 97, Batch 83/224, Training Loss: 0.3258\n",
            "Epoch 97, Batch 84/224, Training Loss: 0.5525\n",
            "Epoch 97, Batch 85/224, Training Loss: 0.3596\n",
            "Epoch 97, Batch 86/224, Training Loss: 0.2409\n",
            "Epoch 97, Batch 87/224, Training Loss: 0.2897\n",
            "Epoch 97, Batch 88/224, Training Loss: 0.3007\n",
            "Epoch 97, Batch 89/224, Training Loss: 0.6403\n",
            "Epoch 97, Batch 90/224, Training Loss: 0.2647\n",
            "Epoch 97, Batch 91/224, Training Loss: 0.2539\n",
            "Epoch 97, Batch 92/224, Training Loss: 0.4040\n",
            "Epoch 97, Batch 93/224, Training Loss: 0.4343\n",
            "Epoch 97, Batch 94/224, Training Loss: 0.3085\n",
            "Epoch 97, Batch 95/224, Training Loss: 0.4845\n",
            "Epoch 97, Batch 96/224, Training Loss: 0.7352\n",
            "Epoch 97, Batch 97/224, Training Loss: 0.6334\n",
            "Epoch 97, Batch 98/224, Training Loss: 0.5575\n",
            "Epoch 97, Batch 99/224, Training Loss: 0.3479\n",
            "Epoch 97, Batch 100/224, Training Loss: 0.2402\n",
            "Epoch 97, Batch 101/224, Training Loss: 0.4189\n",
            "Epoch 97, Batch 102/224, Training Loss: 0.4419\n",
            "Epoch 97, Batch 103/224, Training Loss: 0.3726\n",
            "Epoch 97, Batch 104/224, Training Loss: 0.2071\n",
            "Epoch 97, Batch 105/224, Training Loss: 0.3139\n",
            "Epoch 97, Batch 106/224, Training Loss: 0.3135\n",
            "Epoch 97, Batch 107/224, Training Loss: 0.4105\n",
            "Epoch 97, Batch 108/224, Training Loss: 0.2745\n",
            "Epoch 97, Batch 109/224, Training Loss: 0.4324\n",
            "Epoch 97, Batch 110/224, Training Loss: 0.4551\n",
            "Epoch 97, Batch 111/224, Training Loss: 0.7788\n",
            "Epoch 97, Batch 112/224, Training Loss: 0.4091\n",
            "Epoch 97, Batch 113/224, Training Loss: 0.3577\n",
            "Epoch 97, Batch 114/224, Training Loss: 0.2663\n",
            "Epoch 97, Batch 115/224, Training Loss: 0.3011\n",
            "Epoch 97, Batch 116/224, Training Loss: 0.2731\n",
            "Epoch 97, Batch 117/224, Training Loss: 0.3520\n",
            "Epoch 97, Batch 118/224, Training Loss: 0.2753\n",
            "Epoch 97, Batch 119/224, Training Loss: 0.3919\n",
            "Epoch 97, Batch 120/224, Training Loss: 0.3106\n",
            "Epoch 97, Batch 121/224, Training Loss: 0.5858\n",
            "Epoch 97, Batch 122/224, Training Loss: 0.4823\n",
            "Epoch 97, Batch 123/224, Training Loss: 0.2181\n",
            "Epoch 97, Batch 124/224, Training Loss: 0.4007\n",
            "Epoch 97, Batch 125/224, Training Loss: 0.3664\n",
            "Epoch 97, Batch 126/224, Training Loss: 0.2802\n",
            "Epoch 97, Batch 127/224, Training Loss: 0.6167\n",
            "Epoch 97, Batch 128/224, Training Loss: 0.3437\n",
            "Epoch 97, Batch 129/224, Training Loss: 0.3144\n",
            "Epoch 97, Batch 130/224, Training Loss: 0.3041\n",
            "Epoch 97, Batch 131/224, Training Loss: 0.3468\n",
            "Epoch 97, Batch 132/224, Training Loss: 0.4290\n",
            "Epoch 97, Batch 133/224, Training Loss: 0.7759\n",
            "Epoch 97, Batch 134/224, Training Loss: 0.4099\n",
            "Epoch 97, Batch 135/224, Training Loss: 0.3577\n",
            "Epoch 97, Batch 136/224, Training Loss: 0.3321\n",
            "Epoch 97, Batch 137/224, Training Loss: 0.5246\n",
            "Epoch 97, Batch 138/224, Training Loss: 0.5220\n",
            "Epoch 97, Batch 139/224, Training Loss: 0.3308\n",
            "Epoch 97, Batch 140/224, Training Loss: 0.2525\n",
            "Epoch 97, Batch 141/224, Training Loss: 0.8358\n",
            "Epoch 97, Batch 142/224, Training Loss: 0.3898\n",
            "Epoch 97, Batch 143/224, Training Loss: 0.3872\n",
            "Epoch 97, Batch 144/224, Training Loss: 0.8405\n",
            "Epoch 97, Batch 145/224, Training Loss: 0.3016\n",
            "Epoch 97, Batch 146/224, Training Loss: 0.5610\n",
            "Epoch 97, Batch 147/224, Training Loss: 0.3130\n",
            "Epoch 97, Batch 148/224, Training Loss: 0.2563\n",
            "Epoch 97, Batch 149/224, Training Loss: 0.4062\n",
            "Epoch 97, Batch 150/224, Training Loss: 0.5028\n",
            "Epoch 97, Batch 151/224, Training Loss: 0.4562\n",
            "Epoch 97, Batch 152/224, Training Loss: 0.2772\n",
            "Epoch 97, Batch 153/224, Training Loss: 0.6182\n",
            "Epoch 97, Batch 154/224, Training Loss: 0.2325\n",
            "Epoch 97, Batch 155/224, Training Loss: 0.3409\n",
            "Epoch 97, Batch 156/224, Training Loss: 0.5870\n",
            "Epoch 97, Batch 157/224, Training Loss: 0.3582\n",
            "Epoch 97, Batch 158/224, Training Loss: 0.3075\n",
            "Epoch 97, Batch 159/224, Training Loss: 0.3363\n",
            "Epoch 97, Batch 160/224, Training Loss: 0.2931\n",
            "Epoch 97, Batch 161/224, Training Loss: 0.6363\n",
            "Epoch 97, Batch 162/224, Training Loss: 0.5084\n",
            "Epoch 97, Batch 163/224, Training Loss: 0.2511\n",
            "Epoch 97, Batch 164/224, Training Loss: 0.2696\n",
            "Epoch 97, Batch 165/224, Training Loss: 0.3136\n",
            "Epoch 97, Batch 166/224, Training Loss: 0.3751\n",
            "Epoch 97, Batch 167/224, Training Loss: 0.2623\n",
            "Epoch 97, Batch 168/224, Training Loss: 0.2693\n",
            "Epoch 97, Batch 169/224, Training Loss: 0.4787\n",
            "Epoch 97, Batch 170/224, Training Loss: 0.3525\n",
            "Epoch 97, Batch 171/224, Training Loss: 0.5073\n",
            "Epoch 97, Batch 172/224, Training Loss: 0.3029\n",
            "Epoch 97, Batch 173/224, Training Loss: 0.3666\n",
            "Epoch 97, Batch 174/224, Training Loss: 0.4285\n",
            "Epoch 97, Batch 175/224, Training Loss: 0.2732\n",
            "Epoch 97, Batch 176/224, Training Loss: 0.3036\n",
            "Epoch 97, Batch 177/224, Training Loss: 0.3522\n",
            "Epoch 97, Batch 178/224, Training Loss: 0.2835\n",
            "Epoch 97, Batch 179/224, Training Loss: 0.2519\n",
            "Epoch 97, Batch 180/224, Training Loss: 0.8730\n",
            "Epoch 97, Batch 181/224, Training Loss: 0.3302\n",
            "Epoch 97, Batch 182/224, Training Loss: 0.6017\n",
            "Epoch 97, Batch 183/224, Training Loss: 0.3048\n",
            "Epoch 97, Batch 184/224, Training Loss: 0.4316\n",
            "Epoch 97, Batch 185/224, Training Loss: 0.5176\n",
            "Epoch 97, Batch 186/224, Training Loss: 0.4081\n",
            "Epoch 97, Batch 187/224, Training Loss: 0.4636\n",
            "Epoch 97, Batch 188/224, Training Loss: 0.3757\n",
            "Epoch 97, Batch 189/224, Training Loss: 0.4514\n",
            "Epoch 97, Batch 190/224, Training Loss: 0.3326\n",
            "Epoch 97, Batch 191/224, Training Loss: 0.3880\n",
            "Epoch 97, Batch 192/224, Training Loss: 0.4116\n",
            "Epoch 97, Batch 193/224, Training Loss: 0.4088\n",
            "Epoch 97, Batch 194/224, Training Loss: 0.3473\n",
            "Epoch 97, Batch 195/224, Training Loss: 0.3884\n",
            "Epoch 97, Batch 196/224, Training Loss: 0.3641\n",
            "Epoch 97, Batch 197/224, Training Loss: 0.3334\n",
            "Epoch 97, Batch 198/224, Training Loss: 0.3638\n",
            "Epoch 97, Batch 199/224, Training Loss: 0.5062\n",
            "Epoch 97, Batch 200/224, Training Loss: 0.2721\n",
            "Epoch 97, Batch 201/224, Training Loss: 0.3382\n",
            "Epoch 97, Batch 202/224, Training Loss: 0.3071\n",
            "Epoch 97, Batch 203/224, Training Loss: 0.4651\n",
            "Epoch 97, Batch 204/224, Training Loss: 0.4621\n",
            "Epoch 97, Batch 205/224, Training Loss: 0.2996\n",
            "Epoch 97, Batch 206/224, Training Loss: 0.4105\n",
            "Epoch 97, Batch 207/224, Training Loss: 0.3306\n",
            "Epoch 97, Batch 208/224, Training Loss: 0.3914\n",
            "Epoch 97, Batch 209/224, Training Loss: 0.4151\n",
            "Epoch 97, Batch 210/224, Training Loss: 0.3134\n",
            "Epoch 97, Batch 211/224, Training Loss: 0.3147\n",
            "Epoch 97, Batch 212/224, Training Loss: 0.5431\n",
            "Epoch 97, Batch 213/224, Training Loss: 0.4488\n",
            "Epoch 97, Batch 214/224, Training Loss: 0.3480\n",
            "Epoch 97, Batch 215/224, Training Loss: 0.5205\n",
            "Epoch 97, Batch 216/224, Training Loss: 0.2100\n",
            "Epoch 97, Batch 217/224, Training Loss: 0.3059\n",
            "Epoch 97, Batch 218/224, Training Loss: 0.2358\n",
            "Epoch 97, Batch 219/224, Training Loss: 0.3234\n",
            "Epoch 97, Batch 220/224, Training Loss: 0.4626\n",
            "Epoch 97, Batch 221/224, Training Loss: 0.2946\n",
            "Epoch 97, Batch 222/224, Training Loss: 0.3250\n",
            "Epoch 97, Batch 223/224, Training Loss: 0.3736\n",
            "Epoch 97/100, Training Loss: 0.3858, Test Loss: 2.9851\n",
            "Epoch 98, Batch 0/224, Training Loss: 0.2158\n",
            "Epoch 98, Batch 1/224, Training Loss: 0.2822\n",
            "Epoch 98, Batch 2/224, Training Loss: 0.5184\n",
            "Epoch 98, Batch 3/224, Training Loss: 0.3485\n",
            "Epoch 98, Batch 4/224, Training Loss: 0.3442\n",
            "Epoch 98, Batch 5/224, Training Loss: 0.6209\n",
            "Epoch 98, Batch 6/224, Training Loss: 0.2688\n",
            "Epoch 98, Batch 7/224, Training Loss: 0.2707\n",
            "Epoch 98, Batch 8/224, Training Loss: 0.4667\n",
            "Epoch 98, Batch 9/224, Training Loss: 0.3587\n",
            "Epoch 98, Batch 10/224, Training Loss: 0.3542\n",
            "Epoch 98, Batch 11/224, Training Loss: 0.5805\n",
            "Epoch 98, Batch 12/224, Training Loss: 0.2248\n",
            "Epoch 98, Batch 13/224, Training Loss: 0.3125\n",
            "Epoch 98, Batch 14/224, Training Loss: 0.3322\n",
            "Epoch 98, Batch 15/224, Training Loss: 0.3017\n",
            "Epoch 98, Batch 16/224, Training Loss: 0.6165\n",
            "Epoch 98, Batch 17/224, Training Loss: 0.2678\n",
            "Epoch 98, Batch 18/224, Training Loss: 0.3523\n",
            "Epoch 98, Batch 19/224, Training Loss: 0.3571\n",
            "Epoch 98, Batch 20/224, Training Loss: 0.2530\n",
            "Epoch 98, Batch 21/224, Training Loss: 0.2790\n",
            "Epoch 98, Batch 22/224, Training Loss: 0.3536\n",
            "Epoch 98, Batch 23/224, Training Loss: 0.3363\n",
            "Epoch 98, Batch 24/224, Training Loss: 0.3390\n",
            "Epoch 98, Batch 25/224, Training Loss: 0.2936\n",
            "Epoch 98, Batch 26/224, Training Loss: 0.2337\n",
            "Epoch 98, Batch 27/224, Training Loss: 0.2458\n",
            "Epoch 98, Batch 28/224, Training Loss: 0.7850\n",
            "Epoch 98, Batch 29/224, Training Loss: 0.1650\n",
            "Epoch 98, Batch 30/224, Training Loss: 0.2470\n",
            "Epoch 98, Batch 31/224, Training Loss: 0.3693\n",
            "Epoch 98, Batch 32/224, Training Loss: 0.4354\n",
            "Epoch 98, Batch 33/224, Training Loss: 0.3569\n",
            "Epoch 98, Batch 34/224, Training Loss: 0.3893\n",
            "Epoch 98, Batch 35/224, Training Loss: 0.2510\n",
            "Epoch 98, Batch 36/224, Training Loss: 0.3297\n",
            "Epoch 98, Batch 37/224, Training Loss: 0.2669\n",
            "Epoch 98, Batch 38/224, Training Loss: 0.3822\n",
            "Epoch 98, Batch 39/224, Training Loss: 0.9770\n",
            "Epoch 98, Batch 40/224, Training Loss: 0.4684\n",
            "Epoch 98, Batch 41/224, Training Loss: 0.3381\n",
            "Epoch 98, Batch 42/224, Training Loss: 0.2226\n",
            "Epoch 98, Batch 43/224, Training Loss: 0.2160\n",
            "Epoch 98, Batch 44/224, Training Loss: 0.5241\n",
            "Epoch 98, Batch 45/224, Training Loss: 0.3334\n",
            "Epoch 98, Batch 46/224, Training Loss: 0.2851\n",
            "Epoch 98, Batch 47/224, Training Loss: 0.3981\n",
            "Epoch 98, Batch 48/224, Training Loss: 0.3136\n",
            "Epoch 98, Batch 49/224, Training Loss: 0.4856\n",
            "Epoch 98, Batch 50/224, Training Loss: 0.7174\n",
            "Epoch 98, Batch 51/224, Training Loss: 0.4937\n",
            "Epoch 98, Batch 52/224, Training Loss: 0.3951\n",
            "Epoch 98, Batch 53/224, Training Loss: 0.6991\n",
            "Epoch 98, Batch 54/224, Training Loss: 0.4362\n",
            "Epoch 98, Batch 55/224, Training Loss: 0.3490\n",
            "Epoch 98, Batch 56/224, Training Loss: 0.4448\n",
            "Epoch 98, Batch 57/224, Training Loss: 0.3794\n",
            "Epoch 98, Batch 58/224, Training Loss: 0.3975\n",
            "Epoch 98, Batch 59/224, Training Loss: 0.3946\n",
            "Epoch 98, Batch 60/224, Training Loss: 0.4034\n",
            "Epoch 98, Batch 61/224, Training Loss: 0.5780\n",
            "Epoch 98, Batch 62/224, Training Loss: 0.5835\n",
            "Epoch 98, Batch 63/224, Training Loss: 0.8588\n",
            "Epoch 98, Batch 64/224, Training Loss: 0.5174\n",
            "Epoch 98, Batch 65/224, Training Loss: 0.3687\n",
            "Epoch 98, Batch 66/224, Training Loss: 0.5858\n",
            "Epoch 98, Batch 67/224, Training Loss: 0.8170\n",
            "Epoch 98, Batch 68/224, Training Loss: 0.5197\n",
            "Epoch 98, Batch 69/224, Training Loss: 0.5601\n",
            "Epoch 98, Batch 70/224, Training Loss: 0.4353\n",
            "Epoch 98, Batch 71/224, Training Loss: 0.3889\n",
            "Epoch 98, Batch 72/224, Training Loss: 0.4991\n",
            "Epoch 98, Batch 73/224, Training Loss: 0.3102\n",
            "Epoch 98, Batch 74/224, Training Loss: 0.5482\n",
            "Epoch 98, Batch 75/224, Training Loss: 0.2295\n",
            "Epoch 98, Batch 76/224, Training Loss: 0.4765\n",
            "Epoch 98, Batch 77/224, Training Loss: 0.5003\n",
            "Epoch 98, Batch 78/224, Training Loss: 0.2756\n",
            "Epoch 98, Batch 79/224, Training Loss: 0.3632\n",
            "Epoch 98, Batch 80/224, Training Loss: 0.4167\n",
            "Epoch 98, Batch 81/224, Training Loss: 0.3659\n",
            "Epoch 98, Batch 82/224, Training Loss: 0.2274\n",
            "Epoch 98, Batch 83/224, Training Loss: 0.4275\n",
            "Epoch 98, Batch 84/224, Training Loss: 0.3258\n",
            "Epoch 98, Batch 85/224, Training Loss: 0.2963\n",
            "Epoch 98, Batch 86/224, Training Loss: 0.2940\n",
            "Epoch 98, Batch 87/224, Training Loss: 0.3231\n",
            "Epoch 98, Batch 88/224, Training Loss: 0.2769\n",
            "Epoch 98, Batch 89/224, Training Loss: 0.3318\n",
            "Epoch 98, Batch 90/224, Training Loss: 0.4260\n",
            "Epoch 98, Batch 91/224, Training Loss: 0.2469\n",
            "Epoch 98, Batch 92/224, Training Loss: 0.2992\n",
            "Epoch 98, Batch 93/224, Training Loss: 0.4299\n",
            "Epoch 98, Batch 94/224, Training Loss: 0.3876\n",
            "Epoch 98, Batch 95/224, Training Loss: 0.3121\n",
            "Epoch 98, Batch 96/224, Training Loss: 0.2996\n",
            "Epoch 98, Batch 97/224, Training Loss: 0.2966\n",
            "Epoch 98, Batch 98/224, Training Loss: 0.3689\n",
            "Epoch 98, Batch 99/224, Training Loss: 0.5095\n",
            "Epoch 98, Batch 100/224, Training Loss: 0.3401\n",
            "Epoch 98, Batch 101/224, Training Loss: 0.5094\n",
            "Epoch 98, Batch 102/224, Training Loss: 0.4312\n",
            "Epoch 98, Batch 103/224, Training Loss: 0.3088\n",
            "Epoch 98, Batch 104/224, Training Loss: 0.3717\n",
            "Epoch 98, Batch 105/224, Training Loss: 0.3249\n",
            "Epoch 98, Batch 106/224, Training Loss: 0.3428\n",
            "Epoch 98, Batch 107/224, Training Loss: 0.2912\n",
            "Epoch 98, Batch 108/224, Training Loss: 0.2413\n",
            "Epoch 98, Batch 109/224, Training Loss: 0.3531\n",
            "Epoch 98, Batch 110/224, Training Loss: 0.2989\n",
            "Epoch 98, Batch 111/224, Training Loss: 0.5286\n",
            "Epoch 98, Batch 112/224, Training Loss: 0.4360\n",
            "Epoch 98, Batch 113/224, Training Loss: 0.3556\n",
            "Epoch 98, Batch 114/224, Training Loss: 0.4849\n",
            "Epoch 98, Batch 115/224, Training Loss: 0.6066\n",
            "Epoch 98, Batch 116/224, Training Loss: 0.3329\n",
            "Epoch 98, Batch 117/224, Training Loss: 0.3173\n",
            "Epoch 98, Batch 118/224, Training Loss: 1.0316\n",
            "Epoch 98, Batch 119/224, Training Loss: 0.4255\n",
            "Epoch 98, Batch 120/224, Training Loss: 0.4023\n",
            "Epoch 98, Batch 121/224, Training Loss: 0.6841\n",
            "Epoch 98, Batch 122/224, Training Loss: 0.3878\n",
            "Epoch 98, Batch 123/224, Training Loss: 0.3788\n",
            "Epoch 98, Batch 124/224, Training Loss: 0.2686\n",
            "Epoch 98, Batch 125/224, Training Loss: 0.3547\n",
            "Epoch 98, Batch 126/224, Training Loss: 0.2889\n",
            "Epoch 98, Batch 127/224, Training Loss: 0.3151\n",
            "Epoch 98, Batch 128/224, Training Loss: 0.4172\n",
            "Epoch 98, Batch 129/224, Training Loss: 0.3288\n",
            "Epoch 98, Batch 130/224, Training Loss: 0.3727\n",
            "Epoch 98, Batch 131/224, Training Loss: 0.3950\n",
            "Epoch 98, Batch 132/224, Training Loss: 0.5676\n",
            "Epoch 98, Batch 133/224, Training Loss: 0.3051\n",
            "Epoch 98, Batch 134/224, Training Loss: 0.2970\n",
            "Epoch 98, Batch 135/224, Training Loss: 0.3166\n",
            "Epoch 98, Batch 136/224, Training Loss: 0.4496\n",
            "Epoch 98, Batch 137/224, Training Loss: 0.2493\n",
            "Epoch 98, Batch 138/224, Training Loss: 0.2341\n",
            "Epoch 98, Batch 139/224, Training Loss: 0.3195\n",
            "Epoch 98, Batch 140/224, Training Loss: 0.3945\n",
            "Epoch 98, Batch 141/224, Training Loss: 0.4395\n",
            "Epoch 98, Batch 142/224, Training Loss: 0.4146\n",
            "Epoch 98, Batch 143/224, Training Loss: 0.2261\n",
            "Epoch 98, Batch 144/224, Training Loss: 0.9821\n",
            "Epoch 98, Batch 145/224, Training Loss: 0.4474\n",
            "Epoch 98, Batch 146/224, Training Loss: 0.9800\n",
            "Epoch 98, Batch 147/224, Training Loss: 0.4440\n",
            "Epoch 98, Batch 148/224, Training Loss: 0.5469\n",
            "Epoch 98, Batch 149/224, Training Loss: 0.5374\n",
            "Epoch 98, Batch 150/224, Training Loss: 0.2857\n",
            "Epoch 98, Batch 151/224, Training Loss: 0.2255\n",
            "Epoch 98, Batch 152/224, Training Loss: 0.3953\n",
            "Epoch 98, Batch 153/224, Training Loss: 0.3474\n",
            "Epoch 98, Batch 154/224, Training Loss: 0.4167\n",
            "Epoch 98, Batch 155/224, Training Loss: 0.4008\n",
            "Epoch 98, Batch 156/224, Training Loss: 0.2633\n",
            "Epoch 98, Batch 157/224, Training Loss: 0.3807\n",
            "Epoch 98, Batch 158/224, Training Loss: 0.3179\n",
            "Epoch 98, Batch 159/224, Training Loss: 0.2356\n",
            "Epoch 98, Batch 160/224, Training Loss: 0.3979\n",
            "Epoch 98, Batch 161/224, Training Loss: 0.4503\n",
            "Epoch 98, Batch 162/224, Training Loss: 0.2023\n",
            "Epoch 98, Batch 163/224, Training Loss: 0.2450\n",
            "Epoch 98, Batch 164/224, Training Loss: 0.3966\n",
            "Epoch 98, Batch 165/224, Training Loss: 0.2610\n",
            "Epoch 98, Batch 166/224, Training Loss: 0.2538\n",
            "Epoch 98, Batch 167/224, Training Loss: 0.3178\n",
            "Epoch 98, Batch 168/224, Training Loss: 0.2348\n",
            "Epoch 98, Batch 169/224, Training Loss: 0.3084\n",
            "Epoch 98, Batch 170/224, Training Loss: 0.2208\n",
            "Epoch 98, Batch 171/224, Training Loss: 0.5340\n",
            "Epoch 98, Batch 172/224, Training Loss: 0.2588\n",
            "Epoch 98, Batch 173/224, Training Loss: 0.4088\n",
            "Epoch 98, Batch 174/224, Training Loss: 0.4351\n",
            "Epoch 98, Batch 175/224, Training Loss: 0.2262\n",
            "Epoch 98, Batch 176/224, Training Loss: 0.3421\n",
            "Epoch 98, Batch 177/224, Training Loss: 0.4885\n",
            "Epoch 98, Batch 178/224, Training Loss: 0.3368\n",
            "Epoch 98, Batch 179/224, Training Loss: 0.3911\n",
            "Epoch 98, Batch 180/224, Training Loss: 0.4556\n",
            "Epoch 98, Batch 181/224, Training Loss: 0.2665\n",
            "Epoch 98, Batch 182/224, Training Loss: 0.2281\n",
            "Epoch 98, Batch 183/224, Training Loss: 0.3747\n",
            "Epoch 98, Batch 184/224, Training Loss: 0.3554\n",
            "Epoch 98, Batch 185/224, Training Loss: 0.3466\n",
            "Epoch 98, Batch 186/224, Training Loss: 1.2043\n",
            "Epoch 98, Batch 187/224, Training Loss: 0.3814\n",
            "Epoch 98, Batch 188/224, Training Loss: 0.2963\n",
            "Epoch 98, Batch 189/224, Training Loss: 0.6749\n",
            "Epoch 98, Batch 190/224, Training Loss: 0.3672\n",
            "Epoch 98, Batch 191/224, Training Loss: 0.3644\n",
            "Epoch 98, Batch 192/224, Training Loss: 0.3435\n",
            "Epoch 98, Batch 193/224, Training Loss: 0.3581\n",
            "Epoch 98, Batch 194/224, Training Loss: 0.4319\n",
            "Epoch 98, Batch 195/224, Training Loss: 0.4467\n",
            "Epoch 98, Batch 196/224, Training Loss: 0.3165\n",
            "Epoch 98, Batch 197/224, Training Loss: 0.5414\n",
            "Epoch 98, Batch 198/224, Training Loss: 0.4266\n",
            "Epoch 98, Batch 199/224, Training Loss: 0.2910\n",
            "Epoch 98, Batch 200/224, Training Loss: 0.3122\n",
            "Epoch 98, Batch 201/224, Training Loss: 0.4120\n",
            "Epoch 98, Batch 202/224, Training Loss: 0.7589\n",
            "Epoch 98, Batch 203/224, Training Loss: 0.4967\n",
            "Epoch 98, Batch 204/224, Training Loss: 0.7817\n",
            "Epoch 98, Batch 205/224, Training Loss: 0.2282\n",
            "Epoch 98, Batch 206/224, Training Loss: 0.4099\n",
            "Epoch 98, Batch 207/224, Training Loss: 0.2694\n",
            "Epoch 98, Batch 208/224, Training Loss: 0.3011\n",
            "Epoch 98, Batch 209/224, Training Loss: 0.2697\n",
            "Epoch 98, Batch 210/224, Training Loss: 0.4699\n",
            "Epoch 98, Batch 211/224, Training Loss: 0.4764\n",
            "Epoch 98, Batch 212/224, Training Loss: 0.5231\n",
            "Epoch 98, Batch 213/224, Training Loss: 0.2516\n",
            "Epoch 98, Batch 214/224, Training Loss: 0.3666\n",
            "Epoch 98, Batch 215/224, Training Loss: 0.5441\n",
            "Epoch 98, Batch 216/224, Training Loss: 0.2792\n",
            "Epoch 98, Batch 217/224, Training Loss: 0.3396\n",
            "Epoch 98, Batch 218/224, Training Loss: 0.4373\n",
            "Epoch 98, Batch 219/224, Training Loss: 0.2708\n",
            "Epoch 98, Batch 220/224, Training Loss: 0.5606\n",
            "Epoch 98, Batch 221/224, Training Loss: 0.2692\n",
            "Epoch 98, Batch 222/224, Training Loss: 1.0498\n",
            "Epoch 98, Batch 223/224, Training Loss: 0.2278\n",
            "Epoch 98/100, Training Loss: 0.3995, Test Loss: 3.1536\n",
            "Epoch 99, Batch 0/224, Training Loss: 0.3392\n",
            "Epoch 99, Batch 1/224, Training Loss: 0.3313\n",
            "Epoch 99, Batch 2/224, Training Loss: 0.2823\n",
            "Epoch 99, Batch 3/224, Training Loss: 0.2948\n",
            "Epoch 99, Batch 4/224, Training Loss: 0.3214\n",
            "Epoch 99, Batch 5/224, Training Loss: 0.6623\n",
            "Epoch 99, Batch 6/224, Training Loss: 0.3150\n",
            "Epoch 99, Batch 7/224, Training Loss: 0.3375\n",
            "Epoch 99, Batch 8/224, Training Loss: 0.2153\n",
            "Epoch 99, Batch 9/224, Training Loss: 0.2730\n",
            "Epoch 99, Batch 10/224, Training Loss: 0.4131\n",
            "Epoch 99, Batch 11/224, Training Loss: 0.3496\n",
            "Epoch 99, Batch 12/224, Training Loss: 0.3179\n",
            "Epoch 99, Batch 13/224, Training Loss: 0.6456\n",
            "Epoch 99, Batch 14/224, Training Loss: 0.4780\n",
            "Epoch 99, Batch 15/224, Training Loss: 0.4364\n",
            "Epoch 99, Batch 16/224, Training Loss: 0.2579\n",
            "Epoch 99, Batch 17/224, Training Loss: 0.3854\n",
            "Epoch 99, Batch 18/224, Training Loss: 0.2442\n",
            "Epoch 99, Batch 19/224, Training Loss: 0.3198\n",
            "Epoch 99, Batch 20/224, Training Loss: 0.3747\n",
            "Epoch 99, Batch 21/224, Training Loss: 0.4425\n",
            "Epoch 99, Batch 22/224, Training Loss: 0.3408\n",
            "Epoch 99, Batch 23/224, Training Loss: 0.2774\n",
            "Epoch 99, Batch 24/224, Training Loss: 0.2862\n",
            "Epoch 99, Batch 25/224, Training Loss: 0.4804\n",
            "Epoch 99, Batch 26/224, Training Loss: 0.3648\n",
            "Epoch 99, Batch 27/224, Training Loss: 0.5412\n",
            "Epoch 99, Batch 28/224, Training Loss: 0.2617\n",
            "Epoch 99, Batch 29/224, Training Loss: 0.3358\n",
            "Epoch 99, Batch 30/224, Training Loss: 0.3311\n",
            "Epoch 99, Batch 31/224, Training Loss: 0.3240\n",
            "Epoch 99, Batch 32/224, Training Loss: 0.3669\n",
            "Epoch 99, Batch 33/224, Training Loss: 0.2468\n",
            "Epoch 99, Batch 34/224, Training Loss: 0.9320\n",
            "Epoch 99, Batch 35/224, Training Loss: 0.2858\n",
            "Epoch 99, Batch 36/224, Training Loss: 0.2570\n",
            "Epoch 99, Batch 37/224, Training Loss: 0.3141\n",
            "Epoch 99, Batch 38/224, Training Loss: 0.2188\n",
            "Epoch 99, Batch 39/224, Training Loss: 0.2069\n",
            "Epoch 99, Batch 40/224, Training Loss: 0.3079\n",
            "Epoch 99, Batch 41/224, Training Loss: 0.2828\n",
            "Epoch 99, Batch 42/224, Training Loss: 0.3415\n",
            "Epoch 99, Batch 43/224, Training Loss: 0.2450\n",
            "Epoch 99, Batch 44/224, Training Loss: 0.3448\n",
            "Epoch 99, Batch 45/224, Training Loss: 0.5131\n",
            "Epoch 99, Batch 46/224, Training Loss: 0.5393\n",
            "Epoch 99, Batch 47/224, Training Loss: 0.9558\n",
            "Epoch 99, Batch 48/224, Training Loss: 0.2925\n",
            "Epoch 99, Batch 49/224, Training Loss: 0.3815\n",
            "Epoch 99, Batch 50/224, Training Loss: 0.5112\n",
            "Epoch 99, Batch 51/224, Training Loss: 0.3479\n",
            "Epoch 99, Batch 52/224, Training Loss: 0.3094\n",
            "Epoch 99, Batch 53/224, Training Loss: 0.4490\n",
            "Epoch 99, Batch 54/224, Training Loss: 0.3231\n",
            "Epoch 99, Batch 55/224, Training Loss: 0.2782\n",
            "Epoch 99, Batch 56/224, Training Loss: 0.2440\n",
            "Epoch 99, Batch 57/224, Training Loss: 0.6017\n",
            "Epoch 99, Batch 58/224, Training Loss: 0.5859\n",
            "Epoch 99, Batch 59/224, Training Loss: 0.2333\n",
            "Epoch 99, Batch 60/224, Training Loss: 0.2850\n",
            "Epoch 99, Batch 61/224, Training Loss: 0.2974\n",
            "Epoch 99, Batch 62/224, Training Loss: 0.3670\n",
            "Epoch 99, Batch 63/224, Training Loss: 0.3057\n",
            "Epoch 99, Batch 64/224, Training Loss: 0.2922\n",
            "Epoch 99, Batch 65/224, Training Loss: 0.3194\n",
            "Epoch 99, Batch 66/224, Training Loss: 0.4278\n",
            "Epoch 99, Batch 67/224, Training Loss: 0.2838\n",
            "Epoch 99, Batch 68/224, Training Loss: 0.2525\n",
            "Epoch 99, Batch 69/224, Training Loss: 0.3691\n",
            "Epoch 99, Batch 70/224, Training Loss: 0.3448\n",
            "Epoch 99, Batch 71/224, Training Loss: 0.9537\n",
            "Epoch 99, Batch 72/224, Training Loss: 0.3891\n",
            "Epoch 99, Batch 73/224, Training Loss: 0.2659\n",
            "Epoch 99, Batch 74/224, Training Loss: 0.4192\n",
            "Epoch 99, Batch 75/224, Training Loss: 0.5295\n",
            "Epoch 99, Batch 76/224, Training Loss: 0.3832\n",
            "Epoch 99, Batch 77/224, Training Loss: 0.3486\n",
            "Epoch 99, Batch 78/224, Training Loss: 0.4456\n",
            "Epoch 99, Batch 79/224, Training Loss: 0.3344\n",
            "Epoch 99, Batch 80/224, Training Loss: 0.3356\n",
            "Epoch 99, Batch 81/224, Training Loss: 0.2427\n",
            "Epoch 99, Batch 82/224, Training Loss: 0.3959\n",
            "Epoch 99, Batch 83/224, Training Loss: 0.2986\n",
            "Epoch 99, Batch 84/224, Training Loss: 0.4595\n",
            "Epoch 99, Batch 85/224, Training Loss: 0.2722\n",
            "Epoch 99, Batch 86/224, Training Loss: 0.2986\n",
            "Epoch 99, Batch 87/224, Training Loss: 0.3755\n",
            "Epoch 99, Batch 88/224, Training Loss: 0.4720\n",
            "Epoch 99, Batch 89/224, Training Loss: 0.1486\n",
            "Epoch 99, Batch 90/224, Training Loss: 0.2921\n",
            "Epoch 99, Batch 91/224, Training Loss: 0.2697\n",
            "Epoch 99, Batch 92/224, Training Loss: 0.2793\n",
            "Epoch 99, Batch 93/224, Training Loss: 0.3565\n",
            "Epoch 99, Batch 94/224, Training Loss: 0.2688\n",
            "Epoch 99, Batch 95/224, Training Loss: 0.3860\n",
            "Epoch 99, Batch 96/224, Training Loss: 0.3468\n",
            "Epoch 99, Batch 97/224, Training Loss: 0.3638\n",
            "Epoch 99, Batch 98/224, Training Loss: 0.3538\n",
            "Epoch 99, Batch 99/224, Training Loss: 0.4465\n",
            "Epoch 99, Batch 100/224, Training Loss: 0.8095\n",
            "Epoch 99, Batch 101/224, Training Loss: 0.2771\n",
            "Epoch 99, Batch 102/224, Training Loss: 0.4616\n",
            "Epoch 99, Batch 103/224, Training Loss: 0.3506\n",
            "Epoch 99, Batch 104/224, Training Loss: 0.3576\n",
            "Epoch 99, Batch 105/224, Training Loss: 0.5765\n",
            "Epoch 99, Batch 106/224, Training Loss: 0.6721\n",
            "Epoch 99, Batch 107/224, Training Loss: 0.4042\n",
            "Epoch 99, Batch 108/224, Training Loss: 0.3467\n",
            "Epoch 99, Batch 109/224, Training Loss: 0.6323\n",
            "Epoch 99, Batch 110/224, Training Loss: 0.3226\n",
            "Epoch 99, Batch 111/224, Training Loss: 0.3846\n",
            "Epoch 99, Batch 112/224, Training Loss: 0.2254\n",
            "Epoch 99, Batch 113/224, Training Loss: 0.2734\n",
            "Epoch 99, Batch 114/224, Training Loss: 0.2527\n",
            "Epoch 99, Batch 115/224, Training Loss: 0.8469\n",
            "Epoch 99, Batch 116/224, Training Loss: 0.5466\n",
            "Epoch 99, Batch 117/224, Training Loss: 0.2873\n",
            "Epoch 99, Batch 118/224, Training Loss: 0.3503\n",
            "Epoch 99, Batch 119/224, Training Loss: 0.4984\n",
            "Epoch 99, Batch 120/224, Training Loss: 0.3792\n",
            "Epoch 99, Batch 121/224, Training Loss: 0.4925\n",
            "Epoch 99, Batch 122/224, Training Loss: 0.5058\n",
            "Epoch 99, Batch 123/224, Training Loss: 0.8352\n",
            "Epoch 99, Batch 124/224, Training Loss: 0.3146\n",
            "Epoch 99, Batch 125/224, Training Loss: 0.7892\n",
            "Epoch 99, Batch 126/224, Training Loss: 0.3543\n",
            "Epoch 99, Batch 127/224, Training Loss: 0.2524\n",
            "Epoch 99, Batch 128/224, Training Loss: 0.3864\n",
            "Epoch 99, Batch 129/224, Training Loss: 0.4527\n",
            "Epoch 99, Batch 130/224, Training Loss: 0.3154\n",
            "Epoch 99, Batch 131/224, Training Loss: 0.3191\n",
            "Epoch 99, Batch 132/224, Training Loss: 0.2158\n",
            "Epoch 99, Batch 133/224, Training Loss: 0.3070\n",
            "Epoch 99, Batch 134/224, Training Loss: 0.3884\n",
            "Epoch 99, Batch 135/224, Training Loss: 0.3487\n",
            "Epoch 99, Batch 136/224, Training Loss: 0.3216\n",
            "Epoch 99, Batch 137/224, Training Loss: 0.3149\n",
            "Epoch 99, Batch 138/224, Training Loss: 0.3617\n",
            "Epoch 99, Batch 139/224, Training Loss: 0.3171\n",
            "Epoch 99, Batch 140/224, Training Loss: 0.3712\n",
            "Epoch 99, Batch 141/224, Training Loss: 0.3542\n",
            "Epoch 99, Batch 142/224, Training Loss: 0.2876\n",
            "Epoch 99, Batch 143/224, Training Loss: 0.2514\n",
            "Epoch 99, Batch 144/224, Training Loss: 0.5001\n",
            "Epoch 99, Batch 145/224, Training Loss: 0.3722\n",
            "Epoch 99, Batch 146/224, Training Loss: 0.3733\n",
            "Epoch 99, Batch 147/224, Training Loss: 0.3263\n",
            "Epoch 99, Batch 148/224, Training Loss: 0.2935\n",
            "Epoch 99, Batch 149/224, Training Loss: 0.2634\n",
            "Epoch 99, Batch 150/224, Training Loss: 0.3157\n",
            "Epoch 99, Batch 151/224, Training Loss: 0.2386\n",
            "Epoch 99, Batch 152/224, Training Loss: 0.4134\n",
            "Epoch 99, Batch 153/224, Training Loss: 0.3556\n",
            "Epoch 99, Batch 154/224, Training Loss: 0.3751\n",
            "Epoch 99, Batch 155/224, Training Loss: 0.4807\n",
            "Epoch 99, Batch 156/224, Training Loss: 0.3928\n",
            "Epoch 99, Batch 157/224, Training Loss: 0.5888\n",
            "Epoch 99, Batch 158/224, Training Loss: 0.5556\n",
            "Epoch 99, Batch 159/224, Training Loss: 0.2289\n",
            "Epoch 99, Batch 160/224, Training Loss: 0.3412\n",
            "Epoch 99, Batch 161/224, Training Loss: 0.7336\n",
            "Epoch 99, Batch 162/224, Training Loss: 0.3973\n",
            "Epoch 99, Batch 163/224, Training Loss: 0.2601\n",
            "Epoch 99, Batch 164/224, Training Loss: 0.2523\n",
            "Epoch 99, Batch 165/224, Training Loss: 0.3041\n",
            "Epoch 99, Batch 166/224, Training Loss: 0.2246\n",
            "Epoch 99, Batch 167/224, Training Loss: 0.4351\n",
            "Epoch 99, Batch 168/224, Training Loss: 0.3225\n",
            "Epoch 99, Batch 169/224, Training Loss: 0.4351\n",
            "Epoch 99, Batch 170/224, Training Loss: 0.3446\n",
            "Epoch 99, Batch 171/224, Training Loss: 0.3077\n",
            "Epoch 99, Batch 172/224, Training Loss: 0.3014\n",
            "Epoch 99, Batch 173/224, Training Loss: 0.2784\n",
            "Epoch 99, Batch 174/224, Training Loss: 0.3786\n",
            "Epoch 99, Batch 175/224, Training Loss: 0.2746\n",
            "Epoch 99, Batch 176/224, Training Loss: 0.3883\n",
            "Epoch 99, Batch 177/224, Training Loss: 0.2935\n",
            "Epoch 99, Batch 178/224, Training Loss: 0.3196\n",
            "Epoch 99, Batch 179/224, Training Loss: 0.3236\n",
            "Epoch 99, Batch 180/224, Training Loss: 0.3930\n",
            "Epoch 99, Batch 181/224, Training Loss: 0.3413\n",
            "Epoch 99, Batch 182/224, Training Loss: 0.3430\n",
            "Epoch 99, Batch 183/224, Training Loss: 0.2481\n",
            "Epoch 99, Batch 184/224, Training Loss: 0.6156\n",
            "Epoch 99, Batch 185/224, Training Loss: 0.3939\n",
            "Epoch 99, Batch 186/224, Training Loss: 0.4688\n",
            "Epoch 99, Batch 187/224, Training Loss: 0.3153\n",
            "Epoch 99, Batch 188/224, Training Loss: 0.3261\n",
            "Epoch 99, Batch 189/224, Training Loss: 0.5401\n",
            "Epoch 99, Batch 190/224, Training Loss: 0.3037\n",
            "Epoch 99, Batch 191/224, Training Loss: 0.3725\n",
            "Epoch 99, Batch 192/224, Training Loss: 0.2894\n",
            "Epoch 99, Batch 193/224, Training Loss: 0.3588\n",
            "Epoch 99, Batch 194/224, Training Loss: 0.6498\n",
            "Epoch 99, Batch 195/224, Training Loss: 0.3005\n",
            "Epoch 99, Batch 196/224, Training Loss: 0.4534\n",
            "Epoch 99, Batch 197/224, Training Loss: 0.3399\n",
            "Epoch 99, Batch 198/224, Training Loss: 0.5477\n",
            "Epoch 99, Batch 199/224, Training Loss: 0.4550\n",
            "Epoch 99, Batch 200/224, Training Loss: 0.2863\n",
            "Epoch 99, Batch 201/224, Training Loss: 0.3380\n",
            "Epoch 99, Batch 202/224, Training Loss: 0.1953\n",
            "Epoch 99, Batch 203/224, Training Loss: 0.5519\n",
            "Epoch 99, Batch 204/224, Training Loss: 0.2731\n",
            "Epoch 99, Batch 205/224, Training Loss: 0.2703\n",
            "Epoch 99, Batch 206/224, Training Loss: 0.3220\n",
            "Epoch 99, Batch 207/224, Training Loss: 0.4419\n",
            "Epoch 99, Batch 208/224, Training Loss: 0.4010\n",
            "Epoch 99, Batch 209/224, Training Loss: 0.3782\n",
            "Epoch 99, Batch 210/224, Training Loss: 0.3221\n",
            "Epoch 99, Batch 211/224, Training Loss: 0.3913\n",
            "Epoch 99, Batch 212/224, Training Loss: 0.2571\n",
            "Epoch 99, Batch 213/224, Training Loss: 0.2791\n",
            "Epoch 99, Batch 214/224, Training Loss: 0.4513\n",
            "Epoch 99, Batch 215/224, Training Loss: 0.5016\n",
            "Epoch 99, Batch 216/224, Training Loss: 0.4460\n",
            "Epoch 99, Batch 217/224, Training Loss: 0.3506\n",
            "Epoch 99, Batch 218/224, Training Loss: 0.3026\n",
            "Epoch 99, Batch 219/224, Training Loss: 0.2523\n",
            "Epoch 99, Batch 220/224, Training Loss: 0.3259\n",
            "Epoch 99, Batch 221/224, Training Loss: 0.3203\n",
            "Epoch 99, Batch 222/224, Training Loss: 0.5943\n",
            "Epoch 99, Batch 223/224, Training Loss: 0.3138\n",
            "Epoch 99/100, Training Loss: 0.3772, Test Loss: 3.0604\n",
            "Epoch 100, Batch 0/224, Training Loss: 0.2092\n",
            "Epoch 100, Batch 1/224, Training Loss: 0.3084\n",
            "Epoch 100, Batch 2/224, Training Loss: 0.4461\n",
            "Epoch 100, Batch 3/224, Training Loss: 0.2199\n",
            "Epoch 100, Batch 4/224, Training Loss: 0.3223\n",
            "Epoch 100, Batch 5/224, Training Loss: 0.2356\n",
            "Epoch 100, Batch 6/224, Training Loss: 0.3517\n",
            "Epoch 100, Batch 7/224, Training Loss: 0.2562\n",
            "Epoch 100, Batch 8/224, Training Loss: 0.3151\n",
            "Epoch 100, Batch 9/224, Training Loss: 0.3824\n",
            "Epoch 100, Batch 10/224, Training Loss: 0.7431\n",
            "Epoch 100, Batch 11/224, Training Loss: 0.2641\n",
            "Epoch 100, Batch 12/224, Training Loss: 0.2524\n",
            "Epoch 100, Batch 13/224, Training Loss: 0.3316\n",
            "Epoch 100, Batch 14/224, Training Loss: 0.4224\n",
            "Epoch 100, Batch 15/224, Training Loss: 0.2218\n",
            "Epoch 100, Batch 16/224, Training Loss: 0.6298\n",
            "Epoch 100, Batch 17/224, Training Loss: 0.4397\n",
            "Epoch 100, Batch 18/224, Training Loss: 0.2712\n",
            "Epoch 100, Batch 19/224, Training Loss: 0.7284\n",
            "Epoch 100, Batch 20/224, Training Loss: 0.6250\n",
            "Epoch 100, Batch 21/224, Training Loss: 0.3084\n",
            "Epoch 100, Batch 22/224, Training Loss: 0.2801\n",
            "Epoch 100, Batch 23/224, Training Loss: 0.1962\n",
            "Epoch 100, Batch 24/224, Training Loss: 0.2510\n",
            "Epoch 100, Batch 25/224, Training Loss: 0.5115\n",
            "Epoch 100, Batch 26/224, Training Loss: 0.6466\n",
            "Epoch 100, Batch 27/224, Training Loss: 0.3136\n",
            "Epoch 100, Batch 28/224, Training Loss: 0.3588\n",
            "Epoch 100, Batch 29/224, Training Loss: 0.4174\n",
            "Epoch 100, Batch 30/224, Training Loss: 0.2477\n",
            "Epoch 100, Batch 31/224, Training Loss: 0.2658\n",
            "Epoch 100, Batch 32/224, Training Loss: 0.2393\n",
            "Epoch 100, Batch 33/224, Training Loss: 0.2670\n",
            "Epoch 100, Batch 34/224, Training Loss: 0.2144\n",
            "Epoch 100, Batch 35/224, Training Loss: 0.3311\n",
            "Epoch 100, Batch 36/224, Training Loss: 0.6841\n",
            "Epoch 100, Batch 37/224, Training Loss: 0.2773\n",
            "Epoch 100, Batch 38/224, Training Loss: 0.3153\n",
            "Epoch 100, Batch 39/224, Training Loss: 0.2733\n",
            "Epoch 100, Batch 40/224, Training Loss: 0.3365\n",
            "Epoch 100, Batch 41/224, Training Loss: 0.2809\n",
            "Epoch 100, Batch 42/224, Training Loss: 0.2508\n",
            "Epoch 100, Batch 43/224, Training Loss: 0.2279\n",
            "Epoch 100, Batch 44/224, Training Loss: 0.3692\n",
            "Epoch 100, Batch 45/224, Training Loss: 0.3437\n",
            "Epoch 100, Batch 46/224, Training Loss: 0.4523\n",
            "Epoch 100, Batch 47/224, Training Loss: 0.3350\n",
            "Epoch 100, Batch 48/224, Training Loss: 0.3564\n",
            "Epoch 100, Batch 49/224, Training Loss: 0.5709\n",
            "Epoch 100, Batch 50/224, Training Loss: 0.3536\n",
            "Epoch 100, Batch 51/224, Training Loss: 0.3239\n",
            "Epoch 100, Batch 52/224, Training Loss: 0.2521\n",
            "Epoch 100, Batch 53/224, Training Loss: 0.4285\n",
            "Epoch 100, Batch 54/224, Training Loss: 0.2776\n",
            "Epoch 100, Batch 55/224, Training Loss: 0.3083\n",
            "Epoch 100, Batch 56/224, Training Loss: 0.3121\n",
            "Epoch 100, Batch 57/224, Training Loss: 0.8638\n",
            "Epoch 100, Batch 58/224, Training Loss: 0.5382\n",
            "Epoch 100, Batch 59/224, Training Loss: 0.3480\n",
            "Epoch 100, Batch 60/224, Training Loss: 0.3427\n",
            "Epoch 100, Batch 61/224, Training Loss: 0.2399\n",
            "Epoch 100, Batch 62/224, Training Loss: 0.5481\n",
            "Epoch 100, Batch 63/224, Training Loss: 0.2607\n",
            "Epoch 100, Batch 64/224, Training Loss: 0.2519\n",
            "Epoch 100, Batch 65/224, Training Loss: 0.2121\n",
            "Epoch 100, Batch 66/224, Training Loss: 0.3721\n",
            "Epoch 100, Batch 67/224, Training Loss: 0.4315\n",
            "Epoch 100, Batch 68/224, Training Loss: 0.2393\n",
            "Epoch 100, Batch 69/224, Training Loss: 0.5224\n",
            "Epoch 100, Batch 70/224, Training Loss: 0.3816\n",
            "Epoch 100, Batch 71/224, Training Loss: 0.2693\n",
            "Epoch 100, Batch 72/224, Training Loss: 0.2317\n",
            "Epoch 100, Batch 73/224, Training Loss: 0.2879\n",
            "Epoch 100, Batch 74/224, Training Loss: 0.2233\n",
            "Epoch 100, Batch 75/224, Training Loss: 0.2884\n",
            "Epoch 100, Batch 76/224, Training Loss: 0.2422\n",
            "Epoch 100, Batch 77/224, Training Loss: 0.3423\n",
            "Epoch 100, Batch 78/224, Training Loss: 0.3979\n",
            "Epoch 100, Batch 79/224, Training Loss: 0.4226\n",
            "Epoch 100, Batch 80/224, Training Loss: 0.2686\n",
            "Epoch 100, Batch 81/224, Training Loss: 0.3325\n",
            "Epoch 100, Batch 82/224, Training Loss: 0.3688\n",
            "Epoch 100, Batch 83/224, Training Loss: 0.2142\n",
            "Epoch 100, Batch 84/224, Training Loss: 0.4034\n",
            "Epoch 100, Batch 85/224, Training Loss: 0.3316\n",
            "Epoch 100, Batch 86/224, Training Loss: 0.2754\n",
            "Epoch 100, Batch 87/224, Training Loss: 0.5380\n",
            "Epoch 100, Batch 88/224, Training Loss: 0.3494\n",
            "Epoch 100, Batch 89/224, Training Loss: 0.2924\n",
            "Epoch 100, Batch 90/224, Training Loss: 0.3612\n",
            "Epoch 100, Batch 91/224, Training Loss: 0.2258\n",
            "Epoch 100, Batch 92/224, Training Loss: 0.6500\n",
            "Epoch 100, Batch 93/224, Training Loss: 0.4631\n",
            "Epoch 100, Batch 94/224, Training Loss: 0.2819\n",
            "Epoch 100, Batch 95/224, Training Loss: 0.3721\n",
            "Epoch 100, Batch 96/224, Training Loss: 0.4778\n",
            "Epoch 100, Batch 97/224, Training Loss: 0.4335\n",
            "Epoch 100, Batch 98/224, Training Loss: 0.3347\n",
            "Epoch 100, Batch 99/224, Training Loss: 0.3658\n",
            "Epoch 100, Batch 100/224, Training Loss: 0.5966\n",
            "Epoch 100, Batch 101/224, Training Loss: 0.2932\n",
            "Epoch 100, Batch 102/224, Training Loss: 0.4873\n",
            "Epoch 100, Batch 103/224, Training Loss: 0.3054\n",
            "Epoch 100, Batch 104/224, Training Loss: 0.1729\n",
            "Epoch 100, Batch 105/224, Training Loss: 0.3190\n",
            "Epoch 100, Batch 106/224, Training Loss: 0.4079\n",
            "Epoch 100, Batch 107/224, Training Loss: 0.2439\n",
            "Epoch 100, Batch 108/224, Training Loss: 0.2772\n",
            "Epoch 100, Batch 109/224, Training Loss: 0.4821\n",
            "Epoch 100, Batch 110/224, Training Loss: 0.3043\n",
            "Epoch 100, Batch 111/224, Training Loss: 0.4331\n",
            "Epoch 100, Batch 112/224, Training Loss: 0.2087\n",
            "Epoch 100, Batch 113/224, Training Loss: 0.2619\n",
            "Epoch 100, Batch 114/224, Training Loss: 0.4310\n",
            "Epoch 100, Batch 115/224, Training Loss: 0.2615\n",
            "Epoch 100, Batch 116/224, Training Loss: 0.2900\n",
            "Epoch 100, Batch 117/224, Training Loss: 0.4628\n",
            "Epoch 100, Batch 118/224, Training Loss: 0.2447\n",
            "Epoch 100, Batch 119/224, Training Loss: 0.3815\n",
            "Epoch 100, Batch 120/224, Training Loss: 0.2684\n",
            "Epoch 100, Batch 121/224, Training Loss: 0.3847\n",
            "Epoch 100, Batch 122/224, Training Loss: 0.4358\n",
            "Epoch 100, Batch 123/224, Training Loss: 0.3363\n",
            "Epoch 100, Batch 124/224, Training Loss: 0.3580\n",
            "Epoch 100, Batch 125/224, Training Loss: 0.2543\n",
            "Epoch 100, Batch 126/224, Training Loss: 0.2640\n",
            "Epoch 100, Batch 127/224, Training Loss: 0.3728\n",
            "Epoch 100, Batch 128/224, Training Loss: 0.3294\n",
            "Epoch 100, Batch 129/224, Training Loss: 0.2563\n",
            "Epoch 100, Batch 130/224, Training Loss: 0.3944\n",
            "Epoch 100, Batch 131/224, Training Loss: 0.3852\n",
            "Epoch 100, Batch 132/224, Training Loss: 0.2780\n",
            "Epoch 100, Batch 133/224, Training Loss: 0.4264\n",
            "Epoch 100, Batch 134/224, Training Loss: 0.4051\n",
            "Epoch 100, Batch 135/224, Training Loss: 0.3181\n",
            "Epoch 100, Batch 136/224, Training Loss: 0.2693\n",
            "Epoch 100, Batch 137/224, Training Loss: 0.3245\n",
            "Epoch 100, Batch 138/224, Training Loss: 0.3767\n",
            "Epoch 100, Batch 139/224, Training Loss: 0.4825\n",
            "Epoch 100, Batch 140/224, Training Loss: 0.3192\n",
            "Epoch 100, Batch 141/224, Training Loss: 0.1999\n",
            "Epoch 100, Batch 142/224, Training Loss: 0.5386\n",
            "Epoch 100, Batch 143/224, Training Loss: 0.3252\n",
            "Epoch 100, Batch 144/224, Training Loss: 0.3570\n",
            "Epoch 100, Batch 145/224, Training Loss: 0.2487\n",
            "Epoch 100, Batch 146/224, Training Loss: 0.3139\n",
            "Epoch 100, Batch 147/224, Training Loss: 0.3032\n",
            "Epoch 100, Batch 148/224, Training Loss: 0.2288\n",
            "Epoch 100, Batch 149/224, Training Loss: 0.5795\n",
            "Epoch 100, Batch 150/224, Training Loss: 0.2953\n",
            "Epoch 100, Batch 151/224, Training Loss: 0.4170\n",
            "Epoch 100, Batch 152/224, Training Loss: 0.2355\n",
            "Epoch 100, Batch 153/224, Training Loss: 0.2635\n",
            "Epoch 100, Batch 154/224, Training Loss: 0.3291\n",
            "Epoch 100, Batch 155/224, Training Loss: 0.4144\n",
            "Epoch 100, Batch 156/224, Training Loss: 0.5990\n",
            "Epoch 100, Batch 157/224, Training Loss: 0.2968\n",
            "Epoch 100, Batch 158/224, Training Loss: 0.3689\n",
            "Epoch 100, Batch 159/224, Training Loss: 0.3952\n",
            "Epoch 100, Batch 160/224, Training Loss: 0.2234\n",
            "Epoch 100, Batch 161/224, Training Loss: 0.2922\n",
            "Epoch 100, Batch 162/224, Training Loss: 0.2729\n",
            "Epoch 100, Batch 163/224, Training Loss: 0.4867\n",
            "Epoch 100, Batch 164/224, Training Loss: 0.5170\n",
            "Epoch 100, Batch 165/224, Training Loss: 0.4291\n",
            "Epoch 100, Batch 166/224, Training Loss: 0.2074\n",
            "Epoch 100, Batch 167/224, Training Loss: 0.2433\n",
            "Epoch 100, Batch 168/224, Training Loss: 0.2928\n",
            "Epoch 100, Batch 169/224, Training Loss: 0.3163\n",
            "Epoch 100, Batch 170/224, Training Loss: 0.3352\n",
            "Epoch 100, Batch 171/224, Training Loss: 0.3086\n",
            "Epoch 100, Batch 172/224, Training Loss: 0.4714\n",
            "Epoch 100, Batch 173/224, Training Loss: 0.3233\n",
            "Epoch 100, Batch 174/224, Training Loss: 0.4329\n",
            "Epoch 100, Batch 175/224, Training Loss: 0.8163\n",
            "Epoch 100, Batch 176/224, Training Loss: 0.3658\n",
            "Epoch 100, Batch 177/224, Training Loss: 0.4329\n",
            "Epoch 100, Batch 178/224, Training Loss: 0.4070\n",
            "Epoch 100, Batch 179/224, Training Loss: 0.2531\n",
            "Epoch 100, Batch 180/224, Training Loss: 0.3992\n",
            "Epoch 100, Batch 181/224, Training Loss: 0.4088\n",
            "Epoch 100, Batch 182/224, Training Loss: 0.4480\n",
            "Epoch 100, Batch 183/224, Training Loss: 0.5934\n",
            "Epoch 100, Batch 184/224, Training Loss: 0.3595\n",
            "Epoch 100, Batch 185/224, Training Loss: 0.3238\n",
            "Epoch 100, Batch 186/224, Training Loss: 0.2844\n",
            "Epoch 100, Batch 187/224, Training Loss: 0.3159\n",
            "Epoch 100, Batch 188/224, Training Loss: 0.2445\n",
            "Epoch 100, Batch 189/224, Training Loss: 0.5288\n",
            "Epoch 100, Batch 190/224, Training Loss: 0.3107\n",
            "Epoch 100, Batch 191/224, Training Loss: 0.4171\n",
            "Epoch 100, Batch 192/224, Training Loss: 0.4691\n",
            "Epoch 100, Batch 193/224, Training Loss: 0.3463\n",
            "Epoch 100, Batch 194/224, Training Loss: 0.3947\n",
            "Epoch 100, Batch 195/224, Training Loss: 0.7706\n",
            "Epoch 100, Batch 196/224, Training Loss: 0.3485\n",
            "Epoch 100, Batch 197/224, Training Loss: 0.3042\n",
            "Epoch 100, Batch 198/224, Training Loss: 0.3053\n",
            "Epoch 100, Batch 199/224, Training Loss: 0.4910\n",
            "Epoch 100, Batch 200/224, Training Loss: 0.7428\n",
            "Epoch 100, Batch 201/224, Training Loss: 0.3349\n",
            "Epoch 100, Batch 202/224, Training Loss: 0.3248\n",
            "Epoch 100, Batch 203/224, Training Loss: 0.6974\n",
            "Epoch 100, Batch 204/224, Training Loss: 0.4209\n",
            "Epoch 100, Batch 205/224, Training Loss: 0.2762\n",
            "Epoch 100, Batch 206/224, Training Loss: 0.3766\n",
            "Epoch 100, Batch 207/224, Training Loss: 0.3435\n",
            "Epoch 100, Batch 208/224, Training Loss: 0.6671\n",
            "Epoch 100, Batch 209/224, Training Loss: 0.6000\n",
            "Epoch 100, Batch 210/224, Training Loss: 0.3579\n",
            "Epoch 100, Batch 211/224, Training Loss: 0.2029\n",
            "Epoch 100, Batch 212/224, Training Loss: 0.2715\n",
            "Epoch 100, Batch 213/224, Training Loss: 0.2517\n",
            "Epoch 100, Batch 214/224, Training Loss: 0.8133\n",
            "Epoch 100, Batch 215/224, Training Loss: 0.3760\n",
            "Epoch 100, Batch 216/224, Training Loss: 0.2667\n",
            "Epoch 100, Batch 217/224, Training Loss: 0.4131\n",
            "Epoch 100, Batch 218/224, Training Loss: 0.3158\n",
            "Epoch 100, Batch 219/224, Training Loss: 0.4286\n",
            "Epoch 100, Batch 220/224, Training Loss: 0.3057\n",
            "Epoch 100, Batch 221/224, Training Loss: 0.3323\n",
            "Epoch 100, Batch 222/224, Training Loss: 0.3615\n",
            "Epoch 100, Batch 223/224, Training Loss: 0.4442\n",
            "Epoch 100/100, Training Loss: 0.3660, Test Loss: 3.1035\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_losses)"
      ],
      "metadata": {
        "id": "vViN1Jj0ITb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad945317-82ed-4281-c3c0-8860f0e79a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.131572736161096, 2.76469515476908, 2.5756656655243466, 2.4356348301683153, 2.704208961554936, 2.331142951335226, 2.4532586123262132, 2.417185998388699, 2.366822593978473, 2.316369118435042, 2.356951272913388, 2.4379546642303467, 2.4911506537880217, 2.4984587792839323, 2.479176795908383, 2.487879829747336, 2.6668931926999773, 2.7169976936919347, 2.5888824526752745, 2.753108929310526, 2.663636786597116, 2.689198212964194, 2.7378784098795483, 2.857735174042838, 2.9760231993028095, 2.9137066773005893, 2.8085944780281613, 2.9467536679336, 2.838561522109168, 2.9741115335907256, 2.8944475650787354, 3.0023009862218584, 3.0038290343114307, 2.9259183747427806, 2.921163043805531, 3.118866481951305, 3.021870957953589, 2.948903339249747, 2.955783132995878, 3.0299329331942966, 2.9690197152750835, 3.0532357564994266, 3.0621107050350735, 3.001053028873035, 2.8748733741896495, 3.0782326630183627, 3.0475130400487354, 2.9486863293818066, 3.0738810982022966, 3.0654483437538147, 3.1854495917047774, 3.0227467715740204, 3.015635547893388, 3.1249376918588365, 3.022171235510281, 3.092700402651514, 3.145389205643109, 2.9747489541769028, 3.1399355104991367, 3.103247561625072, 3.1054677069187164, 3.2216164086546217, 3.076998625482832, 3.1249619743653705, 3.149990690605981, 3.151658351932253, 3.1481670141220093, 3.144508195774896, 3.1065643770354137, 3.079299705369132, 3.1826436051300595, 3.1663244707243785, 3.0117142626217435, 3.1651274476732527, 3.1439964388098036, 3.26177641749382, 3.1010042812143053, 3.082267463207245, 3.064693491373743, 3.0985376302685057, 3.019418920789446, 3.123949774674007, 3.075151577591896, 3.067343154123851, 3.1559547079460963, 3.2318399931703294, 3.18198470558439, 3.196153061730521, 3.208369029419763, 3.0900276388440813, 3.128531575202942, 3.0525876539094106, 3.1643285006284714, 3.1354520874364034, 3.0292408296040128, 3.0272710557494844, 2.985134497284889, 3.153618478349277, 3.0604320211069926, 3.1035476603678296]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Test Data\n",
        "model.eval()\n",
        "test_predictions_list = []\n",
        "test_targets_list = []\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_Y in test_loader:\n",
        "        # Move to the appropriate device\n",
        "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "        # Clamp indices in batch_X to ensure they are within the valid range\n",
        "        batch_X = torch.clamp(batch_X, 0, vocab_size - 1)\n",
        "\n",
        "        # Forward pass\n",
        "        test_predictions = model(batch_X)\n",
        "\n",
        "        # Store predictions and true values\n",
        "        test_predictions_list.extend(test_predictions.squeeze(-1).cpu().numpy())\n",
        "        test_targets_list.extend(batch_Y.cpu().numpy())\n",
        "\n",
        "# Convert predictions and targets directly to NumPy arrays\n",
        "test_predictions_array = np.array(test_predictions_list)\n",
        "test_targets_array = np.array(test_targets_list)\n",
        "\n",
        "# Classify as 0 or 1 based on prediction >= 6.25\n",
        "binary_targets = []\n",
        "binary_results = []\n",
        "for prediction in test_predictions_array:\n",
        "    if prediction >= 6.25:\n",
        "        binary_results.append(1)\n",
        "    else:\n",
        "        binary_results.append(0)\n",
        "\n",
        "for target in test_targets_array:\n",
        "    if target >= 6.25:\n",
        "        binary_targets.append(1)\n",
        "    else:\n",
        "        binary_targets.append(0)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(binary_targets, binary_results))\n",
        "\n",
        "# Flatten arrays to ensure 1D shape\n",
        "test_predictions_array = test_predictions_array.flatten()\n",
        "test_targets_array = test_targets_array.flatten()\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for Regression\n",
        "print(f\"Test MSE: {mean_squared_error(test_targets_array, test_predictions_array)}\")\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "print(f\"Test MAE: {mean_absolute_error(test_targets_array, test_predictions_array)}\")\n",
        "\n",
        "# Calculate R² Score (coefficient of determination)\n",
        "print(f\"Test R² Score: {r2_score(test_targets_array, test_predictions_array)}\")\n",
        "\n",
        "\n",
        "print(test_targets_array.shape)\n",
        "print(test_predictions_array.shape)\n",
        "\n",
        "# Plot predictions vs ground truth for test set\n",
        "plt.plot(range(50), test_targets_array[:50], label=\"Ground Truth\", alpha=0.7)\n",
        "plt.plot(range(50), test_predictions_array[:50], label=\"Predictions\", alpha=0.7)\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.ylabel(\"Positivity Score\")\n",
        "plt.title(\"Test Predictions vs Ground Truth\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AYw_FXCHGF9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "outputId": "f4cd39d3-f0a1-414c-b35c-b4ce2e1aa6d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7917857142857143\n",
            "Test MSE: 3.1035478115081787\n",
            "Test MAE: 1.324675440788269\n",
            "Test R² Score: 0.4498298764228821\n",
            "(5600,)\n",
            "(5600,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPTIMIZED Bidirectional LSTM - Early Stopping"
      ],
      "metadata": {
        "id": "q6voLPkP9quv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define LSTM Model\n",
        "class OptimizedBiLSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(OptimizedBiLSTMModel, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=0.3)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x.long())\n",
        "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
        "        last_hidden = lstm_out[:, -1, :]\n",
        "        dropped_out = self.dropout(last_hidden)\n",
        "        output = self.fc(dropped_out)\n",
        "        return output\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hidden_dim = 128\n",
        "output_dim = 1\n",
        "num_layers = 3\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "embedding_dim = 100\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "vocab_size = len(vocab) + 1  # Use your vocabulary size\n",
        "model = OptimizedBiLSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "\n",
        "# Initialize lists to store training and testing losses\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "# Training Loop\n",
        "for t in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    batch_num = 0\n",
        "\n",
        "    # Training phase\n",
        "    for batch_X, batch_Y in train_loader:\n",
        "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        predictions = model(batch_X)\n",
        "        loss = criterion(predictions, batch_Y.float())\n",
        "        print(f\"Epoch {t+1}, Batch {batch_num}/{len(train_loader)}, Training Loss: {loss:.4f}\")\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_train_loss += loss.item()\n",
        "        batch_num += 1\n",
        "\n",
        "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)  # Store training loss\n",
        "\n",
        "    # Evaluation phase on the test set\n",
        "    model.eval()\n",
        "    epoch_test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_Y in test_loader:\n",
        "            batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "            # Ensure indices are valid for the embedding layer\n",
        "            batch_X = torch.clamp(batch_X, 0, vocab_size - 1)\n",
        "\n",
        "            # Ensure shapes match for loss calculation\n",
        "            batch_Y = batch_Y.view(-1, 1)  # Reshape to [batch_size, 1]\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model(batch_X)\n",
        "            loss = criterion(predictions, batch_Y.float())\n",
        "            epoch_test_loss += loss.item()\n",
        "\n",
        "    avg_test_loss = epoch_test_loss / len(test_loader)\n",
        "    test_losses.append(avg_test_loss)\n",
        "\n",
        "    # Print epoch progress\n",
        "    print(f\"Epoch {t+1}/{num_epochs}, Training Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "# Plot Training and Test Loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss', marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss', marker='s')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "db26537e-e3b0-4ba2-c506-0345212f9213",
        "id": "Ggq9IaCu9quw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0/224, Training Loss: 37.3850\n",
            "Epoch 1, Batch 1/224, Training Loss: 33.9407\n",
            "Epoch 1, Batch 2/224, Training Loss: 36.0776\n",
            "Epoch 1, Batch 3/224, Training Loss: 34.7021\n",
            "Epoch 1, Batch 4/224, Training Loss: 31.8019\n",
            "Epoch 1, Batch 5/224, Training Loss: 30.5979\n",
            "Epoch 1, Batch 6/224, Training Loss: 31.3441\n",
            "Epoch 1, Batch 7/224, Training Loss: 28.1005\n",
            "Epoch 1, Batch 8/224, Training Loss: 20.8916\n",
            "Epoch 1, Batch 9/224, Training Loss: 16.3903\n",
            "Epoch 1, Batch 10/224, Training Loss: 16.7016\n",
            "Epoch 1, Batch 11/224, Training Loss: 10.4258\n",
            "Epoch 1, Batch 12/224, Training Loss: 7.9010\n",
            "Epoch 1, Batch 13/224, Training Loss: 6.4749\n",
            "Epoch 1, Batch 14/224, Training Loss: 6.5724\n",
            "Epoch 1, Batch 15/224, Training Loss: 5.1949\n",
            "Epoch 1, Batch 16/224, Training Loss: 6.1513\n",
            "Epoch 1, Batch 17/224, Training Loss: 6.1317\n",
            "Epoch 1, Batch 18/224, Training Loss: 5.9137\n",
            "Epoch 1, Batch 19/224, Training Loss: 6.6338\n",
            "Epoch 1, Batch 20/224, Training Loss: 4.9809\n",
            "Epoch 1, Batch 21/224, Training Loss: 6.2237\n",
            "Epoch 1, Batch 22/224, Training Loss: 6.0285\n",
            "Epoch 1, Batch 23/224, Training Loss: 5.2545\n",
            "Epoch 1, Batch 24/224, Training Loss: 5.0024\n",
            "Epoch 1, Batch 25/224, Training Loss: 4.2219\n",
            "Epoch 1, Batch 26/224, Training Loss: 5.4715\n",
            "Epoch 1, Batch 27/224, Training Loss: 5.8644\n",
            "Epoch 1, Batch 28/224, Training Loss: 6.3777\n",
            "Epoch 1, Batch 29/224, Training Loss: 4.8455\n",
            "Epoch 1, Batch 30/224, Training Loss: 5.8370\n",
            "Epoch 1, Batch 31/224, Training Loss: 6.4366\n",
            "Epoch 1, Batch 32/224, Training Loss: 5.4711\n",
            "Epoch 1, Batch 33/224, Training Loss: 5.4192\n",
            "Epoch 1, Batch 34/224, Training Loss: 6.0030\n",
            "Epoch 1, Batch 35/224, Training Loss: 5.9430\n",
            "Epoch 1, Batch 36/224, Training Loss: 5.4079\n",
            "Epoch 1, Batch 37/224, Training Loss: 6.3968\n",
            "Epoch 1, Batch 38/224, Training Loss: 6.4912\n",
            "Epoch 1, Batch 39/224, Training Loss: 6.6073\n",
            "Epoch 1, Batch 40/224, Training Loss: 5.5113\n",
            "Epoch 1, Batch 41/224, Training Loss: 5.0978\n",
            "Epoch 1, Batch 42/224, Training Loss: 5.5872\n",
            "Epoch 1, Batch 43/224, Training Loss: 5.6715\n",
            "Epoch 1, Batch 44/224, Training Loss: 5.8089\n",
            "Epoch 1, Batch 45/224, Training Loss: 5.1565\n",
            "Epoch 1, Batch 46/224, Training Loss: 6.2314\n",
            "Epoch 1, Batch 47/224, Training Loss: 5.0029\n",
            "Epoch 1, Batch 48/224, Training Loss: 4.5956\n",
            "Epoch 1, Batch 49/224, Training Loss: 5.3996\n",
            "Epoch 1, Batch 50/224, Training Loss: 5.3056\n",
            "Epoch 1, Batch 51/224, Training Loss: 6.5992\n",
            "Epoch 1, Batch 52/224, Training Loss: 5.3540\n",
            "Epoch 1, Batch 53/224, Training Loss: 5.5771\n",
            "Epoch 1, Batch 54/224, Training Loss: 4.4938\n",
            "Epoch 1, Batch 55/224, Training Loss: 5.5091\n",
            "Epoch 1, Batch 56/224, Training Loss: 4.9566\n",
            "Epoch 1, Batch 57/224, Training Loss: 5.3675\n",
            "Epoch 1, Batch 58/224, Training Loss: 4.6373\n",
            "Epoch 1, Batch 59/224, Training Loss: 5.4376\n",
            "Epoch 1, Batch 60/224, Training Loss: 4.5965\n",
            "Epoch 1, Batch 61/224, Training Loss: 4.6356\n",
            "Epoch 1, Batch 62/224, Training Loss: 5.8704\n",
            "Epoch 1, Batch 63/224, Training Loss: 4.2336\n",
            "Epoch 1, Batch 64/224, Training Loss: 5.5136\n",
            "Epoch 1, Batch 65/224, Training Loss: 5.8212\n",
            "Epoch 1, Batch 66/224, Training Loss: 5.1021\n",
            "Epoch 1, Batch 67/224, Training Loss: 5.0955\n",
            "Epoch 1, Batch 68/224, Training Loss: 5.1292\n",
            "Epoch 1, Batch 69/224, Training Loss: 5.1887\n",
            "Epoch 1, Batch 70/224, Training Loss: 4.6620\n",
            "Epoch 1, Batch 71/224, Training Loss: 4.9293\n",
            "Epoch 1, Batch 72/224, Training Loss: 5.1883\n",
            "Epoch 1, Batch 73/224, Training Loss: 4.2838\n",
            "Epoch 1, Batch 74/224, Training Loss: 3.7006\n",
            "Epoch 1, Batch 75/224, Training Loss: 5.1394\n",
            "Epoch 1, Batch 76/224, Training Loss: 4.3059\n",
            "Epoch 1, Batch 77/224, Training Loss: 5.2830\n",
            "Epoch 1, Batch 78/224, Training Loss: 4.0411\n",
            "Epoch 1, Batch 79/224, Training Loss: 4.8179\n",
            "Epoch 1, Batch 80/224, Training Loss: 5.2566\n",
            "Epoch 1, Batch 81/224, Training Loss: 4.8284\n",
            "Epoch 1, Batch 82/224, Training Loss: 3.7657\n",
            "Epoch 1, Batch 83/224, Training Loss: 4.1902\n",
            "Epoch 1, Batch 84/224, Training Loss: 4.2825\n",
            "Epoch 1, Batch 85/224, Training Loss: 3.5981\n",
            "Epoch 1, Batch 86/224, Training Loss: 5.4943\n",
            "Epoch 1, Batch 87/224, Training Loss: 4.4104\n",
            "Epoch 1, Batch 88/224, Training Loss: 4.7072\n",
            "Epoch 1, Batch 89/224, Training Loss: 4.4118\n",
            "Epoch 1, Batch 90/224, Training Loss: 4.1437\n",
            "Epoch 1, Batch 91/224, Training Loss: 3.8313\n",
            "Epoch 1, Batch 92/224, Training Loss: 5.1281\n",
            "Epoch 1, Batch 93/224, Training Loss: 5.0578\n",
            "Epoch 1, Batch 94/224, Training Loss: 4.1446\n",
            "Epoch 1, Batch 95/224, Training Loss: 4.5098\n",
            "Epoch 1, Batch 96/224, Training Loss: 4.6089\n",
            "Epoch 1, Batch 97/224, Training Loss: 2.7355\n",
            "Epoch 1, Batch 98/224, Training Loss: 4.7132\n",
            "Epoch 1, Batch 99/224, Training Loss: 3.8059\n",
            "Epoch 1, Batch 100/224, Training Loss: 3.8309\n",
            "Epoch 1, Batch 101/224, Training Loss: 4.1949\n",
            "Epoch 1, Batch 102/224, Training Loss: 3.1019\n",
            "Epoch 1, Batch 103/224, Training Loss: 3.3882\n",
            "Epoch 1, Batch 104/224, Training Loss: 3.8345\n",
            "Epoch 1, Batch 105/224, Training Loss: 4.2169\n",
            "Epoch 1, Batch 106/224, Training Loss: 6.3492\n",
            "Epoch 1, Batch 107/224, Training Loss: 6.5059\n",
            "Epoch 1, Batch 108/224, Training Loss: 5.5669\n",
            "Epoch 1, Batch 109/224, Training Loss: 5.1347\n",
            "Epoch 1, Batch 110/224, Training Loss: 3.2758\n",
            "Epoch 1, Batch 111/224, Training Loss: 3.8707\n",
            "Epoch 1, Batch 112/224, Training Loss: 5.3075\n",
            "Epoch 1, Batch 113/224, Training Loss: 4.7658\n",
            "Epoch 1, Batch 114/224, Training Loss: 4.5524\n",
            "Epoch 1, Batch 115/224, Training Loss: 4.2163\n",
            "Epoch 1, Batch 116/224, Training Loss: 4.8474\n",
            "Epoch 1, Batch 117/224, Training Loss: 4.4000\n",
            "Epoch 1, Batch 118/224, Training Loss: 3.6744\n",
            "Epoch 1, Batch 119/224, Training Loss: 3.7051\n",
            "Epoch 1, Batch 120/224, Training Loss: 5.1092\n",
            "Epoch 1, Batch 121/224, Training Loss: 4.3424\n",
            "Epoch 1, Batch 122/224, Training Loss: 4.3810\n",
            "Epoch 1, Batch 123/224, Training Loss: 3.7231\n",
            "Epoch 1, Batch 124/224, Training Loss: 3.3220\n",
            "Epoch 1, Batch 125/224, Training Loss: 4.1581\n",
            "Epoch 1, Batch 126/224, Training Loss: 4.5058\n",
            "Epoch 1, Batch 127/224, Training Loss: 3.8160\n",
            "Epoch 1, Batch 128/224, Training Loss: 3.1518\n",
            "Epoch 1, Batch 129/224, Training Loss: 4.5241\n",
            "Epoch 1, Batch 130/224, Training Loss: 4.1508\n",
            "Epoch 1, Batch 131/224, Training Loss: 3.1999\n",
            "Epoch 1, Batch 132/224, Training Loss: 4.6545\n",
            "Epoch 1, Batch 133/224, Training Loss: 6.7526\n",
            "Epoch 1, Batch 134/224, Training Loss: 5.9267\n",
            "Epoch 1, Batch 135/224, Training Loss: 4.0078\n",
            "Epoch 1, Batch 136/224, Training Loss: 3.9296\n",
            "Epoch 1, Batch 137/224, Training Loss: 4.7973\n",
            "Epoch 1, Batch 138/224, Training Loss: 5.0013\n",
            "Epoch 1, Batch 139/224, Training Loss: 4.8974\n",
            "Epoch 1, Batch 140/224, Training Loss: 4.1069\n",
            "Epoch 1, Batch 141/224, Training Loss: 4.6096\n",
            "Epoch 1, Batch 142/224, Training Loss: 4.5397\n",
            "Epoch 1, Batch 143/224, Training Loss: 3.6428\n",
            "Epoch 1, Batch 144/224, Training Loss: 3.3753\n",
            "Epoch 1, Batch 145/224, Training Loss: 4.5027\n",
            "Epoch 1, Batch 146/224, Training Loss: 3.8442\n",
            "Epoch 1, Batch 147/224, Training Loss: 4.3699\n",
            "Epoch 1, Batch 148/224, Training Loss: 3.7394\n",
            "Epoch 1, Batch 149/224, Training Loss: 3.3344\n",
            "Epoch 1, Batch 150/224, Training Loss: 3.3866\n",
            "Epoch 1, Batch 151/224, Training Loss: 3.2526\n",
            "Epoch 1, Batch 152/224, Training Loss: 5.7940\n",
            "Epoch 1, Batch 153/224, Training Loss: 4.5269\n",
            "Epoch 1, Batch 154/224, Training Loss: 3.6531\n",
            "Epoch 1, Batch 155/224, Training Loss: 4.4337\n",
            "Epoch 1, Batch 156/224, Training Loss: 4.2149\n",
            "Epoch 1, Batch 157/224, Training Loss: 3.3399\n",
            "Epoch 1, Batch 158/224, Training Loss: 4.0011\n",
            "Epoch 1, Batch 159/224, Training Loss: 3.9318\n",
            "Epoch 1, Batch 160/224, Training Loss: 2.9248\n",
            "Epoch 1, Batch 161/224, Training Loss: 3.3881\n",
            "Epoch 1, Batch 162/224, Training Loss: 4.5008\n",
            "Epoch 1, Batch 163/224, Training Loss: 4.7019\n",
            "Epoch 1, Batch 164/224, Training Loss: 3.2913\n",
            "Epoch 1, Batch 165/224, Training Loss: 3.6787\n",
            "Epoch 1, Batch 166/224, Training Loss: 3.8848\n",
            "Epoch 1, Batch 167/224, Training Loss: 3.9960\n",
            "Epoch 1, Batch 168/224, Training Loss: 4.2069\n",
            "Epoch 1, Batch 169/224, Training Loss: 4.6759\n",
            "Epoch 1, Batch 170/224, Training Loss: 4.1210\n",
            "Epoch 1, Batch 171/224, Training Loss: 4.6495\n",
            "Epoch 1, Batch 172/224, Training Loss: 3.7863\n",
            "Epoch 1, Batch 173/224, Training Loss: 4.0677\n",
            "Epoch 1, Batch 174/224, Training Loss: 3.7195\n",
            "Epoch 1, Batch 175/224, Training Loss: 4.0044\n",
            "Epoch 1, Batch 176/224, Training Loss: 5.0759\n",
            "Epoch 1, Batch 177/224, Training Loss: 3.5900\n",
            "Epoch 1, Batch 178/224, Training Loss: 3.1316\n",
            "Epoch 1, Batch 179/224, Training Loss: 3.5175\n",
            "Epoch 1, Batch 180/224, Training Loss: 3.1396\n",
            "Epoch 1, Batch 181/224, Training Loss: 2.7953\n",
            "Epoch 1, Batch 182/224, Training Loss: 4.2563\n",
            "Epoch 1, Batch 183/224, Training Loss: 2.8416\n",
            "Epoch 1, Batch 184/224, Training Loss: 3.7006\n",
            "Epoch 1, Batch 185/224, Training Loss: 3.3254\n",
            "Epoch 1, Batch 186/224, Training Loss: 3.3929\n",
            "Epoch 1, Batch 187/224, Training Loss: 3.4367\n",
            "Epoch 1, Batch 188/224, Training Loss: 3.1831\n",
            "Epoch 1, Batch 189/224, Training Loss: 2.9934\n",
            "Epoch 1, Batch 190/224, Training Loss: 5.0259\n",
            "Epoch 1, Batch 191/224, Training Loss: 3.6917\n",
            "Epoch 1, Batch 192/224, Training Loss: 3.3565\n",
            "Epoch 1, Batch 193/224, Training Loss: 3.1236\n",
            "Epoch 1, Batch 194/224, Training Loss: 3.5277\n",
            "Epoch 1, Batch 195/224, Training Loss: 3.7432\n",
            "Epoch 1, Batch 196/224, Training Loss: 3.1750\n",
            "Epoch 1, Batch 197/224, Training Loss: 3.8211\n",
            "Epoch 1, Batch 198/224, Training Loss: 3.2884\n",
            "Epoch 1, Batch 199/224, Training Loss: 3.8775\n",
            "Epoch 1, Batch 200/224, Training Loss: 3.3098\n",
            "Epoch 1, Batch 201/224, Training Loss: 2.8335\n",
            "Epoch 1, Batch 202/224, Training Loss: 2.5748\n",
            "Epoch 1, Batch 203/224, Training Loss: 2.9024\n",
            "Epoch 1, Batch 204/224, Training Loss: 4.2362\n",
            "Epoch 1, Batch 205/224, Training Loss: 4.9131\n",
            "Epoch 1, Batch 206/224, Training Loss: 3.2437\n",
            "Epoch 1, Batch 207/224, Training Loss: 2.3094\n",
            "Epoch 1, Batch 208/224, Training Loss: 4.4573\n",
            "Epoch 1, Batch 209/224, Training Loss: 3.8458\n",
            "Epoch 1, Batch 210/224, Training Loss: 4.2678\n",
            "Epoch 1, Batch 211/224, Training Loss: 3.2527\n",
            "Epoch 1, Batch 212/224, Training Loss: 3.6842\n",
            "Epoch 1, Batch 213/224, Training Loss: 3.5891\n",
            "Epoch 1, Batch 214/224, Training Loss: 3.2730\n",
            "Epoch 1, Batch 215/224, Training Loss: 3.1658\n",
            "Epoch 1, Batch 216/224, Training Loss: 3.5551\n",
            "Epoch 1, Batch 217/224, Training Loss: 4.2222\n",
            "Epoch 1, Batch 218/224, Training Loss: 3.6267\n",
            "Epoch 1, Batch 219/224, Training Loss: 3.5355\n",
            "Epoch 1, Batch 220/224, Training Loss: 4.3235\n",
            "Epoch 1, Batch 221/224, Training Loss: 3.6252\n",
            "Epoch 1, Batch 222/224, Training Loss: 3.2878\n",
            "Epoch 1, Batch 223/224, Training Loss: 2.9238\n",
            "Epoch 1/10, Training Loss: 5.7024, Test Loss: 3.2049\n",
            "Epoch 2, Batch 0/224, Training Loss: 3.3212\n",
            "Epoch 2, Batch 1/224, Training Loss: 2.8021\n",
            "Epoch 2, Batch 2/224, Training Loss: 3.1064\n",
            "Epoch 2, Batch 3/224, Training Loss: 3.0936\n",
            "Epoch 2, Batch 4/224, Training Loss: 4.1248\n",
            "Epoch 2, Batch 5/224, Training Loss: 3.9836\n",
            "Epoch 2, Batch 6/224, Training Loss: 3.6847\n",
            "Epoch 2, Batch 7/224, Training Loss: 2.8594\n",
            "Epoch 2, Batch 8/224, Training Loss: 2.9520\n",
            "Epoch 2, Batch 9/224, Training Loss: 3.4250\n",
            "Epoch 2, Batch 10/224, Training Loss: 3.7931\n",
            "Epoch 2, Batch 11/224, Training Loss: 4.1691\n",
            "Epoch 2, Batch 12/224, Training Loss: 3.5892\n",
            "Epoch 2, Batch 13/224, Training Loss: 3.4586\n",
            "Epoch 2, Batch 14/224, Training Loss: 3.2534\n",
            "Epoch 2, Batch 15/224, Training Loss: 3.2109\n",
            "Epoch 2, Batch 16/224, Training Loss: 3.0187\n",
            "Epoch 2, Batch 17/224, Training Loss: 2.9373\n",
            "Epoch 2, Batch 18/224, Training Loss: 3.7728\n",
            "Epoch 2, Batch 19/224, Training Loss: 3.3405\n",
            "Epoch 2, Batch 20/224, Training Loss: 3.2503\n",
            "Epoch 2, Batch 21/224, Training Loss: 3.8579\n",
            "Epoch 2, Batch 22/224, Training Loss: 2.7878\n",
            "Epoch 2, Batch 23/224, Training Loss: 4.0351\n",
            "Epoch 2, Batch 24/224, Training Loss: 2.6533\n",
            "Epoch 2, Batch 25/224, Training Loss: 2.8101\n",
            "Epoch 2, Batch 26/224, Training Loss: 2.9754\n",
            "Epoch 2, Batch 27/224, Training Loss: 3.7919\n",
            "Epoch 2, Batch 28/224, Training Loss: 3.0077\n",
            "Epoch 2, Batch 29/224, Training Loss: 3.4576\n",
            "Epoch 2, Batch 30/224, Training Loss: 3.1926\n",
            "Epoch 2, Batch 31/224, Training Loss: 2.7228\n",
            "Epoch 2, Batch 32/224, Training Loss: 3.1258\n",
            "Epoch 2, Batch 33/224, Training Loss: 3.4449\n",
            "Epoch 2, Batch 34/224, Training Loss: 3.1847\n",
            "Epoch 2, Batch 35/224, Training Loss: 3.4674\n",
            "Epoch 2, Batch 36/224, Training Loss: 2.9282\n",
            "Epoch 2, Batch 37/224, Training Loss: 2.6648\n",
            "Epoch 2, Batch 38/224, Training Loss: 2.9661\n",
            "Epoch 2, Batch 39/224, Training Loss: 2.9583\n",
            "Epoch 2, Batch 40/224, Training Loss: 3.0855\n",
            "Epoch 2, Batch 41/224, Training Loss: 3.5370\n",
            "Epoch 2, Batch 42/224, Training Loss: 2.7987\n",
            "Epoch 2, Batch 43/224, Training Loss: 4.2994\n",
            "Epoch 2, Batch 44/224, Training Loss: 3.5780\n",
            "Epoch 2, Batch 45/224, Training Loss: 3.6003\n",
            "Epoch 2, Batch 46/224, Training Loss: 3.0773\n",
            "Epoch 2, Batch 47/224, Training Loss: 3.6152\n",
            "Epoch 2, Batch 48/224, Training Loss: 2.6556\n",
            "Epoch 2, Batch 49/224, Training Loss: 2.8725\n",
            "Epoch 2, Batch 50/224, Training Loss: 3.0884\n",
            "Epoch 2, Batch 51/224, Training Loss: 3.4599\n",
            "Epoch 2, Batch 52/224, Training Loss: 3.1105\n",
            "Epoch 2, Batch 53/224, Training Loss: 3.7051\n",
            "Epoch 2, Batch 54/224, Training Loss: 3.3763\n",
            "Epoch 2, Batch 55/224, Training Loss: 3.3477\n",
            "Epoch 2, Batch 56/224, Training Loss: 3.1672\n",
            "Epoch 2, Batch 57/224, Training Loss: 3.1056\n",
            "Epoch 2, Batch 58/224, Training Loss: 3.2086\n",
            "Epoch 2, Batch 59/224, Training Loss: 2.8417\n",
            "Epoch 2, Batch 60/224, Training Loss: 3.3892\n",
            "Epoch 2, Batch 61/224, Training Loss: 2.6999\n",
            "Epoch 2, Batch 62/224, Training Loss: 2.3327\n",
            "Epoch 2, Batch 63/224, Training Loss: 2.4044\n",
            "Epoch 2, Batch 64/224, Training Loss: 3.1014\n",
            "Epoch 2, Batch 65/224, Training Loss: 3.3675\n",
            "Epoch 2, Batch 66/224, Training Loss: 2.6451\n",
            "Epoch 2, Batch 67/224, Training Loss: 3.8231\n",
            "Epoch 2, Batch 68/224, Training Loss: 3.3802\n",
            "Epoch 2, Batch 69/224, Training Loss: 3.1539\n",
            "Epoch 2, Batch 70/224, Training Loss: 3.3110\n",
            "Epoch 2, Batch 71/224, Training Loss: 3.0042\n",
            "Epoch 2, Batch 72/224, Training Loss: 2.7737\n",
            "Epoch 2, Batch 73/224, Training Loss: 3.0830\n",
            "Epoch 2, Batch 74/224, Training Loss: 2.9641\n",
            "Epoch 2, Batch 75/224, Training Loss: 3.0748\n",
            "Epoch 2, Batch 76/224, Training Loss: 3.1308\n",
            "Epoch 2, Batch 77/224, Training Loss: 3.2855\n",
            "Epoch 2, Batch 78/224, Training Loss: 3.3781\n",
            "Epoch 2, Batch 79/224, Training Loss: 2.6513\n",
            "Epoch 2, Batch 80/224, Training Loss: 2.0062\n",
            "Epoch 2, Batch 81/224, Training Loss: 2.1710\n",
            "Epoch 2, Batch 82/224, Training Loss: 2.5899\n",
            "Epoch 2, Batch 83/224, Training Loss: 2.8152\n",
            "Epoch 2, Batch 84/224, Training Loss: 3.0237\n",
            "Epoch 2, Batch 85/224, Training Loss: 3.4701\n",
            "Epoch 2, Batch 86/224, Training Loss: 3.8125\n",
            "Epoch 2, Batch 87/224, Training Loss: 2.7035\n",
            "Epoch 2, Batch 88/224, Training Loss: 2.8812\n",
            "Epoch 2, Batch 89/224, Training Loss: 3.1020\n",
            "Epoch 2, Batch 90/224, Training Loss: 2.5338\n",
            "Epoch 2, Batch 91/224, Training Loss: 3.3222\n",
            "Epoch 2, Batch 92/224, Training Loss: 2.3131\n",
            "Epoch 2, Batch 93/224, Training Loss: 3.4643\n",
            "Epoch 2, Batch 94/224, Training Loss: 3.3173\n",
            "Epoch 2, Batch 95/224, Training Loss: 2.4716\n",
            "Epoch 2, Batch 96/224, Training Loss: 3.4893\n",
            "Epoch 2, Batch 97/224, Training Loss: 2.7512\n",
            "Epoch 2, Batch 98/224, Training Loss: 2.9952\n",
            "Epoch 2, Batch 99/224, Training Loss: 2.9216\n",
            "Epoch 2, Batch 100/224, Training Loss: 3.1081\n",
            "Epoch 2, Batch 101/224, Training Loss: 2.1501\n",
            "Epoch 2, Batch 102/224, Training Loss: 2.7931\n",
            "Epoch 2, Batch 103/224, Training Loss: 2.4746\n",
            "Epoch 2, Batch 104/224, Training Loss: 3.5077\n",
            "Epoch 2, Batch 105/224, Training Loss: 2.7726\n",
            "Epoch 2, Batch 106/224, Training Loss: 3.6358\n",
            "Epoch 2, Batch 107/224, Training Loss: 3.5750\n",
            "Epoch 2, Batch 108/224, Training Loss: 2.4473\n",
            "Epoch 2, Batch 109/224, Training Loss: 2.8577\n",
            "Epoch 2, Batch 110/224, Training Loss: 3.2750\n",
            "Epoch 2, Batch 111/224, Training Loss: 3.3564\n",
            "Epoch 2, Batch 112/224, Training Loss: 3.3415\n",
            "Epoch 2, Batch 113/224, Training Loss: 2.8979\n",
            "Epoch 2, Batch 114/224, Training Loss: 2.5049\n",
            "Epoch 2, Batch 115/224, Training Loss: 2.7197\n",
            "Epoch 2, Batch 116/224, Training Loss: 2.5515\n",
            "Epoch 2, Batch 117/224, Training Loss: 2.6316\n",
            "Epoch 2, Batch 118/224, Training Loss: 2.8354\n",
            "Epoch 2, Batch 119/224, Training Loss: 2.3828\n",
            "Epoch 2, Batch 120/224, Training Loss: 2.4427\n",
            "Epoch 2, Batch 121/224, Training Loss: 2.3660\n",
            "Epoch 2, Batch 122/224, Training Loss: 2.8815\n",
            "Epoch 2, Batch 123/224, Training Loss: 2.6289\n",
            "Epoch 2, Batch 124/224, Training Loss: 2.6264\n",
            "Epoch 2, Batch 125/224, Training Loss: 2.4367\n",
            "Epoch 2, Batch 126/224, Training Loss: 2.7358\n",
            "Epoch 2, Batch 127/224, Training Loss: 2.4244\n",
            "Epoch 2, Batch 128/224, Training Loss: 3.3073\n",
            "Epoch 2, Batch 129/224, Training Loss: 2.6126\n",
            "Epoch 2, Batch 130/224, Training Loss: 3.5466\n",
            "Epoch 2, Batch 131/224, Training Loss: 3.2170\n",
            "Epoch 2, Batch 132/224, Training Loss: 2.8404\n",
            "Epoch 2, Batch 133/224, Training Loss: 2.6591\n",
            "Epoch 2, Batch 134/224, Training Loss: 2.5527\n",
            "Epoch 2, Batch 135/224, Training Loss: 3.4572\n",
            "Epoch 2, Batch 136/224, Training Loss: 3.7409\n",
            "Epoch 2, Batch 137/224, Training Loss: 3.3739\n",
            "Epoch 2, Batch 138/224, Training Loss: 2.3306\n",
            "Epoch 2, Batch 139/224, Training Loss: 2.5187\n",
            "Epoch 2, Batch 140/224, Training Loss: 3.5155\n",
            "Epoch 2, Batch 141/224, Training Loss: 2.6793\n",
            "Epoch 2, Batch 142/224, Training Loss: 3.0755\n",
            "Epoch 2, Batch 143/224, Training Loss: 3.0651\n",
            "Epoch 2, Batch 144/224, Training Loss: 2.4915\n",
            "Epoch 2, Batch 145/224, Training Loss: 3.4173\n",
            "Epoch 2, Batch 146/224, Training Loss: 3.4887\n",
            "Epoch 2, Batch 147/224, Training Loss: 2.9905\n",
            "Epoch 2, Batch 148/224, Training Loss: 2.4431\n",
            "Epoch 2, Batch 149/224, Training Loss: 3.2333\n",
            "Epoch 2, Batch 150/224, Training Loss: 2.8625\n",
            "Epoch 2, Batch 151/224, Training Loss: 3.1571\n",
            "Epoch 2, Batch 152/224, Training Loss: 2.7268\n",
            "Epoch 2, Batch 153/224, Training Loss: 2.1856\n",
            "Epoch 2, Batch 154/224, Training Loss: 2.3271\n",
            "Epoch 2, Batch 155/224, Training Loss: 3.0656\n",
            "Epoch 2, Batch 156/224, Training Loss: 3.2866\n",
            "Epoch 2, Batch 157/224, Training Loss: 2.5829\n",
            "Epoch 2, Batch 158/224, Training Loss: 1.9408\n",
            "Epoch 2, Batch 159/224, Training Loss: 2.9970\n",
            "Epoch 2, Batch 160/224, Training Loss: 2.2540\n",
            "Epoch 2, Batch 161/224, Training Loss: 2.3237\n",
            "Epoch 2, Batch 162/224, Training Loss: 3.4347\n",
            "Epoch 2, Batch 163/224, Training Loss: 3.2241\n",
            "Epoch 2, Batch 164/224, Training Loss: 3.0819\n",
            "Epoch 2, Batch 165/224, Training Loss: 2.6080\n",
            "Epoch 2, Batch 166/224, Training Loss: 3.8783\n",
            "Epoch 2, Batch 167/224, Training Loss: 2.5773\n",
            "Epoch 2, Batch 168/224, Training Loss: 2.9717\n",
            "Epoch 2, Batch 169/224, Training Loss: 2.3383\n",
            "Epoch 2, Batch 170/224, Training Loss: 2.6133\n",
            "Epoch 2, Batch 171/224, Training Loss: 2.9042\n",
            "Epoch 2, Batch 172/224, Training Loss: 2.9085\n",
            "Epoch 2, Batch 173/224, Training Loss: 3.0355\n",
            "Epoch 2, Batch 174/224, Training Loss: 3.0045\n",
            "Epoch 2, Batch 175/224, Training Loss: 2.4429\n",
            "Epoch 2, Batch 176/224, Training Loss: 2.2952\n",
            "Epoch 2, Batch 177/224, Training Loss: 2.8687\n",
            "Epoch 2, Batch 178/224, Training Loss: 2.9012\n",
            "Epoch 2, Batch 179/224, Training Loss: 2.7757\n",
            "Epoch 2, Batch 180/224, Training Loss: 2.3699\n",
            "Epoch 2, Batch 181/224, Training Loss: 2.8164\n",
            "Epoch 2, Batch 182/224, Training Loss: 3.3166\n",
            "Epoch 2, Batch 183/224, Training Loss: 3.4808\n",
            "Epoch 2, Batch 184/224, Training Loss: 4.0288\n",
            "Epoch 2, Batch 185/224, Training Loss: 3.0882\n",
            "Epoch 2, Batch 186/224, Training Loss: 3.1159\n",
            "Epoch 2, Batch 187/224, Training Loss: 1.9904\n",
            "Epoch 2, Batch 188/224, Training Loss: 3.1052\n",
            "Epoch 2, Batch 189/224, Training Loss: 2.6736\n",
            "Epoch 2, Batch 190/224, Training Loss: 2.2611\n",
            "Epoch 2, Batch 191/224, Training Loss: 2.7783\n",
            "Epoch 2, Batch 192/224, Training Loss: 2.0944\n",
            "Epoch 2, Batch 193/224, Training Loss: 3.5204\n",
            "Epoch 2, Batch 194/224, Training Loss: 3.8467\n",
            "Epoch 2, Batch 195/224, Training Loss: 2.8512\n",
            "Epoch 2, Batch 196/224, Training Loss: 2.8045\n",
            "Epoch 2, Batch 197/224, Training Loss: 1.9734\n",
            "Epoch 2, Batch 198/224, Training Loss: 2.9168\n",
            "Epoch 2, Batch 199/224, Training Loss: 2.4004\n",
            "Epoch 2, Batch 200/224, Training Loss: 3.1344\n",
            "Epoch 2, Batch 201/224, Training Loss: 2.7798\n",
            "Epoch 2, Batch 202/224, Training Loss: 2.0447\n",
            "Epoch 2, Batch 203/224, Training Loss: 2.8191\n",
            "Epoch 2, Batch 204/224, Training Loss: 2.3014\n",
            "Epoch 2, Batch 205/224, Training Loss: 2.4953\n",
            "Epoch 2, Batch 206/224, Training Loss: 2.7123\n",
            "Epoch 2, Batch 207/224, Training Loss: 2.6399\n",
            "Epoch 2, Batch 208/224, Training Loss: 2.7377\n",
            "Epoch 2, Batch 209/224, Training Loss: 2.7879\n",
            "Epoch 2, Batch 210/224, Training Loss: 3.5296\n",
            "Epoch 2, Batch 211/224, Training Loss: 2.6816\n",
            "Epoch 2, Batch 212/224, Training Loss: 2.1320\n",
            "Epoch 2, Batch 213/224, Training Loss: 2.4000\n",
            "Epoch 2, Batch 214/224, Training Loss: 2.6324\n",
            "Epoch 2, Batch 215/224, Training Loss: 2.0303\n",
            "Epoch 2, Batch 216/224, Training Loss: 1.9951\n",
            "Epoch 2, Batch 217/224, Training Loss: 3.1367\n",
            "Epoch 2, Batch 218/224, Training Loss: 2.6380\n",
            "Epoch 2, Batch 219/224, Training Loss: 3.8399\n",
            "Epoch 2, Batch 220/224, Training Loss: 3.1888\n",
            "Epoch 2, Batch 221/224, Training Loss: 2.7599\n",
            "Epoch 2, Batch 222/224, Training Loss: 2.8467\n",
            "Epoch 2, Batch 223/224, Training Loss: 3.0366\n",
            "Epoch 2/10, Training Loss: 2.9779, Test Loss: 2.6617\n",
            "Epoch 3, Batch 0/224, Training Loss: 2.7268\n",
            "Epoch 3, Batch 1/224, Training Loss: 3.0178\n",
            "Epoch 3, Batch 2/224, Training Loss: 2.5896\n",
            "Epoch 3, Batch 3/224, Training Loss: 3.0475\n",
            "Epoch 3, Batch 4/224, Training Loss: 1.9542\n",
            "Epoch 3, Batch 5/224, Training Loss: 2.9699\n",
            "Epoch 3, Batch 6/224, Training Loss: 2.1339\n",
            "Epoch 3, Batch 7/224, Training Loss: 1.9239\n",
            "Epoch 3, Batch 8/224, Training Loss: 2.6251\n",
            "Epoch 3, Batch 9/224, Training Loss: 2.9355\n",
            "Epoch 3, Batch 10/224, Training Loss: 2.9538\n",
            "Epoch 3, Batch 11/224, Training Loss: 2.4133\n",
            "Epoch 3, Batch 12/224, Training Loss: 2.8806\n",
            "Epoch 3, Batch 13/224, Training Loss: 2.4280\n",
            "Epoch 3, Batch 14/224, Training Loss: 2.8286\n",
            "Epoch 3, Batch 15/224, Training Loss: 1.8229\n",
            "Epoch 3, Batch 16/224, Training Loss: 2.4673\n",
            "Epoch 3, Batch 17/224, Training Loss: 2.7476\n",
            "Epoch 3, Batch 18/224, Training Loss: 3.0139\n",
            "Epoch 3, Batch 19/224, Training Loss: 2.2588\n",
            "Epoch 3, Batch 20/224, Training Loss: 2.3485\n",
            "Epoch 3, Batch 21/224, Training Loss: 2.6437\n",
            "Epoch 3, Batch 22/224, Training Loss: 2.9420\n",
            "Epoch 3, Batch 23/224, Training Loss: 2.3728\n",
            "Epoch 3, Batch 24/224, Training Loss: 3.6249\n",
            "Epoch 3, Batch 25/224, Training Loss: 2.5951\n",
            "Epoch 3, Batch 26/224, Training Loss: 3.0434\n",
            "Epoch 3, Batch 27/224, Training Loss: 2.8722\n",
            "Epoch 3, Batch 28/224, Training Loss: 2.1499\n",
            "Epoch 3, Batch 29/224, Training Loss: 3.1598\n",
            "Epoch 3, Batch 30/224, Training Loss: 2.8596\n",
            "Epoch 3, Batch 31/224, Training Loss: 3.0197\n",
            "Epoch 3, Batch 32/224, Training Loss: 3.1348\n",
            "Epoch 3, Batch 33/224, Training Loss: 3.6851\n",
            "Epoch 3, Batch 34/224, Training Loss: 3.3456\n",
            "Epoch 3, Batch 35/224, Training Loss: 2.5863\n",
            "Epoch 3, Batch 36/224, Training Loss: 2.8391\n",
            "Epoch 3, Batch 37/224, Training Loss: 3.1259\n",
            "Epoch 3, Batch 38/224, Training Loss: 2.5100\n",
            "Epoch 3, Batch 39/224, Training Loss: 1.9295\n",
            "Epoch 3, Batch 40/224, Training Loss: 3.3707\n",
            "Epoch 3, Batch 41/224, Training Loss: 1.9843\n",
            "Epoch 3, Batch 42/224, Training Loss: 2.3132\n",
            "Epoch 3, Batch 43/224, Training Loss: 2.7657\n",
            "Epoch 3, Batch 44/224, Training Loss: 2.2036\n",
            "Epoch 3, Batch 45/224, Training Loss: 2.7645\n",
            "Epoch 3, Batch 46/224, Training Loss: 1.8794\n",
            "Epoch 3, Batch 47/224, Training Loss: 3.0745\n",
            "Epoch 3, Batch 48/224, Training Loss: 2.5240\n",
            "Epoch 3, Batch 49/224, Training Loss: 2.3679\n",
            "Epoch 3, Batch 50/224, Training Loss: 1.6975\n",
            "Epoch 3, Batch 51/224, Training Loss: 3.0567\n",
            "Epoch 3, Batch 52/224, Training Loss: 2.6092\n",
            "Epoch 3, Batch 53/224, Training Loss: 3.1892\n",
            "Epoch 3, Batch 54/224, Training Loss: 3.5547\n",
            "Epoch 3, Batch 55/224, Training Loss: 2.5546\n",
            "Epoch 3, Batch 56/224, Training Loss: 3.7846\n",
            "Epoch 3, Batch 57/224, Training Loss: 2.5905\n",
            "Epoch 3, Batch 58/224, Training Loss: 1.9661\n",
            "Epoch 3, Batch 59/224, Training Loss: 2.8364\n",
            "Epoch 3, Batch 60/224, Training Loss: 2.7547\n",
            "Epoch 3, Batch 61/224, Training Loss: 2.1527\n",
            "Epoch 3, Batch 62/224, Training Loss: 2.4747\n",
            "Epoch 3, Batch 63/224, Training Loss: 2.6944\n",
            "Epoch 3, Batch 64/224, Training Loss: 1.9376\n",
            "Epoch 3, Batch 65/224, Training Loss: 1.6410\n",
            "Epoch 3, Batch 66/224, Training Loss: 3.4122\n",
            "Epoch 3, Batch 67/224, Training Loss: 2.3942\n",
            "Epoch 3, Batch 68/224, Training Loss: 3.5041\n",
            "Epoch 3, Batch 69/224, Training Loss: 2.5064\n",
            "Epoch 3, Batch 70/224, Training Loss: 1.8063\n",
            "Epoch 3, Batch 71/224, Training Loss: 2.3061\n",
            "Epoch 3, Batch 72/224, Training Loss: 2.8439\n",
            "Epoch 3, Batch 73/224, Training Loss: 2.5383\n",
            "Epoch 3, Batch 74/224, Training Loss: 2.4481\n",
            "Epoch 3, Batch 75/224, Training Loss: 2.4782\n",
            "Epoch 3, Batch 76/224, Training Loss: 2.1335\n",
            "Epoch 3, Batch 77/224, Training Loss: 2.5035\n",
            "Epoch 3, Batch 78/224, Training Loss: 2.5568\n",
            "Epoch 3, Batch 79/224, Training Loss: 2.3173\n",
            "Epoch 3, Batch 80/224, Training Loss: 2.7315\n",
            "Epoch 3, Batch 81/224, Training Loss: 2.8493\n",
            "Epoch 3, Batch 82/224, Training Loss: 2.6965\n",
            "Epoch 3, Batch 83/224, Training Loss: 2.0335\n",
            "Epoch 3, Batch 84/224, Training Loss: 2.6368\n",
            "Epoch 3, Batch 85/224, Training Loss: 2.8009\n",
            "Epoch 3, Batch 86/224, Training Loss: 2.6406\n",
            "Epoch 3, Batch 87/224, Training Loss: 3.3928\n",
            "Epoch 3, Batch 88/224, Training Loss: 1.6861\n",
            "Epoch 3, Batch 89/224, Training Loss: 2.6713\n",
            "Epoch 3, Batch 90/224, Training Loss: 2.9041\n",
            "Epoch 3, Batch 91/224, Training Loss: 2.2450\n",
            "Epoch 3, Batch 92/224, Training Loss: 3.1143\n",
            "Epoch 3, Batch 93/224, Training Loss: 2.5015\n",
            "Epoch 3, Batch 94/224, Training Loss: 3.0003\n",
            "Epoch 3, Batch 95/224, Training Loss: 2.9278\n",
            "Epoch 3, Batch 96/224, Training Loss: 2.3964\n",
            "Epoch 3, Batch 97/224, Training Loss: 3.1277\n",
            "Epoch 3, Batch 98/224, Training Loss: 2.4329\n",
            "Epoch 3, Batch 99/224, Training Loss: 2.5308\n",
            "Epoch 3, Batch 100/224, Training Loss: 2.2257\n",
            "Epoch 3, Batch 101/224, Training Loss: 1.9918\n",
            "Epoch 3, Batch 102/224, Training Loss: 2.7822\n",
            "Epoch 3, Batch 103/224, Training Loss: 2.5057\n",
            "Epoch 3, Batch 104/224, Training Loss: 2.3133\n",
            "Epoch 3, Batch 105/224, Training Loss: 2.2377\n",
            "Epoch 3, Batch 106/224, Training Loss: 2.8562\n",
            "Epoch 3, Batch 107/224, Training Loss: 3.0439\n",
            "Epoch 3, Batch 108/224, Training Loss: 3.4551\n",
            "Epoch 3, Batch 109/224, Training Loss: 2.4536\n",
            "Epoch 3, Batch 110/224, Training Loss: 2.9601\n",
            "Epoch 3, Batch 111/224, Training Loss: 2.9404\n",
            "Epoch 3, Batch 112/224, Training Loss: 2.0729\n",
            "Epoch 3, Batch 113/224, Training Loss: 2.7920\n",
            "Epoch 3, Batch 114/224, Training Loss: 2.1861\n",
            "Epoch 3, Batch 115/224, Training Loss: 1.6989\n",
            "Epoch 3, Batch 116/224, Training Loss: 3.0872\n",
            "Epoch 3, Batch 117/224, Training Loss: 1.9872\n",
            "Epoch 3, Batch 118/224, Training Loss: 2.2480\n",
            "Epoch 3, Batch 119/224, Training Loss: 2.5641\n",
            "Epoch 3, Batch 120/224, Training Loss: 1.9958\n",
            "Epoch 3, Batch 121/224, Training Loss: 3.1361\n",
            "Epoch 3, Batch 122/224, Training Loss: 3.6424\n",
            "Epoch 3, Batch 123/224, Training Loss: 2.1481\n",
            "Epoch 3, Batch 124/224, Training Loss: 3.1821\n",
            "Epoch 3, Batch 125/224, Training Loss: 2.2231\n",
            "Epoch 3, Batch 126/224, Training Loss: 2.8656\n",
            "Epoch 3, Batch 127/224, Training Loss: 3.5398\n",
            "Epoch 3, Batch 128/224, Training Loss: 2.3801\n",
            "Epoch 3, Batch 129/224, Training Loss: 2.2581\n",
            "Epoch 3, Batch 130/224, Training Loss: 2.1844\n",
            "Epoch 3, Batch 131/224, Training Loss: 2.1205\n",
            "Epoch 3, Batch 132/224, Training Loss: 2.2863\n",
            "Epoch 3, Batch 133/224, Training Loss: 2.6363\n",
            "Epoch 3, Batch 134/224, Training Loss: 2.8047\n",
            "Epoch 3, Batch 135/224, Training Loss: 2.5465\n",
            "Epoch 3, Batch 136/224, Training Loss: 3.3385\n",
            "Epoch 3, Batch 137/224, Training Loss: 2.1513\n",
            "Epoch 3, Batch 138/224, Training Loss: 2.6502\n",
            "Epoch 3, Batch 139/224, Training Loss: 2.2220\n",
            "Epoch 3, Batch 140/224, Training Loss: 2.3016\n",
            "Epoch 3, Batch 141/224, Training Loss: 2.2274\n",
            "Epoch 3, Batch 142/224, Training Loss: 3.3088\n",
            "Epoch 3, Batch 143/224, Training Loss: 2.8027\n",
            "Epoch 3, Batch 144/224, Training Loss: 2.2231\n",
            "Epoch 3, Batch 145/224, Training Loss: 1.8839\n",
            "Epoch 3, Batch 146/224, Training Loss: 2.4601\n",
            "Epoch 3, Batch 147/224, Training Loss: 2.2775\n",
            "Epoch 3, Batch 148/224, Training Loss: 2.6398\n",
            "Epoch 3, Batch 149/224, Training Loss: 2.5216\n",
            "Epoch 3, Batch 150/224, Training Loss: 2.5102\n",
            "Epoch 3, Batch 151/224, Training Loss: 1.7851\n",
            "Epoch 3, Batch 152/224, Training Loss: 2.3849\n",
            "Epoch 3, Batch 153/224, Training Loss: 2.3269\n",
            "Epoch 3, Batch 154/224, Training Loss: 2.0281\n",
            "Epoch 3, Batch 155/224, Training Loss: 1.8804\n",
            "Epoch 3, Batch 156/224, Training Loss: 2.1239\n",
            "Epoch 3, Batch 157/224, Training Loss: 2.3089\n",
            "Epoch 3, Batch 158/224, Training Loss: 2.4215\n",
            "Epoch 3, Batch 159/224, Training Loss: 1.9117\n",
            "Epoch 3, Batch 160/224, Training Loss: 2.3295\n",
            "Epoch 3, Batch 161/224, Training Loss: 3.3531\n",
            "Epoch 3, Batch 162/224, Training Loss: 3.1028\n",
            "Epoch 3, Batch 163/224, Training Loss: 2.8156\n",
            "Epoch 3, Batch 164/224, Training Loss: 2.8898\n",
            "Epoch 3, Batch 165/224, Training Loss: 2.3234\n",
            "Epoch 3, Batch 166/224, Training Loss: 3.0142\n",
            "Epoch 3, Batch 167/224, Training Loss: 2.3296\n",
            "Epoch 3, Batch 168/224, Training Loss: 2.3032\n",
            "Epoch 3, Batch 169/224, Training Loss: 2.9613\n",
            "Epoch 3, Batch 170/224, Training Loss: 2.2921\n",
            "Epoch 3, Batch 171/224, Training Loss: 2.5612\n",
            "Epoch 3, Batch 172/224, Training Loss: 2.7133\n",
            "Epoch 3, Batch 173/224, Training Loss: 3.1683\n",
            "Epoch 3, Batch 174/224, Training Loss: 3.1397\n",
            "Epoch 3, Batch 175/224, Training Loss: 3.1369\n",
            "Epoch 3, Batch 176/224, Training Loss: 2.1039\n",
            "Epoch 3, Batch 177/224, Training Loss: 2.3662\n",
            "Epoch 3, Batch 178/224, Training Loss: 1.9598\n",
            "Epoch 3, Batch 179/224, Training Loss: 2.6599\n",
            "Epoch 3, Batch 180/224, Training Loss: 1.7622\n",
            "Epoch 3, Batch 181/224, Training Loss: 2.9901\n",
            "Epoch 3, Batch 182/224, Training Loss: 2.1270\n",
            "Epoch 3, Batch 183/224, Training Loss: 3.6729\n",
            "Epoch 3, Batch 184/224, Training Loss: 3.0655\n",
            "Epoch 3, Batch 185/224, Training Loss: 3.9842\n",
            "Epoch 3, Batch 186/224, Training Loss: 1.9220\n",
            "Epoch 3, Batch 187/224, Training Loss: 3.0499\n",
            "Epoch 3, Batch 188/224, Training Loss: 3.4543\n",
            "Epoch 3, Batch 189/224, Training Loss: 1.7157\n",
            "Epoch 3, Batch 190/224, Training Loss: 2.2456\n",
            "Epoch 3, Batch 191/224, Training Loss: 2.5143\n",
            "Epoch 3, Batch 192/224, Training Loss: 2.9777\n",
            "Epoch 3, Batch 193/224, Training Loss: 2.6333\n",
            "Epoch 3, Batch 194/224, Training Loss: 2.4018\n",
            "Epoch 3, Batch 195/224, Training Loss: 2.9205\n",
            "Epoch 3, Batch 196/224, Training Loss: 2.2236\n",
            "Epoch 3, Batch 197/224, Training Loss: 3.0451\n",
            "Epoch 3, Batch 198/224, Training Loss: 2.5452\n",
            "Epoch 3, Batch 199/224, Training Loss: 2.7887\n",
            "Epoch 3, Batch 200/224, Training Loss: 2.3479\n",
            "Epoch 3, Batch 201/224, Training Loss: 2.8679\n",
            "Epoch 3, Batch 202/224, Training Loss: 3.1135\n",
            "Epoch 3, Batch 203/224, Training Loss: 1.8934\n",
            "Epoch 3, Batch 204/224, Training Loss: 2.3006\n",
            "Epoch 3, Batch 205/224, Training Loss: 2.2871\n",
            "Epoch 3, Batch 206/224, Training Loss: 2.7189\n",
            "Epoch 3, Batch 207/224, Training Loss: 2.8675\n",
            "Epoch 3, Batch 208/224, Training Loss: 2.4446\n",
            "Epoch 3, Batch 209/224, Training Loss: 2.2427\n",
            "Epoch 3, Batch 210/224, Training Loss: 2.2290\n",
            "Epoch 3, Batch 211/224, Training Loss: 2.5375\n",
            "Epoch 3, Batch 212/224, Training Loss: 2.8621\n",
            "Epoch 3, Batch 213/224, Training Loss: 2.0376\n",
            "Epoch 3, Batch 214/224, Training Loss: 3.4714\n",
            "Epoch 3, Batch 215/224, Training Loss: 2.7399\n",
            "Epoch 3, Batch 216/224, Training Loss: 2.5533\n",
            "Epoch 3, Batch 217/224, Training Loss: 2.4909\n",
            "Epoch 3, Batch 218/224, Training Loss: 2.6924\n",
            "Epoch 3, Batch 219/224, Training Loss: 2.8798\n",
            "Epoch 3, Batch 220/224, Training Loss: 1.7848\n",
            "Epoch 3, Batch 221/224, Training Loss: 2.0899\n",
            "Epoch 3, Batch 222/224, Training Loss: 1.9083\n",
            "Epoch 3, Batch 223/224, Training Loss: 2.7610\n",
            "Epoch 3/10, Training Loss: 2.5940, Test Loss: 2.5373\n",
            "Epoch 4, Batch 0/224, Training Loss: 2.3789\n",
            "Epoch 4, Batch 1/224, Training Loss: 2.7131\n",
            "Epoch 4, Batch 2/224, Training Loss: 2.4622\n",
            "Epoch 4, Batch 3/224, Training Loss: 2.4712\n",
            "Epoch 4, Batch 4/224, Training Loss: 2.7298\n",
            "Epoch 4, Batch 5/224, Training Loss: 3.1525\n",
            "Epoch 4, Batch 6/224, Training Loss: 2.1806\n",
            "Epoch 4, Batch 7/224, Training Loss: 2.8568\n",
            "Epoch 4, Batch 8/224, Training Loss: 1.9459\n",
            "Epoch 4, Batch 9/224, Training Loss: 2.2632\n",
            "Epoch 4, Batch 10/224, Training Loss: 2.1980\n",
            "Epoch 4, Batch 11/224, Training Loss: 1.9763\n",
            "Epoch 4, Batch 12/224, Training Loss: 2.0343\n",
            "Epoch 4, Batch 13/224, Training Loss: 2.1480\n",
            "Epoch 4, Batch 14/224, Training Loss: 2.1737\n",
            "Epoch 4, Batch 15/224, Training Loss: 2.7569\n",
            "Epoch 4, Batch 16/224, Training Loss: 1.7813\n",
            "Epoch 4, Batch 17/224, Training Loss: 2.7134\n",
            "Epoch 4, Batch 18/224, Training Loss: 2.0488\n",
            "Epoch 4, Batch 19/224, Training Loss: 2.0166\n",
            "Epoch 4, Batch 20/224, Training Loss: 2.3711\n",
            "Epoch 4, Batch 21/224, Training Loss: 1.7836\n",
            "Epoch 4, Batch 22/224, Training Loss: 2.2478\n",
            "Epoch 4, Batch 23/224, Training Loss: 2.4363\n",
            "Epoch 4, Batch 24/224, Training Loss: 2.0509\n",
            "Epoch 4, Batch 25/224, Training Loss: 2.1301\n",
            "Epoch 4, Batch 26/224, Training Loss: 1.9780\n",
            "Epoch 4, Batch 27/224, Training Loss: 1.9622\n",
            "Epoch 4, Batch 28/224, Training Loss: 1.9912\n",
            "Epoch 4, Batch 29/224, Training Loss: 2.5379\n",
            "Epoch 4, Batch 30/224, Training Loss: 2.3361\n",
            "Epoch 4, Batch 31/224, Training Loss: 2.1846\n",
            "Epoch 4, Batch 32/224, Training Loss: 2.5519\n",
            "Epoch 4, Batch 33/224, Training Loss: 2.7503\n",
            "Epoch 4, Batch 34/224, Training Loss: 1.9307\n",
            "Epoch 4, Batch 35/224, Training Loss: 2.1239\n",
            "Epoch 4, Batch 36/224, Training Loss: 3.6010\n",
            "Epoch 4, Batch 37/224, Training Loss: 2.2307\n",
            "Epoch 4, Batch 38/224, Training Loss: 2.1757\n",
            "Epoch 4, Batch 39/224, Training Loss: 1.9381\n",
            "Epoch 4, Batch 40/224, Training Loss: 2.3576\n",
            "Epoch 4, Batch 41/224, Training Loss: 2.8086\n",
            "Epoch 4, Batch 42/224, Training Loss: 2.1407\n",
            "Epoch 4, Batch 43/224, Training Loss: 2.0090\n",
            "Epoch 4, Batch 44/224, Training Loss: 2.0106\n",
            "Epoch 4, Batch 45/224, Training Loss: 1.8664\n",
            "Epoch 4, Batch 46/224, Training Loss: 2.8564\n",
            "Epoch 4, Batch 47/224, Training Loss: 2.1835\n",
            "Epoch 4, Batch 48/224, Training Loss: 2.6038\n",
            "Epoch 4, Batch 49/224, Training Loss: 1.7014\n",
            "Epoch 4, Batch 50/224, Training Loss: 1.9098\n",
            "Epoch 4, Batch 51/224, Training Loss: 1.8867\n",
            "Epoch 4, Batch 52/224, Training Loss: 2.2942\n",
            "Epoch 4, Batch 53/224, Training Loss: 2.3275\n",
            "Epoch 4, Batch 54/224, Training Loss: 3.0442\n",
            "Epoch 4, Batch 55/224, Training Loss: 1.8299\n",
            "Epoch 4, Batch 56/224, Training Loss: 2.6073\n",
            "Epoch 4, Batch 57/224, Training Loss: 2.1184\n",
            "Epoch 4, Batch 58/224, Training Loss: 2.6069\n",
            "Epoch 4, Batch 59/224, Training Loss: 2.4096\n",
            "Epoch 4, Batch 60/224, Training Loss: 2.4714\n",
            "Epoch 4, Batch 61/224, Training Loss: 2.7231\n",
            "Epoch 4, Batch 62/224, Training Loss: 2.5433\n",
            "Epoch 4, Batch 63/224, Training Loss: 2.0579\n",
            "Epoch 4, Batch 64/224, Training Loss: 3.3221\n",
            "Epoch 4, Batch 65/224, Training Loss: 2.7366\n",
            "Epoch 4, Batch 66/224, Training Loss: 2.7006\n",
            "Epoch 4, Batch 67/224, Training Loss: 2.2283\n",
            "Epoch 4, Batch 68/224, Training Loss: 2.3193\n",
            "Epoch 4, Batch 69/224, Training Loss: 2.4386\n",
            "Epoch 4, Batch 70/224, Training Loss: 2.2479\n",
            "Epoch 4, Batch 71/224, Training Loss: 2.0293\n",
            "Epoch 4, Batch 72/224, Training Loss: 2.6099\n",
            "Epoch 4, Batch 73/224, Training Loss: 2.9211\n",
            "Epoch 4, Batch 74/224, Training Loss: 2.2228\n",
            "Epoch 4, Batch 75/224, Training Loss: 3.0357\n",
            "Epoch 4, Batch 76/224, Training Loss: 1.5767\n",
            "Epoch 4, Batch 77/224, Training Loss: 2.2027\n",
            "Epoch 4, Batch 78/224, Training Loss: 2.4869\n",
            "Epoch 4, Batch 79/224, Training Loss: 2.1998\n",
            "Epoch 4, Batch 80/224, Training Loss: 2.8730\n",
            "Epoch 4, Batch 81/224, Training Loss: 1.8147\n",
            "Epoch 4, Batch 82/224, Training Loss: 2.3354\n",
            "Epoch 4, Batch 83/224, Training Loss: 2.0395\n",
            "Epoch 4, Batch 84/224, Training Loss: 2.3014\n",
            "Epoch 4, Batch 85/224, Training Loss: 3.5560\n",
            "Epoch 4, Batch 86/224, Training Loss: 2.2508\n",
            "Epoch 4, Batch 87/224, Training Loss: 2.4931\n",
            "Epoch 4, Batch 88/224, Training Loss: 1.7442\n",
            "Epoch 4, Batch 89/224, Training Loss: 2.2081\n",
            "Epoch 4, Batch 90/224, Training Loss: 2.0474\n",
            "Epoch 4, Batch 91/224, Training Loss: 1.9360\n",
            "Epoch 4, Batch 92/224, Training Loss: 3.2583\n",
            "Epoch 4, Batch 93/224, Training Loss: 2.0210\n",
            "Epoch 4, Batch 94/224, Training Loss: 2.6457\n",
            "Epoch 4, Batch 95/224, Training Loss: 2.1444\n",
            "Epoch 4, Batch 96/224, Training Loss: 2.3003\n",
            "Epoch 4, Batch 97/224, Training Loss: 2.1140\n",
            "Epoch 4, Batch 98/224, Training Loss: 2.2504\n",
            "Epoch 4, Batch 99/224, Training Loss: 2.8489\n",
            "Epoch 4, Batch 100/224, Training Loss: 2.6016\n",
            "Epoch 4, Batch 101/224, Training Loss: 2.0612\n",
            "Epoch 4, Batch 102/224, Training Loss: 1.8940\n",
            "Epoch 4, Batch 103/224, Training Loss: 2.3493\n",
            "Epoch 4, Batch 104/224, Training Loss: 2.8957\n",
            "Epoch 4, Batch 105/224, Training Loss: 2.0916\n",
            "Epoch 4, Batch 106/224, Training Loss: 2.9057\n",
            "Epoch 4, Batch 107/224, Training Loss: 1.8108\n",
            "Epoch 4, Batch 108/224, Training Loss: 1.5532\n",
            "Epoch 4, Batch 109/224, Training Loss: 2.3386\n",
            "Epoch 4, Batch 110/224, Training Loss: 2.3391\n",
            "Epoch 4, Batch 111/224, Training Loss: 2.8264\n",
            "Epoch 4, Batch 112/224, Training Loss: 3.1396\n",
            "Epoch 4, Batch 113/224, Training Loss: 2.2566\n",
            "Epoch 4, Batch 114/224, Training Loss: 1.8313\n",
            "Epoch 4, Batch 115/224, Training Loss: 2.4700\n",
            "Epoch 4, Batch 116/224, Training Loss: 1.9552\n",
            "Epoch 4, Batch 117/224, Training Loss: 2.1830\n",
            "Epoch 4, Batch 118/224, Training Loss: 2.1804\n",
            "Epoch 4, Batch 119/224, Training Loss: 2.4209\n",
            "Epoch 4, Batch 120/224, Training Loss: 2.3199\n",
            "Epoch 4, Batch 121/224, Training Loss: 2.7170\n",
            "Epoch 4, Batch 122/224, Training Loss: 2.7677\n",
            "Epoch 4, Batch 123/224, Training Loss: 2.1466\n",
            "Epoch 4, Batch 124/224, Training Loss: 2.7108\n",
            "Epoch 4, Batch 125/224, Training Loss: 2.7041\n",
            "Epoch 4, Batch 126/224, Training Loss: 2.5104\n",
            "Epoch 4, Batch 127/224, Training Loss: 2.1279\n",
            "Epoch 4, Batch 128/224, Training Loss: 2.0685\n",
            "Epoch 4, Batch 129/224, Training Loss: 2.2840\n",
            "Epoch 4, Batch 130/224, Training Loss: 2.4977\n",
            "Epoch 4, Batch 131/224, Training Loss: 2.7013\n",
            "Epoch 4, Batch 132/224, Training Loss: 1.7165\n",
            "Epoch 4, Batch 133/224, Training Loss: 2.4514\n",
            "Epoch 4, Batch 134/224, Training Loss: 1.9577\n",
            "Epoch 4, Batch 135/224, Training Loss: 2.1859\n",
            "Epoch 4, Batch 136/224, Training Loss: 2.6154\n",
            "Epoch 4, Batch 137/224, Training Loss: 2.9017\n",
            "Epoch 4, Batch 138/224, Training Loss: 2.6990\n",
            "Epoch 4, Batch 139/224, Training Loss: 2.3122\n",
            "Epoch 4, Batch 140/224, Training Loss: 2.1728\n",
            "Epoch 4, Batch 141/224, Training Loss: 1.7485\n",
            "Epoch 4, Batch 142/224, Training Loss: 2.6624\n",
            "Epoch 4, Batch 143/224, Training Loss: 1.5872\n",
            "Epoch 4, Batch 144/224, Training Loss: 2.2204\n",
            "Epoch 4, Batch 145/224, Training Loss: 2.1606\n",
            "Epoch 4, Batch 146/224, Training Loss: 2.3722\n",
            "Epoch 4, Batch 147/224, Training Loss: 2.3536\n",
            "Epoch 4, Batch 148/224, Training Loss: 2.3983\n",
            "Epoch 4, Batch 149/224, Training Loss: 2.0426\n",
            "Epoch 4, Batch 150/224, Training Loss: 2.1749\n",
            "Epoch 4, Batch 151/224, Training Loss: 2.9572\n",
            "Epoch 4, Batch 152/224, Training Loss: 2.7114\n",
            "Epoch 4, Batch 153/224, Training Loss: 1.9148\n",
            "Epoch 4, Batch 154/224, Training Loss: 2.2746\n",
            "Epoch 4, Batch 155/224, Training Loss: 2.8950\n",
            "Epoch 4, Batch 156/224, Training Loss: 2.4443\n",
            "Epoch 4, Batch 157/224, Training Loss: 2.7043\n",
            "Epoch 4, Batch 158/224, Training Loss: 2.7547\n",
            "Epoch 4, Batch 159/224, Training Loss: 2.8061\n",
            "Epoch 4, Batch 160/224, Training Loss: 2.2282\n",
            "Epoch 4, Batch 161/224, Training Loss: 2.3298\n",
            "Epoch 4, Batch 162/224, Training Loss: 1.7514\n",
            "Epoch 4, Batch 163/224, Training Loss: 2.3651\n",
            "Epoch 4, Batch 164/224, Training Loss: 2.8134\n",
            "Epoch 4, Batch 165/224, Training Loss: 2.6127\n",
            "Epoch 4, Batch 166/224, Training Loss: 2.6423\n",
            "Epoch 4, Batch 167/224, Training Loss: 2.8216\n",
            "Epoch 4, Batch 168/224, Training Loss: 3.0310\n",
            "Epoch 4, Batch 169/224, Training Loss: 2.7364\n",
            "Epoch 4, Batch 170/224, Training Loss: 1.7542\n",
            "Epoch 4, Batch 171/224, Training Loss: 2.8212\n",
            "Epoch 4, Batch 172/224, Training Loss: 2.8828\n",
            "Epoch 4, Batch 173/224, Training Loss: 2.6087\n",
            "Epoch 4, Batch 174/224, Training Loss: 2.6850\n",
            "Epoch 4, Batch 175/224, Training Loss: 2.5348\n",
            "Epoch 4, Batch 176/224, Training Loss: 3.2927\n",
            "Epoch 4, Batch 177/224, Training Loss: 2.5196\n",
            "Epoch 4, Batch 178/224, Training Loss: 2.6783\n",
            "Epoch 4, Batch 179/224, Training Loss: 2.2045\n",
            "Epoch 4, Batch 180/224, Training Loss: 1.9231\n",
            "Epoch 4, Batch 181/224, Training Loss: 2.1660\n",
            "Epoch 4, Batch 182/224, Training Loss: 1.6897\n",
            "Epoch 4, Batch 183/224, Training Loss: 2.5196\n",
            "Epoch 4, Batch 184/224, Training Loss: 2.7672\n",
            "Epoch 4, Batch 185/224, Training Loss: 2.5913\n",
            "Epoch 4, Batch 186/224, Training Loss: 2.5578\n",
            "Epoch 4, Batch 187/224, Training Loss: 2.1250\n",
            "Epoch 4, Batch 188/224, Training Loss: 1.8376\n",
            "Epoch 4, Batch 189/224, Training Loss: 1.9583\n",
            "Epoch 4, Batch 190/224, Training Loss: 1.7618\n",
            "Epoch 4, Batch 191/224, Training Loss: 2.4136\n",
            "Epoch 4, Batch 192/224, Training Loss: 2.6143\n",
            "Epoch 4, Batch 193/224, Training Loss: 2.5698\n",
            "Epoch 4, Batch 194/224, Training Loss: 2.4494\n",
            "Epoch 4, Batch 195/224, Training Loss: 2.2572\n",
            "Epoch 4, Batch 196/224, Training Loss: 2.4213\n",
            "Epoch 4, Batch 197/224, Training Loss: 3.2662\n",
            "Epoch 4, Batch 198/224, Training Loss: 2.2523\n",
            "Epoch 4, Batch 199/224, Training Loss: 2.1924\n",
            "Epoch 4, Batch 200/224, Training Loss: 2.1257\n",
            "Epoch 4, Batch 201/224, Training Loss: 3.6184\n",
            "Epoch 4, Batch 202/224, Training Loss: 2.3936\n",
            "Epoch 4, Batch 203/224, Training Loss: 1.9973\n",
            "Epoch 4, Batch 204/224, Training Loss: 2.2617\n",
            "Epoch 4, Batch 205/224, Training Loss: 1.7829\n",
            "Epoch 4, Batch 206/224, Training Loss: 2.3290\n",
            "Epoch 4, Batch 207/224, Training Loss: 2.3924\n",
            "Epoch 4, Batch 208/224, Training Loss: 2.8359\n",
            "Epoch 4, Batch 209/224, Training Loss: 2.8998\n",
            "Epoch 4, Batch 210/224, Training Loss: 1.9604\n",
            "Epoch 4, Batch 211/224, Training Loss: 2.0846\n",
            "Epoch 4, Batch 212/224, Training Loss: 2.5442\n",
            "Epoch 4, Batch 213/224, Training Loss: 2.1467\n",
            "Epoch 4, Batch 214/224, Training Loss: 2.8230\n",
            "Epoch 4, Batch 215/224, Training Loss: 1.7969\n",
            "Epoch 4, Batch 216/224, Training Loss: 2.5357\n",
            "Epoch 4, Batch 217/224, Training Loss: 1.9812\n",
            "Epoch 4, Batch 218/224, Training Loss: 2.6225\n",
            "Epoch 4, Batch 219/224, Training Loss: 2.4731\n",
            "Epoch 4, Batch 220/224, Training Loss: 2.5959\n",
            "Epoch 4, Batch 221/224, Training Loss: 2.2827\n",
            "Epoch 4, Batch 222/224, Training Loss: 2.3156\n",
            "Epoch 4, Batch 223/224, Training Loss: 2.0151\n",
            "Epoch 4/10, Training Loss: 2.3681, Test Loss: 2.4215\n",
            "Epoch 5, Batch 0/224, Training Loss: 2.3284\n",
            "Epoch 5, Batch 1/224, Training Loss: 2.0209\n",
            "Epoch 5, Batch 2/224, Training Loss: 2.5125\n",
            "Epoch 5, Batch 3/224, Training Loss: 2.3083\n",
            "Epoch 5, Batch 4/224, Training Loss: 2.9472\n",
            "Epoch 5, Batch 5/224, Training Loss: 2.0320\n",
            "Epoch 5, Batch 6/224, Training Loss: 1.9184\n",
            "Epoch 5, Batch 7/224, Training Loss: 2.3402\n",
            "Epoch 5, Batch 8/224, Training Loss: 1.7808\n",
            "Epoch 5, Batch 9/224, Training Loss: 1.6234\n",
            "Epoch 5, Batch 10/224, Training Loss: 3.0910\n",
            "Epoch 5, Batch 11/224, Training Loss: 2.0329\n",
            "Epoch 5, Batch 12/224, Training Loss: 2.1871\n",
            "Epoch 5, Batch 13/224, Training Loss: 2.2249\n",
            "Epoch 5, Batch 14/224, Training Loss: 2.0990\n",
            "Epoch 5, Batch 15/224, Training Loss: 2.0686\n",
            "Epoch 5, Batch 16/224, Training Loss: 1.6591\n",
            "Epoch 5, Batch 17/224, Training Loss: 1.9855\n",
            "Epoch 5, Batch 18/224, Training Loss: 2.6202\n",
            "Epoch 5, Batch 19/224, Training Loss: 1.9412\n",
            "Epoch 5, Batch 20/224, Training Loss: 1.8494\n",
            "Epoch 5, Batch 21/224, Training Loss: 2.0875\n",
            "Epoch 5, Batch 22/224, Training Loss: 2.5479\n",
            "Epoch 5, Batch 23/224, Training Loss: 2.1856\n",
            "Epoch 5, Batch 24/224, Training Loss: 1.9736\n",
            "Epoch 5, Batch 25/224, Training Loss: 2.0919\n",
            "Epoch 5, Batch 26/224, Training Loss: 1.9245\n",
            "Epoch 5, Batch 27/224, Training Loss: 1.8707\n",
            "Epoch 5, Batch 28/224, Training Loss: 2.1211\n",
            "Epoch 5, Batch 29/224, Training Loss: 2.0983\n",
            "Epoch 5, Batch 30/224, Training Loss: 2.1212\n",
            "Epoch 5, Batch 31/224, Training Loss: 2.0117\n",
            "Epoch 5, Batch 32/224, Training Loss: 2.6474\n",
            "Epoch 5, Batch 33/224, Training Loss: 1.6233\n",
            "Epoch 5, Batch 34/224, Training Loss: 2.5741\n",
            "Epoch 5, Batch 35/224, Training Loss: 1.9364\n",
            "Epoch 5, Batch 36/224, Training Loss: 2.4508\n",
            "Epoch 5, Batch 37/224, Training Loss: 2.7005\n",
            "Epoch 5, Batch 38/224, Training Loss: 2.0804\n",
            "Epoch 5, Batch 39/224, Training Loss: 2.2312\n",
            "Epoch 5, Batch 40/224, Training Loss: 2.1252\n",
            "Epoch 5, Batch 41/224, Training Loss: 1.7633\n",
            "Epoch 5, Batch 42/224, Training Loss: 2.5178\n",
            "Epoch 5, Batch 43/224, Training Loss: 2.2122\n",
            "Epoch 5, Batch 44/224, Training Loss: 1.8565\n",
            "Epoch 5, Batch 45/224, Training Loss: 1.7161\n",
            "Epoch 5, Batch 46/224, Training Loss: 2.3435\n",
            "Epoch 5, Batch 47/224, Training Loss: 2.6969\n",
            "Epoch 5, Batch 48/224, Training Loss: 2.1115\n",
            "Epoch 5, Batch 49/224, Training Loss: 2.9277\n",
            "Epoch 5, Batch 50/224, Training Loss: 2.9599\n",
            "Epoch 5, Batch 51/224, Training Loss: 2.0009\n",
            "Epoch 5, Batch 52/224, Training Loss: 2.0090\n",
            "Epoch 5, Batch 53/224, Training Loss: 1.3610\n",
            "Epoch 5, Batch 54/224, Training Loss: 2.6228\n",
            "Epoch 5, Batch 55/224, Training Loss: 2.0868\n",
            "Epoch 5, Batch 56/224, Training Loss: 1.7120\n",
            "Epoch 5, Batch 57/224, Training Loss: 2.1567\n",
            "Epoch 5, Batch 58/224, Training Loss: 1.6107\n",
            "Epoch 5, Batch 59/224, Training Loss: 2.6045\n",
            "Epoch 5, Batch 60/224, Training Loss: 1.4277\n",
            "Epoch 5, Batch 61/224, Training Loss: 2.4521\n",
            "Epoch 5, Batch 62/224, Training Loss: 1.7393\n",
            "Epoch 5, Batch 63/224, Training Loss: 2.2569\n",
            "Epoch 5, Batch 64/224, Training Loss: 2.5142\n",
            "Epoch 5, Batch 65/224, Training Loss: 2.5155\n",
            "Epoch 5, Batch 66/224, Training Loss: 2.0539\n",
            "Epoch 5, Batch 67/224, Training Loss: 2.0410\n",
            "Epoch 5, Batch 68/224, Training Loss: 2.5196\n",
            "Epoch 5, Batch 69/224, Training Loss: 2.2005\n",
            "Epoch 5, Batch 70/224, Training Loss: 2.0559\n",
            "Epoch 5, Batch 71/224, Training Loss: 2.3918\n",
            "Epoch 5, Batch 72/224, Training Loss: 2.6396\n",
            "Epoch 5, Batch 73/224, Training Loss: 2.4533\n",
            "Epoch 5, Batch 74/224, Training Loss: 2.0388\n",
            "Epoch 5, Batch 75/224, Training Loss: 1.5995\n",
            "Epoch 5, Batch 76/224, Training Loss: 2.4511\n",
            "Epoch 5, Batch 77/224, Training Loss: 1.6789\n",
            "Epoch 5, Batch 78/224, Training Loss: 1.8794\n",
            "Epoch 5, Batch 79/224, Training Loss: 1.9211\n",
            "Epoch 5, Batch 80/224, Training Loss: 1.9834\n",
            "Epoch 5, Batch 81/224, Training Loss: 1.5060\n",
            "Epoch 5, Batch 82/224, Training Loss: 1.7676\n",
            "Epoch 5, Batch 83/224, Training Loss: 3.0596\n",
            "Epoch 5, Batch 84/224, Training Loss: 2.1485\n",
            "Epoch 5, Batch 85/224, Training Loss: 2.2222\n",
            "Epoch 5, Batch 86/224, Training Loss: 2.9322\n",
            "Epoch 5, Batch 87/224, Training Loss: 2.4257\n",
            "Epoch 5, Batch 88/224, Training Loss: 2.2287\n",
            "Epoch 5, Batch 89/224, Training Loss: 2.0763\n",
            "Epoch 5, Batch 90/224, Training Loss: 1.9747\n",
            "Epoch 5, Batch 91/224, Training Loss: 2.2521\n",
            "Epoch 5, Batch 92/224, Training Loss: 1.8397\n",
            "Epoch 5, Batch 93/224, Training Loss: 1.8116\n",
            "Epoch 5, Batch 94/224, Training Loss: 2.5402\n",
            "Epoch 5, Batch 95/224, Training Loss: 2.4241\n",
            "Epoch 5, Batch 96/224, Training Loss: 2.3597\n",
            "Epoch 5, Batch 97/224, Training Loss: 1.5423\n",
            "Epoch 5, Batch 98/224, Training Loss: 2.8573\n",
            "Epoch 5, Batch 99/224, Training Loss: 2.8401\n",
            "Epoch 5, Batch 100/224, Training Loss: 2.2389\n",
            "Epoch 5, Batch 101/224, Training Loss: 1.8198\n",
            "Epoch 5, Batch 102/224, Training Loss: 2.2048\n",
            "Epoch 5, Batch 103/224, Training Loss: 2.4695\n",
            "Epoch 5, Batch 104/224, Training Loss: 2.1237\n",
            "Epoch 5, Batch 105/224, Training Loss: 1.9471\n",
            "Epoch 5, Batch 106/224, Training Loss: 2.7068\n",
            "Epoch 5, Batch 107/224, Training Loss: 1.8300\n",
            "Epoch 5, Batch 108/224, Training Loss: 2.0261\n",
            "Epoch 5, Batch 109/224, Training Loss: 2.3630\n",
            "Epoch 5, Batch 110/224, Training Loss: 1.9564\n",
            "Epoch 5, Batch 111/224, Training Loss: 2.1237\n",
            "Epoch 5, Batch 112/224, Training Loss: 2.1789\n",
            "Epoch 5, Batch 113/224, Training Loss: 1.7196\n",
            "Epoch 5, Batch 114/224, Training Loss: 1.5930\n",
            "Epoch 5, Batch 115/224, Training Loss: 3.2118\n",
            "Epoch 5, Batch 116/224, Training Loss: 2.3791\n",
            "Epoch 5, Batch 117/224, Training Loss: 2.0273\n",
            "Epoch 5, Batch 118/224, Training Loss: 2.3903\n",
            "Epoch 5, Batch 119/224, Training Loss: 2.3734\n",
            "Epoch 5, Batch 120/224, Training Loss: 2.4828\n",
            "Epoch 5, Batch 121/224, Training Loss: 2.5788\n",
            "Epoch 5, Batch 122/224, Training Loss: 1.8793\n",
            "Epoch 5, Batch 123/224, Training Loss: 2.3681\n",
            "Epoch 5, Batch 124/224, Training Loss: 2.4101\n",
            "Epoch 5, Batch 125/224, Training Loss: 1.6352\n",
            "Epoch 5, Batch 126/224, Training Loss: 3.3234\n",
            "Epoch 5, Batch 127/224, Training Loss: 2.3486\n",
            "Epoch 5, Batch 128/224, Training Loss: 2.2669\n",
            "Epoch 5, Batch 129/224, Training Loss: 2.0968\n",
            "Epoch 5, Batch 130/224, Training Loss: 1.8817\n",
            "Epoch 5, Batch 131/224, Training Loss: 1.9393\n",
            "Epoch 5, Batch 132/224, Training Loss: 2.1085\n",
            "Epoch 5, Batch 133/224, Training Loss: 1.6522\n",
            "Epoch 5, Batch 134/224, Training Loss: 2.3855\n",
            "Epoch 5, Batch 135/224, Training Loss: 2.2456\n",
            "Epoch 5, Batch 136/224, Training Loss: 1.9541\n",
            "Epoch 5, Batch 137/224, Training Loss: 2.4863\n",
            "Epoch 5, Batch 138/224, Training Loss: 2.3467\n",
            "Epoch 5, Batch 139/224, Training Loss: 2.2862\n",
            "Epoch 5, Batch 140/224, Training Loss: 2.3266\n",
            "Epoch 5, Batch 141/224, Training Loss: 1.9700\n",
            "Epoch 5, Batch 142/224, Training Loss: 2.2072\n",
            "Epoch 5, Batch 143/224, Training Loss: 3.1791\n",
            "Epoch 5, Batch 144/224, Training Loss: 2.2322\n",
            "Epoch 5, Batch 145/224, Training Loss: 2.1000\n",
            "Epoch 5, Batch 146/224, Training Loss: 2.6460\n",
            "Epoch 5, Batch 147/224, Training Loss: 2.6021\n",
            "Epoch 5, Batch 148/224, Training Loss: 1.9216\n",
            "Epoch 5, Batch 149/224, Training Loss: 1.7886\n",
            "Epoch 5, Batch 150/224, Training Loss: 2.1488\n",
            "Epoch 5, Batch 151/224, Training Loss: 2.0733\n",
            "Epoch 5, Batch 152/224, Training Loss: 1.8921\n",
            "Epoch 5, Batch 153/224, Training Loss: 2.8260\n",
            "Epoch 5, Batch 154/224, Training Loss: 2.4127\n",
            "Epoch 5, Batch 155/224, Training Loss: 3.1376\n",
            "Epoch 5, Batch 156/224, Training Loss: 2.4086\n",
            "Epoch 5, Batch 157/224, Training Loss: 1.7877\n",
            "Epoch 5, Batch 158/224, Training Loss: 1.9217\n",
            "Epoch 5, Batch 159/224, Training Loss: 2.9757\n",
            "Epoch 5, Batch 160/224, Training Loss: 2.0705\n",
            "Epoch 5, Batch 161/224, Training Loss: 2.3682\n",
            "Epoch 5, Batch 162/224, Training Loss: 2.7374\n",
            "Epoch 5, Batch 163/224, Training Loss: 2.2820\n",
            "Epoch 5, Batch 164/224, Training Loss: 1.8742\n",
            "Epoch 5, Batch 165/224, Training Loss: 2.5772\n",
            "Epoch 5, Batch 166/224, Training Loss: 2.0338\n",
            "Epoch 5, Batch 167/224, Training Loss: 1.6960\n",
            "Epoch 5, Batch 168/224, Training Loss: 2.6857\n",
            "Epoch 5, Batch 169/224, Training Loss: 2.1978\n",
            "Epoch 5, Batch 170/224, Training Loss: 1.5904\n",
            "Epoch 5, Batch 171/224, Training Loss: 2.1788\n",
            "Epoch 5, Batch 172/224, Training Loss: 2.0115\n",
            "Epoch 5, Batch 173/224, Training Loss: 2.4164\n",
            "Epoch 5, Batch 174/224, Training Loss: 1.8068\n",
            "Epoch 5, Batch 175/224, Training Loss: 1.8840\n",
            "Epoch 5, Batch 176/224, Training Loss: 3.0924\n",
            "Epoch 5, Batch 177/224, Training Loss: 1.7793\n",
            "Epoch 5, Batch 178/224, Training Loss: 2.7816\n",
            "Epoch 5, Batch 179/224, Training Loss: 2.6642\n",
            "Epoch 5, Batch 180/224, Training Loss: 1.8564\n",
            "Epoch 5, Batch 181/224, Training Loss: 2.4517\n",
            "Epoch 5, Batch 182/224, Training Loss: 2.2643\n",
            "Epoch 5, Batch 183/224, Training Loss: 1.7953\n",
            "Epoch 5, Batch 184/224, Training Loss: 2.3005\n",
            "Epoch 5, Batch 185/224, Training Loss: 2.1438\n",
            "Epoch 5, Batch 186/224, Training Loss: 2.2111\n",
            "Epoch 5, Batch 187/224, Training Loss: 1.9568\n",
            "Epoch 5, Batch 188/224, Training Loss: 1.9448\n",
            "Epoch 5, Batch 189/224, Training Loss: 2.3145\n",
            "Epoch 5, Batch 190/224, Training Loss: 3.0303\n",
            "Epoch 5, Batch 191/224, Training Loss: 2.2644\n",
            "Epoch 5, Batch 192/224, Training Loss: 2.1755\n",
            "Epoch 5, Batch 193/224, Training Loss: 2.0010\n",
            "Epoch 5, Batch 194/224, Training Loss: 2.2436\n",
            "Epoch 5, Batch 195/224, Training Loss: 2.1803\n",
            "Epoch 5, Batch 196/224, Training Loss: 1.7714\n",
            "Epoch 5, Batch 197/224, Training Loss: 2.5464\n",
            "Epoch 5, Batch 198/224, Training Loss: 2.7914\n",
            "Epoch 5, Batch 199/224, Training Loss: 2.0780\n",
            "Epoch 5, Batch 200/224, Training Loss: 2.6043\n",
            "Epoch 5, Batch 201/224, Training Loss: 2.9431\n",
            "Epoch 5, Batch 202/224, Training Loss: 2.5369\n",
            "Epoch 5, Batch 203/224, Training Loss: 3.0660\n",
            "Epoch 5, Batch 204/224, Training Loss: 2.4514\n",
            "Epoch 5, Batch 205/224, Training Loss: 2.1938\n",
            "Epoch 5, Batch 206/224, Training Loss: 2.8823\n",
            "Epoch 5, Batch 207/224, Training Loss: 2.2257\n",
            "Epoch 5, Batch 208/224, Training Loss: 1.9959\n",
            "Epoch 5, Batch 209/224, Training Loss: 2.0523\n",
            "Epoch 5, Batch 210/224, Training Loss: 2.9991\n",
            "Epoch 5, Batch 211/224, Training Loss: 2.0974\n",
            "Epoch 5, Batch 212/224, Training Loss: 2.4933\n",
            "Epoch 5, Batch 213/224, Training Loss: 2.2972\n",
            "Epoch 5, Batch 214/224, Training Loss: 2.0334\n",
            "Epoch 5, Batch 215/224, Training Loss: 2.4548\n",
            "Epoch 5, Batch 216/224, Training Loss: 1.9701\n",
            "Epoch 5, Batch 217/224, Training Loss: 2.1414\n",
            "Epoch 5, Batch 218/224, Training Loss: 2.1810\n",
            "Epoch 5, Batch 219/224, Training Loss: 1.9736\n",
            "Epoch 5, Batch 220/224, Training Loss: 2.2689\n",
            "Epoch 5, Batch 221/224, Training Loss: 2.5441\n",
            "Epoch 5, Batch 222/224, Training Loss: 2.4698\n",
            "Epoch 5, Batch 223/224, Training Loss: 2.3185\n",
            "Epoch 5/10, Training Loss: 2.2278, Test Loss: 2.4331\n",
            "Epoch 6, Batch 0/224, Training Loss: 2.1518\n",
            "Epoch 6, Batch 1/224, Training Loss: 1.6939\n",
            "Epoch 6, Batch 2/224, Training Loss: 1.9467\n",
            "Epoch 6, Batch 3/224, Training Loss: 2.3632\n",
            "Epoch 6, Batch 4/224, Training Loss: 2.2082\n",
            "Epoch 6, Batch 5/224, Training Loss: 2.8868\n",
            "Epoch 6, Batch 6/224, Training Loss: 1.5139\n",
            "Epoch 6, Batch 7/224, Training Loss: 1.7852\n",
            "Epoch 6, Batch 8/224, Training Loss: 2.2010\n",
            "Epoch 6, Batch 9/224, Training Loss: 1.0774\n",
            "Epoch 6, Batch 10/224, Training Loss: 2.6621\n",
            "Epoch 6, Batch 11/224, Training Loss: 2.0517\n",
            "Epoch 6, Batch 12/224, Training Loss: 2.1196\n",
            "Epoch 6, Batch 13/224, Training Loss: 2.0043\n",
            "Epoch 6, Batch 14/224, Training Loss: 2.1363\n",
            "Epoch 6, Batch 15/224, Training Loss: 1.7686\n",
            "Epoch 6, Batch 16/224, Training Loss: 2.6131\n",
            "Epoch 6, Batch 17/224, Training Loss: 2.1247\n",
            "Epoch 6, Batch 18/224, Training Loss: 2.0930\n",
            "Epoch 6, Batch 19/224, Training Loss: 1.9021\n",
            "Epoch 6, Batch 20/224, Training Loss: 2.4514\n",
            "Epoch 6, Batch 21/224, Training Loss: 2.0893\n",
            "Epoch 6, Batch 22/224, Training Loss: 2.2555\n",
            "Epoch 6, Batch 23/224, Training Loss: 1.7233\n",
            "Epoch 6, Batch 24/224, Training Loss: 1.6497\n",
            "Epoch 6, Batch 25/224, Training Loss: 1.9400\n",
            "Epoch 6, Batch 26/224, Training Loss: 2.1984\n",
            "Epoch 6, Batch 27/224, Training Loss: 2.2965\n",
            "Epoch 6, Batch 28/224, Training Loss: 1.9736\n",
            "Epoch 6, Batch 29/224, Training Loss: 1.8276\n",
            "Epoch 6, Batch 30/224, Training Loss: 2.0920\n",
            "Epoch 6, Batch 31/224, Training Loss: 1.7420\n",
            "Epoch 6, Batch 32/224, Training Loss: 1.6056\n",
            "Epoch 6, Batch 33/224, Training Loss: 2.1907\n",
            "Epoch 6, Batch 34/224, Training Loss: 1.6793\n",
            "Epoch 6, Batch 35/224, Training Loss: 2.3830\n",
            "Epoch 6, Batch 36/224, Training Loss: 1.7030\n",
            "Epoch 6, Batch 37/224, Training Loss: 1.6242\n",
            "Epoch 6, Batch 38/224, Training Loss: 2.0604\n",
            "Epoch 6, Batch 39/224, Training Loss: 1.8020\n",
            "Epoch 6, Batch 40/224, Training Loss: 2.3167\n",
            "Epoch 6, Batch 41/224, Training Loss: 2.1668\n",
            "Epoch 6, Batch 42/224, Training Loss: 2.3752\n",
            "Epoch 6, Batch 43/224, Training Loss: 2.3080\n",
            "Epoch 6, Batch 44/224, Training Loss: 2.1321\n",
            "Epoch 6, Batch 45/224, Training Loss: 2.3713\n",
            "Epoch 6, Batch 46/224, Training Loss: 2.0751\n",
            "Epoch 6, Batch 47/224, Training Loss: 2.0012\n",
            "Epoch 6, Batch 48/224, Training Loss: 1.6224\n",
            "Epoch 6, Batch 49/224, Training Loss: 2.2276\n",
            "Epoch 6, Batch 50/224, Training Loss: 2.0668\n",
            "Epoch 6, Batch 51/224, Training Loss: 1.8503\n",
            "Epoch 6, Batch 52/224, Training Loss: 2.3102\n",
            "Epoch 6, Batch 53/224, Training Loss: 2.0352\n",
            "Epoch 6, Batch 54/224, Training Loss: 1.7939\n",
            "Epoch 6, Batch 55/224, Training Loss: 3.3922\n",
            "Epoch 6, Batch 56/224, Training Loss: 2.2081\n",
            "Epoch 6, Batch 57/224, Training Loss: 2.1940\n",
            "Epoch 6, Batch 58/224, Training Loss: 2.4049\n",
            "Epoch 6, Batch 59/224, Training Loss: 1.3825\n",
            "Epoch 6, Batch 60/224, Training Loss: 2.2341\n",
            "Epoch 6, Batch 61/224, Training Loss: 1.3886\n",
            "Epoch 6, Batch 62/224, Training Loss: 1.9099\n",
            "Epoch 6, Batch 63/224, Training Loss: 1.5390\n",
            "Epoch 6, Batch 64/224, Training Loss: 2.4539\n",
            "Epoch 6, Batch 65/224, Training Loss: 2.6263\n",
            "Epoch 6, Batch 66/224, Training Loss: 2.7671\n",
            "Epoch 6, Batch 67/224, Training Loss: 2.1353\n",
            "Epoch 6, Batch 68/224, Training Loss: 2.4027\n",
            "Epoch 6, Batch 69/224, Training Loss: 2.2043\n",
            "Epoch 6, Batch 70/224, Training Loss: 1.8326\n",
            "Epoch 6, Batch 71/224, Training Loss: 2.0325\n",
            "Epoch 6, Batch 72/224, Training Loss: 1.8308\n",
            "Epoch 6, Batch 73/224, Training Loss: 1.9090\n",
            "Epoch 6, Batch 74/224, Training Loss: 2.3050\n",
            "Epoch 6, Batch 75/224, Training Loss: 2.0084\n",
            "Epoch 6, Batch 76/224, Training Loss: 1.8073\n",
            "Epoch 6, Batch 77/224, Training Loss: 1.7318\n",
            "Epoch 6, Batch 78/224, Training Loss: 2.2274\n",
            "Epoch 6, Batch 79/224, Training Loss: 2.1257\n",
            "Epoch 6, Batch 80/224, Training Loss: 1.8676\n",
            "Epoch 6, Batch 81/224, Training Loss: 1.9763\n",
            "Epoch 6, Batch 82/224, Training Loss: 1.5759\n",
            "Epoch 6, Batch 83/224, Training Loss: 2.5851\n",
            "Epoch 6, Batch 84/224, Training Loss: 2.3775\n",
            "Epoch 6, Batch 85/224, Training Loss: 2.4645\n",
            "Epoch 6, Batch 86/224, Training Loss: 1.6075\n",
            "Epoch 6, Batch 87/224, Training Loss: 1.8613\n",
            "Epoch 6, Batch 88/224, Training Loss: 1.9568\n",
            "Epoch 6, Batch 89/224, Training Loss: 1.4499\n",
            "Epoch 6, Batch 90/224, Training Loss: 2.7933\n",
            "Epoch 6, Batch 91/224, Training Loss: 1.7892\n",
            "Epoch 6, Batch 92/224, Training Loss: 2.2375\n",
            "Epoch 6, Batch 93/224, Training Loss: 2.2784\n",
            "Epoch 6, Batch 94/224, Training Loss: 1.9253\n",
            "Epoch 6, Batch 95/224, Training Loss: 2.1916\n",
            "Epoch 6, Batch 96/224, Training Loss: 1.7682\n",
            "Epoch 6, Batch 97/224, Training Loss: 1.8461\n",
            "Epoch 6, Batch 98/224, Training Loss: 1.8875\n",
            "Epoch 6, Batch 99/224, Training Loss: 2.1589\n",
            "Epoch 6, Batch 100/224, Training Loss: 1.5635\n",
            "Epoch 6, Batch 101/224, Training Loss: 1.8190\n",
            "Epoch 6, Batch 102/224, Training Loss: 2.6241\n",
            "Epoch 6, Batch 103/224, Training Loss: 1.8258\n",
            "Epoch 6, Batch 104/224, Training Loss: 2.3099\n",
            "Epoch 6, Batch 105/224, Training Loss: 2.1721\n",
            "Epoch 6, Batch 106/224, Training Loss: 1.5517\n",
            "Epoch 6, Batch 107/224, Training Loss: 2.7812\n",
            "Epoch 6, Batch 108/224, Training Loss: 2.5137\n",
            "Epoch 6, Batch 109/224, Training Loss: 2.1776\n",
            "Epoch 6, Batch 110/224, Training Loss: 2.0100\n",
            "Epoch 6, Batch 111/224, Training Loss: 2.5493\n",
            "Epoch 6, Batch 112/224, Training Loss: 1.6047\n",
            "Epoch 6, Batch 113/224, Training Loss: 1.8170\n",
            "Epoch 6, Batch 114/224, Training Loss: 2.5199\n",
            "Epoch 6, Batch 115/224, Training Loss: 1.7389\n",
            "Epoch 6, Batch 116/224, Training Loss: 1.7954\n",
            "Epoch 6, Batch 117/224, Training Loss: 2.2188\n",
            "Epoch 6, Batch 118/224, Training Loss: 2.4632\n",
            "Epoch 6, Batch 119/224, Training Loss: 2.2394\n",
            "Epoch 6, Batch 120/224, Training Loss: 1.6401\n",
            "Epoch 6, Batch 121/224, Training Loss: 3.2559\n",
            "Epoch 6, Batch 122/224, Training Loss: 1.9425\n",
            "Epoch 6, Batch 123/224, Training Loss: 2.1775\n",
            "Epoch 6, Batch 124/224, Training Loss: 1.9493\n",
            "Epoch 6, Batch 125/224, Training Loss: 2.4334\n",
            "Epoch 6, Batch 126/224, Training Loss: 2.2938\n",
            "Epoch 6, Batch 127/224, Training Loss: 2.5808\n",
            "Epoch 6, Batch 128/224, Training Loss: 1.7744\n",
            "Epoch 6, Batch 129/224, Training Loss: 1.8146\n",
            "Epoch 6, Batch 130/224, Training Loss: 1.7367\n",
            "Epoch 6, Batch 131/224, Training Loss: 1.9708\n",
            "Epoch 6, Batch 132/224, Training Loss: 2.9265\n",
            "Epoch 6, Batch 133/224, Training Loss: 2.5816\n",
            "Epoch 6, Batch 134/224, Training Loss: 1.9062\n",
            "Epoch 6, Batch 135/224, Training Loss: 2.8573\n",
            "Epoch 6, Batch 136/224, Training Loss: 2.3656\n",
            "Epoch 6, Batch 137/224, Training Loss: 1.7621\n",
            "Epoch 6, Batch 138/224, Training Loss: 2.2988\n",
            "Epoch 6, Batch 139/224, Training Loss: 2.6420\n",
            "Epoch 6, Batch 140/224, Training Loss: 1.6642\n",
            "Epoch 6, Batch 141/224, Training Loss: 1.9793\n",
            "Epoch 6, Batch 142/224, Training Loss: 1.7929\n",
            "Epoch 6, Batch 143/224, Training Loss: 1.7095\n",
            "Epoch 6, Batch 144/224, Training Loss: 1.9773\n",
            "Epoch 6, Batch 145/224, Training Loss: 3.6191\n",
            "Epoch 6, Batch 146/224, Training Loss: 6.3651\n",
            "Epoch 6, Batch 147/224, Training Loss: 6.7572\n",
            "Epoch 6, Batch 148/224, Training Loss: 4.8495\n",
            "Epoch 6, Batch 149/224, Training Loss: 3.0459\n",
            "Epoch 6, Batch 150/224, Training Loss: 2.9790\n",
            "Epoch 6, Batch 151/224, Training Loss: 2.7025\n",
            "Epoch 6, Batch 152/224, Training Loss: 2.8055\n",
            "Epoch 6, Batch 153/224, Training Loss: 2.8759\n",
            "Epoch 6, Batch 154/224, Training Loss: 4.5681\n",
            "Epoch 6, Batch 155/224, Training Loss: 3.6159\n",
            "Epoch 6, Batch 156/224, Training Loss: 4.4482\n",
            "Epoch 6, Batch 157/224, Training Loss: 6.2071\n",
            "Epoch 6, Batch 158/224, Training Loss: 3.5196\n",
            "Epoch 6, Batch 159/224, Training Loss: 3.4350\n",
            "Epoch 6, Batch 160/224, Training Loss: 2.8466\n",
            "Epoch 6, Batch 161/224, Training Loss: 3.4576\n",
            "Epoch 6, Batch 162/224, Training Loss: 3.2859\n",
            "Epoch 6, Batch 163/224, Training Loss: 4.2051\n",
            "Epoch 6, Batch 164/224, Training Loss: 2.8064\n",
            "Epoch 6, Batch 165/224, Training Loss: 3.3922\n",
            "Epoch 6, Batch 166/224, Training Loss: 2.8094\n",
            "Epoch 6, Batch 167/224, Training Loss: 2.5586\n",
            "Epoch 6, Batch 168/224, Training Loss: 3.5711\n",
            "Epoch 6, Batch 169/224, Training Loss: 1.9042\n",
            "Epoch 6, Batch 170/224, Training Loss: 4.1852\n",
            "Epoch 6, Batch 171/224, Training Loss: 3.6635\n",
            "Epoch 6, Batch 172/224, Training Loss: 3.3564\n",
            "Epoch 6, Batch 173/224, Training Loss: 2.6076\n",
            "Epoch 6, Batch 174/224, Training Loss: 3.5798\n",
            "Epoch 6, Batch 175/224, Training Loss: 3.0790\n",
            "Epoch 6, Batch 176/224, Training Loss: 2.6674\n",
            "Epoch 6, Batch 177/224, Training Loss: 3.1612\n",
            "Epoch 6, Batch 178/224, Training Loss: 3.7132\n",
            "Epoch 6, Batch 179/224, Training Loss: 3.1915\n",
            "Epoch 6, Batch 180/224, Training Loss: 2.4676\n",
            "Epoch 6, Batch 181/224, Training Loss: 2.8626\n",
            "Epoch 6, Batch 182/224, Training Loss: 3.8020\n",
            "Epoch 6, Batch 183/224, Training Loss: 2.7544\n",
            "Epoch 6, Batch 184/224, Training Loss: 2.4019\n",
            "Epoch 6, Batch 185/224, Training Loss: 3.1181\n",
            "Epoch 6, Batch 186/224, Training Loss: 3.2115\n",
            "Epoch 6, Batch 187/224, Training Loss: 2.1723\n",
            "Epoch 6, Batch 188/224, Training Loss: 3.2264\n",
            "Epoch 6, Batch 189/224, Training Loss: 2.6951\n",
            "Epoch 6, Batch 190/224, Training Loss: 3.2575\n",
            "Epoch 6, Batch 191/224, Training Loss: 3.1111\n",
            "Epoch 6, Batch 192/224, Training Loss: 2.7223\n",
            "Epoch 6, Batch 193/224, Training Loss: 2.8548\n",
            "Epoch 6, Batch 194/224, Training Loss: 2.9202\n",
            "Epoch 6, Batch 195/224, Training Loss: 2.5985\n",
            "Epoch 6, Batch 196/224, Training Loss: 2.7668\n",
            "Epoch 6, Batch 197/224, Training Loss: 2.7918\n",
            "Epoch 6, Batch 198/224, Training Loss: 2.7606\n",
            "Epoch 6, Batch 199/224, Training Loss: 3.6042\n",
            "Epoch 6, Batch 200/224, Training Loss: 2.4088\n",
            "Epoch 6, Batch 201/224, Training Loss: 1.9914\n",
            "Epoch 6, Batch 202/224, Training Loss: 3.4619\n",
            "Epoch 6, Batch 203/224, Training Loss: 3.5274\n",
            "Epoch 6, Batch 204/224, Training Loss: 3.2872\n",
            "Epoch 6, Batch 205/224, Training Loss: 2.5856\n",
            "Epoch 6, Batch 206/224, Training Loss: 3.1853\n",
            "Epoch 6, Batch 207/224, Training Loss: 2.4301\n",
            "Epoch 6, Batch 208/224, Training Loss: 3.1303\n",
            "Epoch 6, Batch 209/224, Training Loss: 1.8647\n",
            "Epoch 6, Batch 210/224, Training Loss: 2.3789\n",
            "Epoch 6, Batch 211/224, Training Loss: 3.4600\n",
            "Epoch 6, Batch 212/224, Training Loss: 2.3059\n",
            "Epoch 6, Batch 213/224, Training Loss: 2.1524\n",
            "Epoch 6, Batch 214/224, Training Loss: 3.2070\n",
            "Epoch 6, Batch 215/224, Training Loss: 2.8167\n",
            "Epoch 6, Batch 216/224, Training Loss: 3.0345\n",
            "Epoch 6, Batch 217/224, Training Loss: 2.4436\n",
            "Epoch 6, Batch 218/224, Training Loss: 4.1169\n",
            "Epoch 6, Batch 219/224, Training Loss: 2.6438\n",
            "Epoch 6, Batch 220/224, Training Loss: 4.7096\n",
            "Epoch 6, Batch 221/224, Training Loss: 4.7514\n",
            "Epoch 6, Batch 222/224, Training Loss: 7.5002\n",
            "Epoch 6, Batch 223/224, Training Loss: 2.5997\n",
            "Epoch 6/10, Training Loss: 2.5096, Test Loss: 6.1117\n",
            "Epoch 7, Batch 0/224, Training Loss: 6.3218\n",
            "Epoch 7, Batch 1/224, Training Loss: 2.6543\n",
            "Epoch 7, Batch 2/224, Training Loss: 10.4893\n",
            "Epoch 7, Batch 3/224, Training Loss: 3.8719\n",
            "Epoch 7, Batch 4/224, Training Loss: 15.1624\n",
            "Epoch 7, Batch 5/224, Training Loss: 8.7500\n",
            "Epoch 7, Batch 6/224, Training Loss: 2.5167\n",
            "Epoch 7, Batch 7/224, Training Loss: 4.4232\n",
            "Epoch 7, Batch 8/224, Training Loss: 2.5034\n",
            "Epoch 7, Batch 9/224, Training Loss: 4.0333\n",
            "Epoch 7, Batch 10/224, Training Loss: 2.6553\n",
            "Epoch 7, Batch 11/224, Training Loss: 2.8218\n",
            "Epoch 7, Batch 12/224, Training Loss: 2.9794\n",
            "Epoch 7, Batch 13/224, Training Loss: 3.1231\n",
            "Epoch 7, Batch 14/224, Training Loss: 2.6937\n",
            "Epoch 7, Batch 15/224, Training Loss: 2.9366\n",
            "Epoch 7, Batch 16/224, Training Loss: 2.4961\n",
            "Epoch 7, Batch 17/224, Training Loss: 3.2184\n",
            "Epoch 7, Batch 18/224, Training Loss: 2.9423\n",
            "Epoch 7, Batch 19/224, Training Loss: 2.0406\n",
            "Epoch 7, Batch 20/224, Training Loss: 2.7357\n",
            "Epoch 7, Batch 21/224, Training Loss: 2.1323\n",
            "Epoch 7, Batch 22/224, Training Loss: 2.9207\n",
            "Epoch 7, Batch 23/224, Training Loss: 2.6266\n",
            "Epoch 7, Batch 24/224, Training Loss: 2.3171\n",
            "Epoch 7, Batch 25/224, Training Loss: 2.5904\n",
            "Epoch 7, Batch 26/224, Training Loss: 2.7532\n",
            "Epoch 7, Batch 27/224, Training Loss: 2.3789\n",
            "Epoch 7, Batch 28/224, Training Loss: 2.7541\n",
            "Epoch 7, Batch 29/224, Training Loss: 3.0596\n",
            "Epoch 7, Batch 30/224, Training Loss: 1.9970\n",
            "Epoch 7, Batch 31/224, Training Loss: 2.7052\n",
            "Epoch 7, Batch 32/224, Training Loss: 2.3889\n",
            "Epoch 7, Batch 33/224, Training Loss: 2.8688\n",
            "Epoch 7, Batch 34/224, Training Loss: 1.9096\n",
            "Epoch 7, Batch 35/224, Training Loss: 2.2145\n",
            "Epoch 7, Batch 36/224, Training Loss: 2.4007\n",
            "Epoch 7, Batch 37/224, Training Loss: 1.8066\n",
            "Epoch 7, Batch 38/224, Training Loss: 2.2058\n",
            "Epoch 7, Batch 39/224, Training Loss: 2.6190\n",
            "Epoch 7, Batch 40/224, Training Loss: 2.3084\n",
            "Epoch 7, Batch 41/224, Training Loss: 2.6379\n",
            "Epoch 7, Batch 42/224, Training Loss: 2.4485\n",
            "Epoch 7, Batch 43/224, Training Loss: 2.4014\n",
            "Epoch 7, Batch 44/224, Training Loss: 2.4369\n",
            "Epoch 7, Batch 45/224, Training Loss: 1.9956\n",
            "Epoch 7, Batch 46/224, Training Loss: 2.2153\n",
            "Epoch 7, Batch 47/224, Training Loss: 2.4689\n",
            "Epoch 7, Batch 48/224, Training Loss: 2.2149\n",
            "Epoch 7, Batch 49/224, Training Loss: 2.0417\n",
            "Epoch 7, Batch 50/224, Training Loss: 2.2052\n",
            "Epoch 7, Batch 51/224, Training Loss: 2.7280\n",
            "Epoch 7, Batch 52/224, Training Loss: 1.8026\n",
            "Epoch 7, Batch 53/224, Training Loss: 2.5751\n",
            "Epoch 7, Batch 54/224, Training Loss: 2.9243\n",
            "Epoch 7, Batch 55/224, Training Loss: 1.8087\n",
            "Epoch 7, Batch 56/224, Training Loss: 2.9644\n",
            "Epoch 7, Batch 57/224, Training Loss: 2.4490\n",
            "Epoch 7, Batch 58/224, Training Loss: 2.6026\n",
            "Epoch 7, Batch 59/224, Training Loss: 2.2872\n",
            "Epoch 7, Batch 60/224, Training Loss: 2.0711\n",
            "Epoch 7, Batch 61/224, Training Loss: 2.0637\n",
            "Epoch 7, Batch 62/224, Training Loss: 2.7103\n",
            "Epoch 7, Batch 63/224, Training Loss: 2.4490\n",
            "Epoch 7, Batch 64/224, Training Loss: 2.0006\n",
            "Epoch 7, Batch 65/224, Training Loss: 1.6757\n",
            "Epoch 7, Batch 66/224, Training Loss: 2.7752\n",
            "Epoch 7, Batch 67/224, Training Loss: 2.0666\n",
            "Epoch 7, Batch 68/224, Training Loss: 2.1954\n",
            "Epoch 7, Batch 69/224, Training Loss: 2.5806\n",
            "Epoch 7, Batch 70/224, Training Loss: 2.2287\n",
            "Epoch 7, Batch 71/224, Training Loss: 1.8683\n",
            "Epoch 7, Batch 72/224, Training Loss: 2.2403\n",
            "Epoch 7, Batch 73/224, Training Loss: 2.5851\n",
            "Epoch 7, Batch 74/224, Training Loss: 1.8594\n",
            "Epoch 7, Batch 75/224, Training Loss: 1.7972\n",
            "Epoch 7, Batch 76/224, Training Loss: 2.2327\n",
            "Epoch 7, Batch 77/224, Training Loss: 2.2801\n",
            "Epoch 7, Batch 78/224, Training Loss: 1.7237\n",
            "Epoch 7, Batch 79/224, Training Loss: 2.2360\n",
            "Epoch 7, Batch 80/224, Training Loss: 2.3976\n",
            "Epoch 7, Batch 81/224, Training Loss: 1.6589\n",
            "Epoch 7, Batch 82/224, Training Loss: 1.6066\n",
            "Epoch 7, Batch 83/224, Training Loss: 2.0847\n",
            "Epoch 7, Batch 84/224, Training Loss: 1.4075\n",
            "Epoch 7, Batch 85/224, Training Loss: 1.8554\n",
            "Epoch 7, Batch 86/224, Training Loss: 1.6647\n",
            "Epoch 7, Batch 87/224, Training Loss: 2.2235\n",
            "Epoch 7, Batch 88/224, Training Loss: 1.7565\n",
            "Epoch 7, Batch 89/224, Training Loss: 2.0486\n",
            "Epoch 7, Batch 90/224, Training Loss: 1.9838\n",
            "Epoch 7, Batch 91/224, Training Loss: 2.3017\n",
            "Epoch 7, Batch 92/224, Training Loss: 2.4407\n",
            "Epoch 7, Batch 93/224, Training Loss: 2.9551\n",
            "Epoch 7, Batch 94/224, Training Loss: 2.0375\n",
            "Epoch 7, Batch 95/224, Training Loss: 1.8731\n",
            "Epoch 7, Batch 96/224, Training Loss: 1.6726\n",
            "Epoch 7, Batch 97/224, Training Loss: 2.2119\n",
            "Epoch 7, Batch 98/224, Training Loss: 1.8528\n",
            "Epoch 7, Batch 99/224, Training Loss: 2.3966\n",
            "Epoch 7, Batch 100/224, Training Loss: 2.6069\n",
            "Epoch 7, Batch 101/224, Training Loss: 2.4748\n",
            "Epoch 7, Batch 102/224, Training Loss: 2.5407\n",
            "Epoch 7, Batch 103/224, Training Loss: 1.7393\n",
            "Epoch 7, Batch 104/224, Training Loss: 2.7328\n",
            "Epoch 7, Batch 105/224, Training Loss: 1.6527\n",
            "Epoch 7, Batch 106/224, Training Loss: 2.3889\n",
            "Epoch 7, Batch 107/224, Training Loss: 2.1986\n",
            "Epoch 7, Batch 108/224, Training Loss: 1.8007\n",
            "Epoch 7, Batch 109/224, Training Loss: 1.6679\n",
            "Epoch 7, Batch 110/224, Training Loss: 2.0602\n",
            "Epoch 7, Batch 111/224, Training Loss: 2.3347\n",
            "Epoch 7, Batch 112/224, Training Loss: 2.3438\n",
            "Epoch 7, Batch 113/224, Training Loss: 2.6699\n",
            "Epoch 7, Batch 114/224, Training Loss: 2.1000\n",
            "Epoch 7, Batch 115/224, Training Loss: 2.0198\n",
            "Epoch 7, Batch 116/224, Training Loss: 1.8446\n",
            "Epoch 7, Batch 117/224, Training Loss: 2.0836\n",
            "Epoch 7, Batch 118/224, Training Loss: 2.2822\n",
            "Epoch 7, Batch 119/224, Training Loss: 2.8094\n",
            "Epoch 7, Batch 120/224, Training Loss: 2.1848\n",
            "Epoch 7, Batch 121/224, Training Loss: 2.7451\n",
            "Epoch 7, Batch 122/224, Training Loss: 1.5713\n",
            "Epoch 7, Batch 123/224, Training Loss: 1.9777\n",
            "Epoch 7, Batch 124/224, Training Loss: 1.8384\n",
            "Epoch 7, Batch 125/224, Training Loss: 3.3428\n",
            "Epoch 7, Batch 126/224, Training Loss: 2.4144\n",
            "Epoch 7, Batch 127/224, Training Loss: 2.0307\n",
            "Epoch 7, Batch 128/224, Training Loss: 1.6447\n",
            "Epoch 7, Batch 129/224, Training Loss: 2.4159\n",
            "Epoch 7, Batch 130/224, Training Loss: 1.1200\n",
            "Epoch 7, Batch 131/224, Training Loss: 1.9186\n",
            "Epoch 7, Batch 132/224, Training Loss: 2.3321\n",
            "Epoch 7, Batch 133/224, Training Loss: 1.9407\n",
            "Epoch 7, Batch 134/224, Training Loss: 2.2363\n",
            "Epoch 7, Batch 135/224, Training Loss: 2.1910\n",
            "Epoch 7, Batch 136/224, Training Loss: 2.9467\n",
            "Epoch 7, Batch 137/224, Training Loss: 2.6251\n",
            "Epoch 7, Batch 138/224, Training Loss: 2.2561\n",
            "Epoch 7, Batch 139/224, Training Loss: 1.9623\n",
            "Epoch 7, Batch 140/224, Training Loss: 3.4496\n",
            "Epoch 7, Batch 141/224, Training Loss: 2.2181\n",
            "Epoch 7, Batch 142/224, Training Loss: 1.9968\n",
            "Epoch 7, Batch 143/224, Training Loss: 2.4611\n",
            "Epoch 7, Batch 144/224, Training Loss: 1.8656\n",
            "Epoch 7, Batch 145/224, Training Loss: 1.8829\n",
            "Epoch 7, Batch 146/224, Training Loss: 2.1906\n",
            "Epoch 7, Batch 147/224, Training Loss: 1.7847\n",
            "Epoch 7, Batch 148/224, Training Loss: 1.9764\n",
            "Epoch 7, Batch 149/224, Training Loss: 1.5444\n",
            "Epoch 7, Batch 150/224, Training Loss: 2.1040\n",
            "Epoch 7, Batch 151/224, Training Loss: 1.6539\n",
            "Epoch 7, Batch 152/224, Training Loss: 1.4380\n",
            "Epoch 7, Batch 153/224, Training Loss: 1.8263\n",
            "Epoch 7, Batch 154/224, Training Loss: 2.0278\n",
            "Epoch 7, Batch 155/224, Training Loss: 1.7288\n",
            "Epoch 7, Batch 156/224, Training Loss: 1.6085\n",
            "Epoch 7, Batch 157/224, Training Loss: 2.1743\n",
            "Epoch 7, Batch 158/224, Training Loss: 2.5140\n",
            "Epoch 7, Batch 159/224, Training Loss: 2.9488\n",
            "Epoch 7, Batch 160/224, Training Loss: 1.4182\n",
            "Epoch 7, Batch 161/224, Training Loss: 2.3696\n",
            "Epoch 7, Batch 162/224, Training Loss: 1.9852\n",
            "Epoch 7, Batch 163/224, Training Loss: 1.7795\n",
            "Epoch 7, Batch 164/224, Training Loss: 2.2623\n",
            "Epoch 7, Batch 165/224, Training Loss: 2.3924\n",
            "Epoch 7, Batch 166/224, Training Loss: 2.2706\n",
            "Epoch 7, Batch 167/224, Training Loss: 1.8014\n",
            "Epoch 7, Batch 168/224, Training Loss: 1.8264\n",
            "Epoch 7, Batch 169/224, Training Loss: 2.7624\n",
            "Epoch 7, Batch 170/224, Training Loss: 2.0804\n",
            "Epoch 7, Batch 171/224, Training Loss: 2.3765\n",
            "Epoch 7, Batch 172/224, Training Loss: 2.1937\n",
            "Epoch 7, Batch 173/224, Training Loss: 1.8328\n",
            "Epoch 7, Batch 174/224, Training Loss: 1.8148\n",
            "Epoch 7, Batch 175/224, Training Loss: 2.9278\n",
            "Epoch 7, Batch 176/224, Training Loss: 1.7867\n",
            "Epoch 7, Batch 177/224, Training Loss: 2.3016\n",
            "Epoch 7, Batch 178/224, Training Loss: 2.7510\n",
            "Epoch 7, Batch 179/224, Training Loss: 1.9095\n",
            "Epoch 7, Batch 180/224, Training Loss: 2.0870\n",
            "Epoch 7, Batch 181/224, Training Loss: 1.6102\n",
            "Epoch 7, Batch 182/224, Training Loss: 2.4346\n",
            "Epoch 7, Batch 183/224, Training Loss: 2.1232\n",
            "Epoch 7, Batch 184/224, Training Loss: 1.7424\n",
            "Epoch 7, Batch 185/224, Training Loss: 2.6163\n",
            "Epoch 7, Batch 186/224, Training Loss: 2.0240\n",
            "Epoch 7, Batch 187/224, Training Loss: 1.8593\n",
            "Epoch 7, Batch 188/224, Training Loss: 1.9231\n",
            "Epoch 7, Batch 189/224, Training Loss: 2.2400\n",
            "Epoch 7, Batch 190/224, Training Loss: 2.6074\n",
            "Epoch 7, Batch 191/224, Training Loss: 1.9778\n",
            "Epoch 7, Batch 192/224, Training Loss: 2.0984\n",
            "Epoch 7, Batch 193/224, Training Loss: 1.6634\n",
            "Epoch 7, Batch 194/224, Training Loss: 1.6963\n",
            "Epoch 7, Batch 195/224, Training Loss: 2.4177\n",
            "Epoch 7, Batch 196/224, Training Loss: 2.0223\n",
            "Epoch 7, Batch 197/224, Training Loss: 2.9104\n",
            "Epoch 7, Batch 198/224, Training Loss: 2.4460\n",
            "Epoch 7, Batch 199/224, Training Loss: 2.3738\n",
            "Epoch 7, Batch 200/224, Training Loss: 1.5222\n",
            "Epoch 7, Batch 201/224, Training Loss: 2.5287\n",
            "Epoch 7, Batch 202/224, Training Loss: 1.8933\n",
            "Epoch 7, Batch 203/224, Training Loss: 2.2891\n",
            "Epoch 7, Batch 204/224, Training Loss: 1.9921\n",
            "Epoch 7, Batch 205/224, Training Loss: 1.5281\n",
            "Epoch 7, Batch 206/224, Training Loss: 1.5122\n",
            "Epoch 7, Batch 207/224, Training Loss: 1.8101\n",
            "Epoch 7, Batch 208/224, Training Loss: 2.3732\n",
            "Epoch 7, Batch 209/224, Training Loss: 1.9290\n",
            "Epoch 7, Batch 210/224, Training Loss: 1.9242\n",
            "Epoch 7, Batch 211/224, Training Loss: 1.7969\n",
            "Epoch 7, Batch 212/224, Training Loss: 2.9393\n",
            "Epoch 7, Batch 213/224, Training Loss: 2.6262\n",
            "Epoch 7, Batch 214/224, Training Loss: 2.1597\n",
            "Epoch 7, Batch 215/224, Training Loss: 2.0381\n",
            "Epoch 7, Batch 216/224, Training Loss: 1.6160\n",
            "Epoch 7, Batch 217/224, Training Loss: 2.9341\n",
            "Epoch 7, Batch 218/224, Training Loss: 2.0176\n",
            "Epoch 7, Batch 219/224, Training Loss: 1.5679\n",
            "Epoch 7, Batch 220/224, Training Loss: 2.8116\n",
            "Epoch 7, Batch 221/224, Training Loss: 1.3455\n",
            "Epoch 7, Batch 222/224, Training Loss: 2.9025\n",
            "Epoch 7, Batch 223/224, Training Loss: 1.9507\n",
            "Epoch 7/10, Training Loss: 2.3874, Test Loss: 2.3826\n",
            "Epoch 8, Batch 0/224, Training Loss: 2.1637\n",
            "Epoch 8, Batch 1/224, Training Loss: 1.8741\n",
            "Epoch 8, Batch 2/224, Training Loss: 1.8803\n",
            "Epoch 8, Batch 3/224, Training Loss: 2.3171\n",
            "Epoch 8, Batch 4/224, Training Loss: 1.7468\n",
            "Epoch 8, Batch 5/224, Training Loss: 2.1020\n",
            "Epoch 8, Batch 6/224, Training Loss: 2.0121\n",
            "Epoch 8, Batch 7/224, Training Loss: 2.0124\n",
            "Epoch 8, Batch 8/224, Training Loss: 2.7138\n",
            "Epoch 8, Batch 9/224, Training Loss: 2.3451\n",
            "Epoch 8, Batch 10/224, Training Loss: 2.6257\n",
            "Epoch 8, Batch 11/224, Training Loss: 2.2135\n",
            "Epoch 8, Batch 12/224, Training Loss: 1.7077\n",
            "Epoch 8, Batch 13/224, Training Loss: 1.7949\n",
            "Epoch 8, Batch 14/224, Training Loss: 2.1768\n",
            "Epoch 8, Batch 15/224, Training Loss: 2.4012\n",
            "Epoch 8, Batch 16/224, Training Loss: 1.8161\n",
            "Epoch 8, Batch 17/224, Training Loss: 2.5129\n",
            "Epoch 8, Batch 18/224, Training Loss: 2.3976\n",
            "Epoch 8, Batch 19/224, Training Loss: 2.2808\n",
            "Epoch 8, Batch 20/224, Training Loss: 1.7687\n",
            "Epoch 8, Batch 21/224, Training Loss: 2.2801\n",
            "Epoch 8, Batch 22/224, Training Loss: 2.1966\n",
            "Epoch 8, Batch 23/224, Training Loss: 2.0616\n",
            "Epoch 8, Batch 24/224, Training Loss: 1.7518\n",
            "Epoch 8, Batch 25/224, Training Loss: 1.9554\n",
            "Epoch 8, Batch 26/224, Training Loss: 2.3488\n",
            "Epoch 8, Batch 27/224, Training Loss: 1.6967\n",
            "Epoch 8, Batch 28/224, Training Loss: 1.9815\n",
            "Epoch 8, Batch 29/224, Training Loss: 2.4304\n",
            "Epoch 8, Batch 30/224, Training Loss: 2.2360\n",
            "Epoch 8, Batch 31/224, Training Loss: 1.5854\n",
            "Epoch 8, Batch 32/224, Training Loss: 1.9066\n",
            "Epoch 8, Batch 33/224, Training Loss: 1.6254\n",
            "Epoch 8, Batch 34/224, Training Loss: 1.7247\n",
            "Epoch 8, Batch 35/224, Training Loss: 1.5411\n",
            "Epoch 8, Batch 36/224, Training Loss: 2.2216\n",
            "Epoch 8, Batch 37/224, Training Loss: 2.6603\n",
            "Epoch 8, Batch 38/224, Training Loss: 2.3212\n",
            "Epoch 8, Batch 39/224, Training Loss: 2.0596\n",
            "Epoch 8, Batch 40/224, Training Loss: 2.1466\n",
            "Epoch 8, Batch 41/224, Training Loss: 2.1933\n",
            "Epoch 8, Batch 42/224, Training Loss: 2.1593\n",
            "Epoch 8, Batch 43/224, Training Loss: 1.6420\n",
            "Epoch 8, Batch 44/224, Training Loss: 1.6068\n",
            "Epoch 8, Batch 45/224, Training Loss: 2.4842\n",
            "Epoch 8, Batch 46/224, Training Loss: 1.9331\n",
            "Epoch 8, Batch 47/224, Training Loss: 1.2508\n",
            "Epoch 8, Batch 48/224, Training Loss: 1.8949\n",
            "Epoch 8, Batch 49/224, Training Loss: 2.5697\n",
            "Epoch 8, Batch 50/224, Training Loss: 2.7172\n",
            "Epoch 8, Batch 51/224, Training Loss: 1.1825\n",
            "Epoch 8, Batch 52/224, Training Loss: 2.1140\n",
            "Epoch 8, Batch 53/224, Training Loss: 1.6911\n",
            "Epoch 8, Batch 54/224, Training Loss: 2.2983\n",
            "Epoch 8, Batch 55/224, Training Loss: 2.0623\n",
            "Epoch 8, Batch 56/224, Training Loss: 1.9515\n",
            "Epoch 8, Batch 57/224, Training Loss: 1.3241\n",
            "Epoch 8, Batch 58/224, Training Loss: 1.4026\n",
            "Epoch 8, Batch 59/224, Training Loss: 2.0013\n",
            "Epoch 8, Batch 60/224, Training Loss: 1.4962\n",
            "Epoch 8, Batch 61/224, Training Loss: 1.9340\n",
            "Epoch 8, Batch 62/224, Training Loss: 2.3587\n",
            "Epoch 8, Batch 63/224, Training Loss: 2.2017\n",
            "Epoch 8, Batch 64/224, Training Loss: 1.8338\n",
            "Epoch 8, Batch 65/224, Training Loss: 2.0280\n",
            "Epoch 8, Batch 66/224, Training Loss: 2.0194\n",
            "Epoch 8, Batch 67/224, Training Loss: 1.7995\n",
            "Epoch 8, Batch 68/224, Training Loss: 1.5626\n",
            "Epoch 8, Batch 69/224, Training Loss: 2.0326\n",
            "Epoch 8, Batch 70/224, Training Loss: 2.1833\n",
            "Epoch 8, Batch 71/224, Training Loss: 1.6467\n",
            "Epoch 8, Batch 72/224, Training Loss: 1.5739\n",
            "Epoch 8, Batch 73/224, Training Loss: 1.6283\n",
            "Epoch 8, Batch 74/224, Training Loss: 2.3073\n",
            "Epoch 8, Batch 75/224, Training Loss: 1.7145\n",
            "Epoch 8, Batch 76/224, Training Loss: 1.6066\n",
            "Epoch 8, Batch 77/224, Training Loss: 1.8891\n",
            "Epoch 8, Batch 78/224, Training Loss: 1.8383\n",
            "Epoch 8, Batch 79/224, Training Loss: 1.6116\n",
            "Epoch 8, Batch 80/224, Training Loss: 1.5566\n",
            "Epoch 8, Batch 81/224, Training Loss: 1.9489\n",
            "Epoch 8, Batch 82/224, Training Loss: 2.1547\n",
            "Epoch 8, Batch 83/224, Training Loss: 2.0557\n",
            "Epoch 8, Batch 84/224, Training Loss: 1.4608\n",
            "Epoch 8, Batch 85/224, Training Loss: 1.5109\n",
            "Epoch 8, Batch 86/224, Training Loss: 1.3232\n",
            "Epoch 8, Batch 87/224, Training Loss: 3.2351\n",
            "Epoch 8, Batch 88/224, Training Loss: 2.2665\n",
            "Epoch 8, Batch 89/224, Training Loss: 2.4104\n",
            "Epoch 8, Batch 90/224, Training Loss: 2.2912\n",
            "Epoch 8, Batch 91/224, Training Loss: 1.7866\n",
            "Epoch 8, Batch 92/224, Training Loss: 1.3437\n",
            "Epoch 8, Batch 93/224, Training Loss: 1.9262\n",
            "Epoch 8, Batch 94/224, Training Loss: 2.3726\n",
            "Epoch 8, Batch 95/224, Training Loss: 1.4449\n",
            "Epoch 8, Batch 96/224, Training Loss: 2.1003\n",
            "Epoch 8, Batch 97/224, Training Loss: 2.5870\n",
            "Epoch 8, Batch 98/224, Training Loss: 2.3541\n",
            "Epoch 8, Batch 99/224, Training Loss: 1.6096\n",
            "Epoch 8, Batch 100/224, Training Loss: 2.6037\n",
            "Epoch 8, Batch 101/224, Training Loss: 2.0314\n",
            "Epoch 8, Batch 102/224, Training Loss: 1.5849\n",
            "Epoch 8, Batch 103/224, Training Loss: 1.8392\n",
            "Epoch 8, Batch 104/224, Training Loss: 1.4645\n",
            "Epoch 8, Batch 105/224, Training Loss: 1.9148\n",
            "Epoch 8, Batch 106/224, Training Loss: 1.6300\n",
            "Epoch 8, Batch 107/224, Training Loss: 1.9503\n",
            "Epoch 8, Batch 108/224, Training Loss: 1.7892\n",
            "Epoch 8, Batch 109/224, Training Loss: 2.5164\n",
            "Epoch 8, Batch 110/224, Training Loss: 2.2922\n",
            "Epoch 8, Batch 111/224, Training Loss: 2.7293\n",
            "Epoch 8, Batch 112/224, Training Loss: 2.3114\n",
            "Epoch 8, Batch 113/224, Training Loss: 2.2663\n",
            "Epoch 8, Batch 114/224, Training Loss: 1.7422\n",
            "Epoch 8, Batch 115/224, Training Loss: 2.0026\n",
            "Epoch 8, Batch 116/224, Training Loss: 2.1380\n",
            "Epoch 8, Batch 117/224, Training Loss: 2.4682\n",
            "Epoch 8, Batch 118/224, Training Loss: 1.6577\n",
            "Epoch 8, Batch 119/224, Training Loss: 1.7614\n",
            "Epoch 8, Batch 120/224, Training Loss: 1.9393\n",
            "Epoch 8, Batch 121/224, Training Loss: 2.1772\n",
            "Epoch 8, Batch 122/224, Training Loss: 1.4853\n",
            "Epoch 8, Batch 123/224, Training Loss: 1.9759\n",
            "Epoch 8, Batch 124/224, Training Loss: 1.9572\n",
            "Epoch 8, Batch 125/224, Training Loss: 1.7129\n",
            "Epoch 8, Batch 126/224, Training Loss: 2.2970\n",
            "Epoch 8, Batch 127/224, Training Loss: 1.8145\n",
            "Epoch 8, Batch 128/224, Training Loss: 2.0339\n",
            "Epoch 8, Batch 129/224, Training Loss: 2.0001\n",
            "Epoch 8, Batch 130/224, Training Loss: 1.5114\n",
            "Epoch 8, Batch 131/224, Training Loss: 2.1147\n",
            "Epoch 8, Batch 132/224, Training Loss: 2.2100\n",
            "Epoch 8, Batch 133/224, Training Loss: 1.9380\n",
            "Epoch 8, Batch 134/224, Training Loss: 1.6762\n",
            "Epoch 8, Batch 135/224, Training Loss: 1.5092\n",
            "Epoch 8, Batch 136/224, Training Loss: 2.3309\n",
            "Epoch 8, Batch 137/224, Training Loss: 2.5238\n",
            "Epoch 8, Batch 138/224, Training Loss: 1.8743\n",
            "Epoch 8, Batch 139/224, Training Loss: 1.7170\n",
            "Epoch 8, Batch 140/224, Training Loss: 2.0453\n",
            "Epoch 8, Batch 141/224, Training Loss: 2.0383\n",
            "Epoch 8, Batch 142/224, Training Loss: 1.7624\n",
            "Epoch 8, Batch 143/224, Training Loss: 1.6795\n",
            "Epoch 8, Batch 144/224, Training Loss: 1.6703\n",
            "Epoch 8, Batch 145/224, Training Loss: 1.7997\n",
            "Epoch 8, Batch 146/224, Training Loss: 1.8924\n",
            "Epoch 8, Batch 147/224, Training Loss: 1.8751\n",
            "Epoch 8, Batch 148/224, Training Loss: 1.3256\n",
            "Epoch 8, Batch 149/224, Training Loss: 2.0017\n",
            "Epoch 8, Batch 150/224, Training Loss: 1.7061\n",
            "Epoch 8, Batch 151/224, Training Loss: 3.1913\n",
            "Epoch 8, Batch 152/224, Training Loss: 2.5174\n",
            "Epoch 8, Batch 153/224, Training Loss: 1.2767\n",
            "Epoch 8, Batch 154/224, Training Loss: 2.5817\n",
            "Epoch 8, Batch 155/224, Training Loss: 2.4740\n",
            "Epoch 8, Batch 156/224, Training Loss: 1.7499\n",
            "Epoch 8, Batch 157/224, Training Loss: 2.1616\n",
            "Epoch 8, Batch 158/224, Training Loss: 2.2003\n",
            "Epoch 8, Batch 159/224, Training Loss: 3.0336\n",
            "Epoch 8, Batch 160/224, Training Loss: 1.2144\n",
            "Epoch 8, Batch 161/224, Training Loss: 1.3713\n",
            "Epoch 8, Batch 162/224, Training Loss: 2.0106\n",
            "Epoch 8, Batch 163/224, Training Loss: 2.2033\n",
            "Epoch 8, Batch 164/224, Training Loss: 2.2258\n",
            "Epoch 8, Batch 165/224, Training Loss: 1.4674\n",
            "Epoch 8, Batch 166/224, Training Loss: 1.6800\n",
            "Epoch 8, Batch 167/224, Training Loss: 1.5151\n",
            "Epoch 8, Batch 168/224, Training Loss: 2.3596\n",
            "Epoch 8, Batch 169/224, Training Loss: 1.9573\n",
            "Epoch 8, Batch 170/224, Training Loss: 1.6285\n",
            "Epoch 8, Batch 171/224, Training Loss: 2.3360\n",
            "Epoch 8, Batch 172/224, Training Loss: 1.7083\n",
            "Epoch 8, Batch 173/224, Training Loss: 2.3813\n",
            "Epoch 8, Batch 174/224, Training Loss: 2.9575\n",
            "Epoch 8, Batch 175/224, Training Loss: 2.2203\n",
            "Epoch 8, Batch 176/224, Training Loss: 2.3583\n",
            "Epoch 8, Batch 177/224, Training Loss: 1.9788\n",
            "Epoch 8, Batch 178/224, Training Loss: 1.7108\n",
            "Epoch 8, Batch 179/224, Training Loss: 2.3537\n",
            "Epoch 8, Batch 180/224, Training Loss: 2.1964\n",
            "Epoch 8, Batch 181/224, Training Loss: 2.1049\n",
            "Epoch 8, Batch 182/224, Training Loss: 2.4378\n",
            "Epoch 8, Batch 183/224, Training Loss: 1.6608\n",
            "Epoch 8, Batch 184/224, Training Loss: 2.4268\n",
            "Epoch 8, Batch 185/224, Training Loss: 2.2009\n",
            "Epoch 8, Batch 186/224, Training Loss: 2.0299\n",
            "Epoch 8, Batch 187/224, Training Loss: 2.3324\n",
            "Epoch 8, Batch 188/224, Training Loss: 2.6374\n",
            "Epoch 8, Batch 189/224, Training Loss: 2.1033\n",
            "Epoch 8, Batch 190/224, Training Loss: 1.9238\n",
            "Epoch 8, Batch 191/224, Training Loss: 2.1325\n",
            "Epoch 8, Batch 192/224, Training Loss: 1.5324\n",
            "Epoch 8, Batch 193/224, Training Loss: 2.8550\n",
            "Epoch 8, Batch 194/224, Training Loss: 2.3618\n",
            "Epoch 8, Batch 195/224, Training Loss: 1.9312\n",
            "Epoch 8, Batch 196/224, Training Loss: 1.9670\n",
            "Epoch 8, Batch 197/224, Training Loss: 2.2314\n",
            "Epoch 8, Batch 198/224, Training Loss: 1.3796\n",
            "Epoch 8, Batch 199/224, Training Loss: 2.2038\n",
            "Epoch 8, Batch 200/224, Training Loss: 2.9541\n",
            "Epoch 8, Batch 201/224, Training Loss: 2.0579\n",
            "Epoch 8, Batch 202/224, Training Loss: 2.3395\n",
            "Epoch 8, Batch 203/224, Training Loss: 2.5075\n",
            "Epoch 8, Batch 204/224, Training Loss: 1.3442\n",
            "Epoch 8, Batch 205/224, Training Loss: 2.3499\n",
            "Epoch 8, Batch 206/224, Training Loss: 1.9848\n",
            "Epoch 8, Batch 207/224, Training Loss: 1.8246\n",
            "Epoch 8, Batch 208/224, Training Loss: 1.9077\n",
            "Epoch 8, Batch 209/224, Training Loss: 2.0657\n",
            "Epoch 8, Batch 210/224, Training Loss: 2.0377\n",
            "Epoch 8, Batch 211/224, Training Loss: 2.0532\n",
            "Epoch 8, Batch 212/224, Training Loss: 1.9613\n",
            "Epoch 8, Batch 213/224, Training Loss: 2.0873\n",
            "Epoch 8, Batch 214/224, Training Loss: 2.6257\n",
            "Epoch 8, Batch 215/224, Training Loss: 1.9131\n",
            "Epoch 8, Batch 216/224, Training Loss: 2.0784\n",
            "Epoch 8, Batch 217/224, Training Loss: 2.3438\n",
            "Epoch 8, Batch 218/224, Training Loss: 1.7372\n",
            "Epoch 8, Batch 219/224, Training Loss: 1.9128\n",
            "Epoch 8, Batch 220/224, Training Loss: 1.8986\n",
            "Epoch 8, Batch 221/224, Training Loss: 1.5355\n",
            "Epoch 8, Batch 222/224, Training Loss: 1.7629\n",
            "Epoch 8, Batch 223/224, Training Loss: 2.0077\n",
            "Epoch 8/10, Training Loss: 2.0140, Test Loss: 2.3008\n",
            "Epoch 9, Batch 0/224, Training Loss: 1.8942\n",
            "Epoch 9, Batch 1/224, Training Loss: 1.5976\n",
            "Epoch 9, Batch 2/224, Training Loss: 1.4075\n",
            "Epoch 9, Batch 3/224, Training Loss: 2.2171\n",
            "Epoch 9, Batch 4/224, Training Loss: 1.4663\n",
            "Epoch 9, Batch 5/224, Training Loss: 2.8537\n",
            "Epoch 9, Batch 6/224, Training Loss: 1.7477\n",
            "Epoch 9, Batch 7/224, Training Loss: 1.6451\n",
            "Epoch 9, Batch 8/224, Training Loss: 1.7143\n",
            "Epoch 9, Batch 9/224, Training Loss: 1.8028\n",
            "Epoch 9, Batch 10/224, Training Loss: 1.3367\n",
            "Epoch 9, Batch 11/224, Training Loss: 2.5198\n",
            "Epoch 9, Batch 12/224, Training Loss: 1.6096\n",
            "Epoch 9, Batch 13/224, Training Loss: 1.5491\n",
            "Epoch 9, Batch 14/224, Training Loss: 1.9444\n",
            "Epoch 9, Batch 15/224, Training Loss: 1.6721\n",
            "Epoch 9, Batch 16/224, Training Loss: 2.1397\n",
            "Epoch 9, Batch 17/224, Training Loss: 1.3595\n",
            "Epoch 9, Batch 18/224, Training Loss: 1.7105\n",
            "Epoch 9, Batch 19/224, Training Loss: 1.5477\n",
            "Epoch 9, Batch 20/224, Training Loss: 1.4540\n",
            "Epoch 9, Batch 21/224, Training Loss: 1.4382\n",
            "Epoch 9, Batch 22/224, Training Loss: 1.5416\n",
            "Epoch 9, Batch 23/224, Training Loss: 1.8495\n",
            "Epoch 9, Batch 24/224, Training Loss: 1.4465\n",
            "Epoch 9, Batch 25/224, Training Loss: 1.7247\n",
            "Epoch 9, Batch 26/224, Training Loss: 1.6893\n",
            "Epoch 9, Batch 27/224, Training Loss: 1.3898\n",
            "Epoch 9, Batch 28/224, Training Loss: 1.4532\n",
            "Epoch 9, Batch 29/224, Training Loss: 2.1466\n",
            "Epoch 9, Batch 30/224, Training Loss: 1.9384\n",
            "Epoch 9, Batch 31/224, Training Loss: 2.0691\n",
            "Epoch 9, Batch 32/224, Training Loss: 1.4026\n",
            "Epoch 9, Batch 33/224, Training Loss: 2.4744\n",
            "Epoch 9, Batch 34/224, Training Loss: 1.9627\n",
            "Epoch 9, Batch 35/224, Training Loss: 1.8598\n",
            "Epoch 9, Batch 36/224, Training Loss: 2.2111\n",
            "Epoch 9, Batch 37/224, Training Loss: 2.1034\n",
            "Epoch 9, Batch 38/224, Training Loss: 1.4607\n",
            "Epoch 9, Batch 39/224, Training Loss: 1.5741\n",
            "Epoch 9, Batch 40/224, Training Loss: 2.3887\n",
            "Epoch 9, Batch 41/224, Training Loss: 1.4413\n",
            "Epoch 9, Batch 42/224, Training Loss: 2.0219\n",
            "Epoch 9, Batch 43/224, Training Loss: 2.0636\n",
            "Epoch 9, Batch 44/224, Training Loss: 2.2192\n",
            "Epoch 9, Batch 45/224, Training Loss: 1.8516\n",
            "Epoch 9, Batch 46/224, Training Loss: 2.3680\n",
            "Epoch 9, Batch 47/224, Training Loss: 1.9139\n",
            "Epoch 9, Batch 48/224, Training Loss: 2.7622\n",
            "Epoch 9, Batch 49/224, Training Loss: 1.7040\n",
            "Epoch 9, Batch 50/224, Training Loss: 1.0378\n",
            "Epoch 9, Batch 51/224, Training Loss: 2.0515\n",
            "Epoch 9, Batch 52/224, Training Loss: 1.8954\n",
            "Epoch 9, Batch 53/224, Training Loss: 1.7783\n",
            "Epoch 9, Batch 54/224, Training Loss: 1.7743\n",
            "Epoch 9, Batch 55/224, Training Loss: 2.5045\n",
            "Epoch 9, Batch 56/224, Training Loss: 1.4953\n",
            "Epoch 9, Batch 57/224, Training Loss: 1.7357\n",
            "Epoch 9, Batch 58/224, Training Loss: 1.8637\n",
            "Epoch 9, Batch 59/224, Training Loss: 1.6866\n",
            "Epoch 9, Batch 60/224, Training Loss: 1.7150\n",
            "Epoch 9, Batch 61/224, Training Loss: 1.9275\n",
            "Epoch 9, Batch 62/224, Training Loss: 1.8384\n",
            "Epoch 9, Batch 63/224, Training Loss: 2.0904\n",
            "Epoch 9, Batch 64/224, Training Loss: 1.6247\n",
            "Epoch 9, Batch 65/224, Training Loss: 1.4324\n",
            "Epoch 9, Batch 66/224, Training Loss: 2.0578\n",
            "Epoch 9, Batch 67/224, Training Loss: 1.6273\n",
            "Epoch 9, Batch 68/224, Training Loss: 1.9568\n",
            "Epoch 9, Batch 69/224, Training Loss: 2.1301\n",
            "Epoch 9, Batch 70/224, Training Loss: 1.7196\n",
            "Epoch 9, Batch 71/224, Training Loss: 1.9706\n",
            "Epoch 9, Batch 72/224, Training Loss: 2.3168\n",
            "Epoch 9, Batch 73/224, Training Loss: 1.3959\n",
            "Epoch 9, Batch 74/224, Training Loss: 1.8580\n",
            "Epoch 9, Batch 75/224, Training Loss: 1.2152\n",
            "Epoch 9, Batch 76/224, Training Loss: 1.9092\n",
            "Epoch 9, Batch 77/224, Training Loss: 1.8505\n",
            "Epoch 9, Batch 78/224, Training Loss: 1.5537\n",
            "Epoch 9, Batch 79/224, Training Loss: 2.1988\n",
            "Epoch 9, Batch 80/224, Training Loss: 2.5053\n",
            "Epoch 9, Batch 81/224, Training Loss: 1.7900\n",
            "Epoch 9, Batch 82/224, Training Loss: 1.7693\n",
            "Epoch 9, Batch 83/224, Training Loss: 1.6078\n",
            "Epoch 9, Batch 84/224, Training Loss: 1.8668\n",
            "Epoch 9, Batch 85/224, Training Loss: 1.9441\n",
            "Epoch 9, Batch 86/224, Training Loss: 1.7398\n",
            "Epoch 9, Batch 87/224, Training Loss: 2.1036\n",
            "Epoch 9, Batch 88/224, Training Loss: 1.7740\n",
            "Epoch 9, Batch 89/224, Training Loss: 2.2615\n",
            "Epoch 9, Batch 90/224, Training Loss: 1.9093\n",
            "Epoch 9, Batch 91/224, Training Loss: 1.6055\n",
            "Epoch 9, Batch 92/224, Training Loss: 1.8608\n",
            "Epoch 9, Batch 93/224, Training Loss: 1.8798\n",
            "Epoch 9, Batch 94/224, Training Loss: 2.2334\n",
            "Epoch 9, Batch 95/224, Training Loss: 1.9158\n",
            "Epoch 9, Batch 96/224, Training Loss: 2.3433\n",
            "Epoch 9, Batch 97/224, Training Loss: 2.1836\n",
            "Epoch 9, Batch 98/224, Training Loss: 2.4198\n",
            "Epoch 9, Batch 99/224, Training Loss: 2.2926\n",
            "Epoch 9, Batch 100/224, Training Loss: 1.8410\n",
            "Epoch 9, Batch 101/224, Training Loss: 2.2555\n",
            "Epoch 9, Batch 102/224, Training Loss: 2.0445\n",
            "Epoch 9, Batch 103/224, Training Loss: 1.8112\n",
            "Epoch 9, Batch 104/224, Training Loss: 2.4067\n",
            "Epoch 9, Batch 105/224, Training Loss: 2.0084\n",
            "Epoch 9, Batch 106/224, Training Loss: 1.8198\n",
            "Epoch 9, Batch 107/224, Training Loss: 1.8929\n",
            "Epoch 9, Batch 108/224, Training Loss: 1.4671\n",
            "Epoch 9, Batch 109/224, Training Loss: 1.5430\n",
            "Epoch 9, Batch 110/224, Training Loss: 2.0234\n",
            "Epoch 9, Batch 111/224, Training Loss: 1.4126\n",
            "Epoch 9, Batch 112/224, Training Loss: 1.7423\n",
            "Epoch 9, Batch 113/224, Training Loss: 1.7000\n",
            "Epoch 9, Batch 114/224, Training Loss: 1.0503\n",
            "Epoch 9, Batch 115/224, Training Loss: 1.8247\n",
            "Epoch 9, Batch 116/224, Training Loss: 1.3510\n",
            "Epoch 9, Batch 117/224, Training Loss: 2.3023\n",
            "Epoch 9, Batch 118/224, Training Loss: 2.2651\n",
            "Epoch 9, Batch 119/224, Training Loss: 2.7163\n",
            "Epoch 9, Batch 120/224, Training Loss: 2.3397\n",
            "Epoch 9, Batch 121/224, Training Loss: 1.5701\n",
            "Epoch 9, Batch 122/224, Training Loss: 1.6799\n",
            "Epoch 9, Batch 123/224, Training Loss: 1.7475\n",
            "Epoch 9, Batch 124/224, Training Loss: 1.7686\n",
            "Epoch 9, Batch 125/224, Training Loss: 1.3664\n",
            "Epoch 9, Batch 126/224, Training Loss: 1.5801\n",
            "Epoch 9, Batch 127/224, Training Loss: 2.0080\n",
            "Epoch 9, Batch 128/224, Training Loss: 1.6449\n",
            "Epoch 9, Batch 129/224, Training Loss: 2.4162\n",
            "Epoch 9, Batch 130/224, Training Loss: 1.5175\n",
            "Epoch 9, Batch 131/224, Training Loss: 1.7824\n",
            "Epoch 9, Batch 132/224, Training Loss: 1.6128\n",
            "Epoch 9, Batch 133/224, Training Loss: 2.1768\n",
            "Epoch 9, Batch 134/224, Training Loss: 1.7584\n",
            "Epoch 9, Batch 135/224, Training Loss: 1.7956\n",
            "Epoch 9, Batch 136/224, Training Loss: 1.8815\n",
            "Epoch 9, Batch 137/224, Training Loss: 2.5305\n",
            "Epoch 9, Batch 138/224, Training Loss: 1.1382\n",
            "Epoch 9, Batch 139/224, Training Loss: 1.7123\n",
            "Epoch 9, Batch 140/224, Training Loss: 1.8135\n",
            "Epoch 9, Batch 141/224, Training Loss: 1.4633\n",
            "Epoch 9, Batch 142/224, Training Loss: 1.9494\n",
            "Epoch 9, Batch 143/224, Training Loss: 2.0304\n",
            "Epoch 9, Batch 144/224, Training Loss: 1.4244\n",
            "Epoch 9, Batch 145/224, Training Loss: 1.8114\n",
            "Epoch 9, Batch 146/224, Training Loss: 1.7789\n",
            "Epoch 9, Batch 147/224, Training Loss: 1.7239\n",
            "Epoch 9, Batch 148/224, Training Loss: 1.9527\n",
            "Epoch 9, Batch 149/224, Training Loss: 1.7573\n",
            "Epoch 9, Batch 150/224, Training Loss: 2.1652\n",
            "Epoch 9, Batch 151/224, Training Loss: 1.7551\n",
            "Epoch 9, Batch 152/224, Training Loss: 1.2671\n",
            "Epoch 9, Batch 153/224, Training Loss: 1.6525\n",
            "Epoch 9, Batch 154/224, Training Loss: 1.4223\n",
            "Epoch 9, Batch 155/224, Training Loss: 1.7289\n",
            "Epoch 9, Batch 156/224, Training Loss: 1.7090\n",
            "Epoch 9, Batch 157/224, Training Loss: 2.4644\n",
            "Epoch 9, Batch 158/224, Training Loss: 1.6326\n",
            "Epoch 9, Batch 159/224, Training Loss: 1.8133\n",
            "Epoch 9, Batch 160/224, Training Loss: 2.2048\n",
            "Epoch 9, Batch 161/224, Training Loss: 2.2573\n",
            "Epoch 9, Batch 162/224, Training Loss: 2.1186\n",
            "Epoch 9, Batch 163/224, Training Loss: 1.1712\n",
            "Epoch 9, Batch 164/224, Training Loss: 1.3914\n",
            "Epoch 9, Batch 165/224, Training Loss: 2.7061\n",
            "Epoch 9, Batch 166/224, Training Loss: 1.7613\n",
            "Epoch 9, Batch 167/224, Training Loss: 1.6033\n",
            "Epoch 9, Batch 168/224, Training Loss: 2.1101\n",
            "Epoch 9, Batch 169/224, Training Loss: 1.6687\n",
            "Epoch 9, Batch 170/224, Training Loss: 1.7189\n",
            "Epoch 9, Batch 171/224, Training Loss: 1.8765\n",
            "Epoch 9, Batch 172/224, Training Loss: 1.8212\n",
            "Epoch 9, Batch 173/224, Training Loss: 1.5056\n",
            "Epoch 9, Batch 174/224, Training Loss: 2.2059\n",
            "Epoch 9, Batch 175/224, Training Loss: 2.2475\n",
            "Epoch 9, Batch 176/224, Training Loss: 1.6669\n",
            "Epoch 9, Batch 177/224, Training Loss: 2.7015\n",
            "Epoch 9, Batch 178/224, Training Loss: 1.9749\n",
            "Epoch 9, Batch 179/224, Training Loss: 2.3207\n",
            "Epoch 9, Batch 180/224, Training Loss: 2.5896\n",
            "Epoch 9, Batch 181/224, Training Loss: 1.7281\n",
            "Epoch 9, Batch 182/224, Training Loss: 1.9100\n",
            "Epoch 9, Batch 183/224, Training Loss: 1.5427\n",
            "Epoch 9, Batch 184/224, Training Loss: 1.8314\n",
            "Epoch 9, Batch 185/224, Training Loss: 1.9697\n",
            "Epoch 9, Batch 186/224, Training Loss: 2.1156\n",
            "Epoch 9, Batch 187/224, Training Loss: 1.8328\n",
            "Epoch 9, Batch 188/224, Training Loss: 1.6554\n",
            "Epoch 9, Batch 189/224, Training Loss: 2.4695\n",
            "Epoch 9, Batch 190/224, Training Loss: 1.7454\n",
            "Epoch 9, Batch 191/224, Training Loss: 1.7346\n",
            "Epoch 9, Batch 192/224, Training Loss: 2.0338\n",
            "Epoch 9, Batch 193/224, Training Loss: 1.4365\n",
            "Epoch 9, Batch 194/224, Training Loss: 1.5370\n",
            "Epoch 9, Batch 195/224, Training Loss: 2.5645\n",
            "Epoch 9, Batch 196/224, Training Loss: 1.5209\n",
            "Epoch 9, Batch 197/224, Training Loss: 3.2685\n",
            "Epoch 9, Batch 198/224, Training Loss: 1.6784\n",
            "Epoch 9, Batch 199/224, Training Loss: 1.7993\n",
            "Epoch 9, Batch 200/224, Training Loss: 1.2719\n",
            "Epoch 9, Batch 201/224, Training Loss: 2.1721\n",
            "Epoch 9, Batch 202/224, Training Loss: 2.7369\n",
            "Epoch 9, Batch 203/224, Training Loss: 1.4498\n",
            "Epoch 9, Batch 204/224, Training Loss: 1.5735\n",
            "Epoch 9, Batch 205/224, Training Loss: 2.0107\n",
            "Epoch 9, Batch 206/224, Training Loss: 2.0609\n",
            "Epoch 9, Batch 207/224, Training Loss: 2.2127\n",
            "Epoch 9, Batch 208/224, Training Loss: 2.1420\n",
            "Epoch 9, Batch 209/224, Training Loss: 1.5351\n",
            "Epoch 9, Batch 210/224, Training Loss: 1.5543\n",
            "Epoch 9, Batch 211/224, Training Loss: 1.8718\n",
            "Epoch 9, Batch 212/224, Training Loss: 1.8710\n",
            "Epoch 9, Batch 213/224, Training Loss: 1.9763\n",
            "Epoch 9, Batch 214/224, Training Loss: 2.0358\n",
            "Epoch 9, Batch 215/224, Training Loss: 1.9184\n",
            "Epoch 9, Batch 216/224, Training Loss: 2.1542\n",
            "Epoch 9, Batch 217/224, Training Loss: 1.4247\n",
            "Epoch 9, Batch 218/224, Training Loss: 1.7736\n",
            "Epoch 9, Batch 219/224, Training Loss: 3.0007\n",
            "Epoch 9, Batch 220/224, Training Loss: 2.2716\n",
            "Epoch 9, Batch 221/224, Training Loss: 1.8757\n",
            "Epoch 9, Batch 222/224, Training Loss: 1.9907\n",
            "Epoch 9, Batch 223/224, Training Loss: 2.2272\n",
            "Epoch 9/10, Training Loss: 1.8741, Test Loss: 2.2710\n",
            "Epoch 10, Batch 0/224, Training Loss: 1.3819\n",
            "Epoch 10, Batch 1/224, Training Loss: 1.3219\n",
            "Epoch 10, Batch 2/224, Training Loss: 1.8996\n",
            "Epoch 10, Batch 3/224, Training Loss: 1.5464\n",
            "Epoch 10, Batch 4/224, Training Loss: 1.3024\n",
            "Epoch 10, Batch 5/224, Training Loss: 1.4529\n",
            "Epoch 10, Batch 6/224, Training Loss: 1.7437\n",
            "Epoch 10, Batch 7/224, Training Loss: 1.5046\n",
            "Epoch 10, Batch 8/224, Training Loss: 2.2609\n",
            "Epoch 10, Batch 9/224, Training Loss: 1.2058\n",
            "Epoch 10, Batch 10/224, Training Loss: 2.0531\n",
            "Epoch 10, Batch 11/224, Training Loss: 2.2907\n",
            "Epoch 10, Batch 12/224, Training Loss: 1.4621\n",
            "Epoch 10, Batch 13/224, Training Loss: 1.4716\n",
            "Epoch 10, Batch 14/224, Training Loss: 2.4647\n",
            "Epoch 10, Batch 15/224, Training Loss: 1.3078\n",
            "Epoch 10, Batch 16/224, Training Loss: 1.8146\n",
            "Epoch 10, Batch 17/224, Training Loss: 1.6521\n",
            "Epoch 10, Batch 18/224, Training Loss: 1.3882\n",
            "Epoch 10, Batch 19/224, Training Loss: 1.8656\n",
            "Epoch 10, Batch 20/224, Training Loss: 1.5701\n",
            "Epoch 10, Batch 21/224, Training Loss: 1.4244\n",
            "Epoch 10, Batch 22/224, Training Loss: 1.7956\n",
            "Epoch 10, Batch 23/224, Training Loss: 1.9025\n",
            "Epoch 10, Batch 24/224, Training Loss: 1.6018\n",
            "Epoch 10, Batch 25/224, Training Loss: 1.7157\n",
            "Epoch 10, Batch 26/224, Training Loss: 1.6152\n",
            "Epoch 10, Batch 27/224, Training Loss: 2.1068\n",
            "Epoch 10, Batch 28/224, Training Loss: 1.6553\n",
            "Epoch 10, Batch 29/224, Training Loss: 2.1310\n",
            "Epoch 10, Batch 30/224, Training Loss: 1.5177\n",
            "Epoch 10, Batch 31/224, Training Loss: 2.1086\n",
            "Epoch 10, Batch 32/224, Training Loss: 1.4049\n",
            "Epoch 10, Batch 33/224, Training Loss: 1.7684\n",
            "Epoch 10, Batch 34/224, Training Loss: 2.3664\n",
            "Epoch 10, Batch 35/224, Training Loss: 1.8879\n",
            "Epoch 10, Batch 36/224, Training Loss: 1.4844\n",
            "Epoch 10, Batch 37/224, Training Loss: 1.6959\n",
            "Epoch 10, Batch 38/224, Training Loss: 1.6391\n",
            "Epoch 10, Batch 39/224, Training Loss: 1.8065\n",
            "Epoch 10, Batch 40/224, Training Loss: 1.6216\n",
            "Epoch 10, Batch 41/224, Training Loss: 1.7847\n",
            "Epoch 10, Batch 42/224, Training Loss: 1.7379\n",
            "Epoch 10, Batch 43/224, Training Loss: 1.7296\n",
            "Epoch 10, Batch 44/224, Training Loss: 1.7864\n",
            "Epoch 10, Batch 45/224, Training Loss: 2.3224\n",
            "Epoch 10, Batch 46/224, Training Loss: 1.9304\n",
            "Epoch 10, Batch 47/224, Training Loss: 1.4136\n",
            "Epoch 10, Batch 48/224, Training Loss: 1.6991\n",
            "Epoch 10, Batch 49/224, Training Loss: 1.3652\n",
            "Epoch 10, Batch 50/224, Training Loss: 1.7890\n",
            "Epoch 10, Batch 51/224, Training Loss: 1.8025\n",
            "Epoch 10, Batch 52/224, Training Loss: 2.0844\n",
            "Epoch 10, Batch 53/224, Training Loss: 1.8112\n",
            "Epoch 10, Batch 54/224, Training Loss: 1.0824\n",
            "Epoch 10, Batch 55/224, Training Loss: 1.7984\n",
            "Epoch 10, Batch 56/224, Training Loss: 1.6510\n",
            "Epoch 10, Batch 57/224, Training Loss: 2.0668\n",
            "Epoch 10, Batch 58/224, Training Loss: 2.4204\n",
            "Epoch 10, Batch 59/224, Training Loss: 1.1916\n",
            "Epoch 10, Batch 60/224, Training Loss: 2.1972\n",
            "Epoch 10, Batch 61/224, Training Loss: 2.1985\n",
            "Epoch 10, Batch 62/224, Training Loss: 2.2947\n",
            "Epoch 10, Batch 63/224, Training Loss: 1.6704\n",
            "Epoch 10, Batch 64/224, Training Loss: 1.3948\n",
            "Epoch 10, Batch 65/224, Training Loss: 1.5782\n",
            "Epoch 10, Batch 66/224, Training Loss: 1.7526\n",
            "Epoch 10, Batch 67/224, Training Loss: 2.4722\n",
            "Epoch 10, Batch 68/224, Training Loss: 1.6840\n",
            "Epoch 10, Batch 69/224, Training Loss: 1.9745\n",
            "Epoch 10, Batch 70/224, Training Loss: 1.8505\n",
            "Epoch 10, Batch 71/224, Training Loss: 2.0545\n",
            "Epoch 10, Batch 72/224, Training Loss: 1.9586\n",
            "Epoch 10, Batch 73/224, Training Loss: 1.3857\n",
            "Epoch 10, Batch 74/224, Training Loss: 2.3781\n",
            "Epoch 10, Batch 75/224, Training Loss: 1.9214\n",
            "Epoch 10, Batch 76/224, Training Loss: 1.5682\n",
            "Epoch 10, Batch 77/224, Training Loss: 2.0704\n",
            "Epoch 10, Batch 78/224, Training Loss: 2.3668\n",
            "Epoch 10, Batch 79/224, Training Loss: 1.5774\n",
            "Epoch 10, Batch 80/224, Training Loss: 1.8595\n",
            "Epoch 10, Batch 81/224, Training Loss: 2.0203\n",
            "Epoch 10, Batch 82/224, Training Loss: 1.8296\n",
            "Epoch 10, Batch 83/224, Training Loss: 1.5002\n",
            "Epoch 10, Batch 84/224, Training Loss: 1.5564\n",
            "Epoch 10, Batch 85/224, Training Loss: 1.5972\n",
            "Epoch 10, Batch 86/224, Training Loss: 1.6448\n",
            "Epoch 10, Batch 87/224, Training Loss: 1.3536\n",
            "Epoch 10, Batch 88/224, Training Loss: 1.5542\n",
            "Epoch 10, Batch 89/224, Training Loss: 1.3830\n",
            "Epoch 10, Batch 90/224, Training Loss: 2.2234\n",
            "Epoch 10, Batch 91/224, Training Loss: 2.5580\n",
            "Epoch 10, Batch 92/224, Training Loss: 1.8920\n",
            "Epoch 10, Batch 93/224, Training Loss: 1.7747\n",
            "Epoch 10, Batch 94/224, Training Loss: 1.5286\n",
            "Epoch 10, Batch 95/224, Training Loss: 1.6879\n",
            "Epoch 10, Batch 96/224, Training Loss: 1.8357\n",
            "Epoch 10, Batch 97/224, Training Loss: 1.7885\n",
            "Epoch 10, Batch 98/224, Training Loss: 1.5234\n",
            "Epoch 10, Batch 99/224, Training Loss: 1.5221\n",
            "Epoch 10, Batch 100/224, Training Loss: 1.8328\n",
            "Epoch 10, Batch 101/224, Training Loss: 1.6949\n",
            "Epoch 10, Batch 102/224, Training Loss: 1.2582\n",
            "Epoch 10, Batch 103/224, Training Loss: 2.6611\n",
            "Epoch 10, Batch 104/224, Training Loss: 2.4548\n",
            "Epoch 10, Batch 105/224, Training Loss: 1.9099\n",
            "Epoch 10, Batch 106/224, Training Loss: 1.3951\n",
            "Epoch 10, Batch 107/224, Training Loss: 1.9434\n",
            "Epoch 10, Batch 108/224, Training Loss: 1.8130\n",
            "Epoch 10, Batch 109/224, Training Loss: 1.8527\n",
            "Epoch 10, Batch 110/224, Training Loss: 1.9061\n",
            "Epoch 10, Batch 111/224, Training Loss: 1.8920\n",
            "Epoch 10, Batch 112/224, Training Loss: 2.0623\n",
            "Epoch 10, Batch 113/224, Training Loss: 2.2841\n",
            "Epoch 10, Batch 114/224, Training Loss: 2.0286\n",
            "Epoch 10, Batch 115/224, Training Loss: 1.5336\n",
            "Epoch 10, Batch 116/224, Training Loss: 2.3493\n",
            "Epoch 10, Batch 117/224, Training Loss: 1.9721\n",
            "Epoch 10, Batch 118/224, Training Loss: 2.2380\n",
            "Epoch 10, Batch 119/224, Training Loss: 1.8262\n",
            "Epoch 10, Batch 120/224, Training Loss: 1.8118\n",
            "Epoch 10, Batch 121/224, Training Loss: 1.4923\n",
            "Epoch 10, Batch 122/224, Training Loss: 1.7449\n",
            "Epoch 10, Batch 123/224, Training Loss: 2.6482\n",
            "Epoch 10, Batch 124/224, Training Loss: 1.2249\n",
            "Epoch 10, Batch 125/224, Training Loss: 2.2567\n",
            "Epoch 10, Batch 126/224, Training Loss: 1.6956\n",
            "Epoch 10, Batch 127/224, Training Loss: 1.9155\n",
            "Epoch 10, Batch 128/224, Training Loss: 1.9007\n",
            "Epoch 10, Batch 129/224, Training Loss: 2.0897\n",
            "Epoch 10, Batch 130/224, Training Loss: 2.0472\n",
            "Epoch 10, Batch 131/224, Training Loss: 1.8623\n",
            "Epoch 10, Batch 132/224, Training Loss: 2.0592\n",
            "Epoch 10, Batch 133/224, Training Loss: 2.1611\n",
            "Epoch 10, Batch 134/224, Training Loss: 3.7037\n",
            "Epoch 10, Batch 135/224, Training Loss: 3.1068\n",
            "Epoch 10, Batch 136/224, Training Loss: 6.0290\n",
            "Epoch 10, Batch 137/224, Training Loss: 5.0429\n",
            "Epoch 10, Batch 138/224, Training Loss: 5.8184\n",
            "Epoch 10, Batch 139/224, Training Loss: 2.7244\n",
            "Epoch 10, Batch 140/224, Training Loss: 2.0973\n",
            "Epoch 10, Batch 141/224, Training Loss: 1.6440\n",
            "Epoch 10, Batch 142/224, Training Loss: 2.9634\n",
            "Epoch 10, Batch 143/224, Training Loss: 2.8969\n",
            "Epoch 10, Batch 144/224, Training Loss: 3.1115\n",
            "Epoch 10, Batch 145/224, Training Loss: 4.5360\n",
            "Epoch 10, Batch 146/224, Training Loss: 4.1996\n",
            "Epoch 10, Batch 147/224, Training Loss: 3.8748\n",
            "Epoch 10, Batch 148/224, Training Loss: 4.3544\n",
            "Epoch 10, Batch 149/224, Training Loss: 5.1817\n",
            "Epoch 10, Batch 150/224, Training Loss: 5.5064\n",
            "Epoch 10, Batch 151/224, Training Loss: 3.6790\n",
            "Epoch 10, Batch 152/224, Training Loss: 4.2442\n",
            "Epoch 10, Batch 153/224, Training Loss: 3.8331\n",
            "Epoch 10, Batch 154/224, Training Loss: 5.0351\n",
            "Epoch 10, Batch 155/224, Training Loss: 3.9251\n",
            "Epoch 10, Batch 156/224, Training Loss: 3.2840\n",
            "Epoch 10, Batch 157/224, Training Loss: 4.3539\n",
            "Epoch 10, Batch 158/224, Training Loss: 3.6839\n",
            "Epoch 10, Batch 159/224, Training Loss: 2.8206\n",
            "Epoch 10, Batch 160/224, Training Loss: 3.5960\n",
            "Epoch 10, Batch 161/224, Training Loss: 3.8129\n",
            "Epoch 10, Batch 162/224, Training Loss: 2.7810\n",
            "Epoch 10, Batch 163/224, Training Loss: 3.7703\n",
            "Epoch 10, Batch 164/224, Training Loss: 2.6352\n",
            "Epoch 10, Batch 165/224, Training Loss: 3.8790\n",
            "Epoch 10, Batch 166/224, Training Loss: 2.2906\n",
            "Epoch 10, Batch 167/224, Training Loss: 2.9069\n",
            "Epoch 10, Batch 168/224, Training Loss: 3.6961\n",
            "Epoch 10, Batch 169/224, Training Loss: 2.6971\n",
            "Epoch 10, Batch 170/224, Training Loss: 2.8159\n",
            "Epoch 10, Batch 171/224, Training Loss: 3.6413\n",
            "Epoch 10, Batch 172/224, Training Loss: 3.2613\n",
            "Epoch 10, Batch 173/224, Training Loss: 3.2592\n",
            "Epoch 10, Batch 174/224, Training Loss: 2.9055\n",
            "Epoch 10, Batch 175/224, Training Loss: 2.2383\n",
            "Epoch 10, Batch 176/224, Training Loss: 2.1378\n",
            "Epoch 10, Batch 177/224, Training Loss: 2.6163\n",
            "Epoch 10, Batch 178/224, Training Loss: 2.8658\n",
            "Epoch 10, Batch 179/224, Training Loss: 3.1628\n",
            "Epoch 10, Batch 180/224, Training Loss: 2.8428\n",
            "Epoch 10, Batch 181/224, Training Loss: 2.6912\n",
            "Epoch 10, Batch 182/224, Training Loss: 2.1983\n",
            "Epoch 10, Batch 183/224, Training Loss: 2.4452\n",
            "Epoch 10, Batch 184/224, Training Loss: 2.4833\n",
            "Epoch 10, Batch 185/224, Training Loss: 2.2050\n",
            "Epoch 10, Batch 186/224, Training Loss: 2.1904\n",
            "Epoch 10, Batch 187/224, Training Loss: 2.3219\n",
            "Epoch 10, Batch 188/224, Training Loss: 1.9806\n",
            "Epoch 10, Batch 189/224, Training Loss: 1.8977\n",
            "Epoch 10, Batch 190/224, Training Loss: 3.2533\n",
            "Epoch 10, Batch 191/224, Training Loss: 5.5378\n",
            "Epoch 10, Batch 192/224, Training Loss: 5.2167\n",
            "Epoch 10, Batch 193/224, Training Loss: 4.4188\n",
            "Epoch 10, Batch 194/224, Training Loss: 3.3149\n",
            "Epoch 10, Batch 195/224, Training Loss: 5.3640\n",
            "Epoch 10, Batch 196/224, Training Loss: 5.0714\n",
            "Epoch 10, Batch 197/224, Training Loss: 5.4867\n",
            "Epoch 10, Batch 198/224, Training Loss: 4.2785\n",
            "Epoch 10, Batch 199/224, Training Loss: 6.7884\n",
            "Epoch 10, Batch 200/224, Training Loss: 3.9105\n",
            "Epoch 10, Batch 201/224, Training Loss: 3.2802\n",
            "Epoch 10, Batch 202/224, Training Loss: 3.3858\n",
            "Epoch 10, Batch 203/224, Training Loss: 4.3205\n",
            "Epoch 10, Batch 204/224, Training Loss: 4.7250\n",
            "Epoch 10, Batch 205/224, Training Loss: 3.8195\n",
            "Epoch 10, Batch 206/224, Training Loss: 2.8521\n",
            "Epoch 10, Batch 207/224, Training Loss: 2.5136\n",
            "Epoch 10, Batch 208/224, Training Loss: 2.2824\n",
            "Epoch 10, Batch 209/224, Training Loss: 2.8668\n",
            "Epoch 10, Batch 210/224, Training Loss: 2.1630\n",
            "Epoch 10, Batch 211/224, Training Loss: 2.5616\n",
            "Epoch 10, Batch 212/224, Training Loss: 2.1323\n",
            "Epoch 10, Batch 213/224, Training Loss: 1.9102\n",
            "Epoch 10, Batch 214/224, Training Loss: 2.2784\n",
            "Epoch 10, Batch 215/224, Training Loss: 2.5927\n",
            "Epoch 10, Batch 216/224, Training Loss: 1.5662\n",
            "Epoch 10, Batch 217/224, Training Loss: 2.3118\n",
            "Epoch 10, Batch 218/224, Training Loss: 1.4101\n",
            "Epoch 10, Batch 219/224, Training Loss: 1.6206\n",
            "Epoch 10, Batch 220/224, Training Loss: 2.4814\n",
            "Epoch 10, Batch 221/224, Training Loss: 1.7044\n",
            "Epoch 10, Batch 222/224, Training Loss: 1.8423\n",
            "Epoch 10, Batch 223/224, Training Loss: 1.9991\n",
            "Epoch 10/10, Training Loss: 2.4090, Test Loss: 2.5139\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_losses) # just a second check\n",
        "print(test_losses.index(min(test_losses)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6f7aa6-c29b-4f83-b9be-1c17a9aa7f8a",
        "id": "ktbEZmia9qux"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.3191971267972673, 2.849556314093726, 2.677961549588612, 2.6936318640198027, 2.4052314311265945, 2.4132461228540967, 2.4769255965948105, 2.4436435784612383, 2.355482952935355, 2.3927909029381618]\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Test Data\n",
        "model.eval()\n",
        "test_predictions_list = []\n",
        "test_targets_list = []\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_Y in test_loader:\n",
        "        # Move to the appropriate device\n",
        "        batch_X, batch_Y = batch_X.to(device), batch_Y.to(device)\n",
        "\n",
        "        # Clamp indices in batch_X to ensure they are within the valid range\n",
        "        batch_X = torch.clamp(batch_X, 0, vocab_size - 1)\n",
        "\n",
        "        # Forward pass\n",
        "        test_predictions = model(batch_X)\n",
        "\n",
        "        # Store predictions and true values\n",
        "        test_predictions_list.extend(test_predictions.squeeze(-1).cpu().numpy())\n",
        "        test_targets_list.extend(batch_Y.cpu().numpy())\n",
        "\n",
        "# Convert predictions and targets directly to NumPy arrays\n",
        "test_predictions_array = np.array(test_predictions_list)\n",
        "test_targets_array = np.array(test_targets_list)\n",
        "\n",
        "# Classify as 0 or 1 based on prediction >= 6.25\n",
        "binary_targets = []\n",
        "binary_results = []\n",
        "for prediction in test_predictions_array:\n",
        "    if prediction >= 6.25:\n",
        "        binary_results.append(1)\n",
        "    else:\n",
        "        binary_results.append(0)\n",
        "\n",
        "for target in test_targets_array:\n",
        "    if target >= 6.25:\n",
        "        binary_targets.append(1)\n",
        "    else:\n",
        "        binary_targets.append(0)\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(binary_targets, binary_results))\n",
        "\n",
        "# Flatten arrays to ensure 1D shape\n",
        "test_predictions_array = test_predictions_array.flatten()\n",
        "test_targets_array = test_targets_array.flatten()\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for Regression\n",
        "print(f\"Test MSE: {mean_squared_error(test_targets_array, test_predictions_array)}\")\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "print(f\"Test MAE: {mean_absolute_error(test_targets_array, test_predictions_array)}\")\n",
        "\n",
        "# Calculate R² Score (coefficient of determination)\n",
        "print(f\"Test R² Score: {r2_score(test_targets_array, test_predictions_array)}\")\n",
        "\n",
        "\n",
        "print(test_targets_array.shape)\n",
        "print(test_predictions_array.shape)\n",
        "\n",
        "# Plot predictions vs ground truth for test set\n",
        "plt.plot(range(50), test_targets_array[:50], label=\"Ground Truth\", alpha=0.7)\n",
        "plt.plot(range(50), test_predictions_array[:50], label=\"Predictions\", alpha=0.7)\n",
        "plt.xlabel(\"Sample\")\n",
        "plt.ylabel(\"Positivity Score\")\n",
        "plt.title(\"Test Predictions vs Ground Truth\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "1b62a1d2-80ec-4744-bfb2-fd6ddb97bd14",
        "id": "iequFEQm9qux"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8176785714285715\n",
            "Test MSE: 2.513878107070923\n",
            "Test MAE: 1.2193543910980225\n",
            "Test R² Score: 0.5543614625930786\n",
            "(5600,)\n",
            "(5600,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test random epochs\n",
        "new_review = \"Rude\"\n",
        "# 0.5 Correct any mis-spelling\n",
        "new_review_corrected = correct_with_symspell(new_review)\n",
        "\n",
        "# 1. Clean the new review\n",
        "new_review_cleaned = clean_text(new_review_corrected)\n",
        "\n",
        "# 2. Convert to numerical representation\n",
        "new_review_int = [vocab_to_int.get(word, 0) for word in new_review_cleaned]\n",
        "\n",
        "# 3. Pad the review\n",
        "new_review_padded = [0]*(max_len - len(new_review_int)) + new_review_int\n",
        "\n",
        "# 4. Convert to tensor\n",
        "new_review_tensor = torch.Tensor(new_review_padded).long().unsqueeze(0).to(device) # unsqueeze to add batch dimension\n",
        "\n",
        "# 5. Make prediction\n",
        "with torch.no_grad():\n",
        "  new_review_prediction = model(new_review_tensor)\n",
        "\n",
        "# 6. Print the prediction\n",
        "print(new_review_prediction.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b0c91a-f300-4d39-8069-377cd2fdff40",
        "id": "vZRiNLJv9quy"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.339258193969727\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}